{{< include macros.qmd >}}

# Brownian Motion {#sec-c_continuoustime}

Brownian motion is a fundamental tool for modeling variables that change randomly over time.  Consider predicting a future stock price.  We don't know today what the price will be tomorrow, nor what it will be the following day, nor what it will be the day after that.  We can regard the price three days from now as today's price plus the change from today to tomorrow plus the change from tomorrow to the following day plus the change from that day to the next.  Thus, there are three random changes in this small example.  A simple way to model this situation is to assume each change is a normally distributed random variable with some mean and variance.  Thus, the price in three days is viewed as today's price plus the sum of three normal increments.

Rather than predicting daily changes as in the previous paragraph, we might be interested in predicting hourly changes or even minute-to-minute changes.  This will lead to more, but smaller, increments.  A Brownian motion is a model of changes at all frequencies, with all changes being normally distributed.

We will ultimately deal with different means and different variances, but we start with what is called a standard Brownian motion, which is similar to beginning the study of normal random variables by studying a standard normal variable, that is, a normal random variable with a zero mean and a unit variance.  The definition of a standard Brownian motion is that its change over any time interval 

- is normally distributed
- is independent of prior changes
- has a zero mean
- has a variance equal to the length of the time interval.

## Brownian Paths

We call a variable that changes randomly over time a stochastic process.  A path of a stochastic process is a random function of time, recording how it evolves over time. 
We can plot an approximate path of a Brownian motion by summing up normally distributed changes.  We take an interval of time $[0, t]$ and split it up as
$$0=t_0 < t_1< \cdots < t_{n-1} < t_n=t$$
where the times $t_i$ are equally spaced, meaning that $t_i-t_{i-1} = t/n$, which we will call $\Delta t$.
We generate $n$ normally distributed random variables with zero means and variance equal to $\Delta t$ and define the Brownian motion, which we call $B$, as the cumulative sum of the normal variables.  By convention, we will start the Brownian motion at $B_0=0$.  This fits the definition of a standard Brownian motion, except that we have limited the frequency of the changes to $n$ changes within the interval.  By taking $n$ larger, we can always get a better approximation.  


```{python}
#| label: fig-brownian-path
#| fig-cap: "A path of an approximate Brownian motion with 1,000 normally distributed steps steps."
import numpy as np
import plotly.graph_objects as go

n = 1000   # number of subdivisions
t = 0.5    # last date
dt = t/n

# generate dB for each time step
dB = np.random.normal(scale = np.sqrt(dt), size=n)

# B starts at 0 and is cumulative sum of the dB
B = np.zeros(n+1)
B[1:] = dB.cumsum()

fig = go.Figure()
fig.add_trace(
  go.Scatter(
    x=np.arange(0, t+dt, dt), 
    y=B, 
    mode='lines', 
    hovertemplate='t=%{x:.2f}<br>B=%{y:.2f}<extra></extra>'  # 
    )
)

fig.update_layout(
    showlegend=False,
    xaxis_title='Time',
    yaxis_title='Approximate Brownian Motion',
    template='plotly_white',
    height=300,
)

fig.show()
```

## Binomial Approximation

We can also generate an approximate path of a Brownian motion by taking only up or down steps of a fixed size at each date, rather than using normally distributed steps.  We call this a binomial model.  A binomial model approximates  the normally distributed increments of a Brownian Motion due to the Central Limit Theorem, which says that an appropriately scaled sum of a large number of random variables has approximately a normal distribution.  The binomial approximation is often useful for pricing options, especially American options, as we will see.

```{python}
#| label: fig-binomial-path
#| fig-cap: "A path of an approximate Brownian motion with 1,000 binomial steps."
import numpy as np
import plotly.graph_objects as go

n = 1000   # number of subdivisions
t = 0.5    # last date
dt = t/n
sqdt = np.sqrt(dt)

# generate dB for each time step
dB = np.random.choice([-sqdt, sqdt], size=n)
B = np.zeros(n+1)

# Brownian path starts at 0 and is cumulative sum of the dB
B[1:] = dB.cumsum()

fig = go.Figure()
fig.add_trace(
  go.Scatter(
    x=np.arange(0, t+dt, dt), 
    y=B, 
    mode='lines', 
    hovertemplate='t=%{x:.2f}<br>B=%{y:.2f}<extra></extra>'  # 
    )
)

fig.update_layout(
    showlegend=False,
    xaxis_title='Time',
    yaxis_title='Binomial Process',
    template='plotly_white',
    height=300,
)

fig.show()
```

## Nonzero Quadratic Variation {#sec-s_quadraticvariation}

@fig-brownian-path and @fig-binomial-path illustrate a distinctive characteristic of a Brownian motion: it jiggles rapidly, moving up and down in a very erratic way.  The name Brownian motion derives from the botanist Robert Brown's observations of the erratic behavior of particles suspended in a fluid.  This has long been thought to be a reasonable model for the behavior of a stock price. The plot of other functions with which we may be familiar will be much smoother.  This is captured in the concept of quadratic variation.  

Consider a discrete partition 
$$0=t_0 < t_1 < t_2 < \cdots < t_n=t$$
of the time interval $[0,t]$ as before.  Let $B$ be a Brownian motion and calculate the sum of squared changes
$$\sum_{i=1}^n (\Delta B_{t_i})^2\; ,$$
where $\Delta B_{t_i}$ denotes the change $B_{t_i}-B_{t_{i-1}}.$  If we consider finer partitions with the length of each time interval $t_i-t_{i-1}$ going to zero, the limit of the sum is called the quadratic variation of the process.  \index{quadratic variation} For a Brownian motion, the quadratic variation over an interval $[0,t]$ is equal to $t$ with probability one.  Here is a plot of the quadratic variation (that is, the cumulative sum of squared changes) of the previous approximation of a Brownian motion.  The plot shows that the approximation has quadratic variation through each date $s \le t$ that is approximately equal to $s$.

```{python}
#| label: fig-quadratic-variation
#| fig-cap: "Quadratic variation of an approximate Brownian motion path with 1,000 normally distributed steps."

# quadratic variation is cumulative sum of squared changes
dQ = dB**2
Q = np.zeros(n+1)
Q[1:] = dQ.cumsum()

fig = go.Figure()
fig.add_trace(
  go.Scatter(
    x=np.arange(0, t+dt, dt), 
    y=Q, 
    mode='lines', 
    hovertemplate='t=%{x:.2f}<br>B=%{y:.2f}<extra></extra>' 
    )
)

fig.update_layout(
    showlegend=False,
    xaxis_title='Time',
    yaxis_title='Quadratic Variation',
    template='plotly_white',
    height=300
)
```

To better visualize the convergence of the quadratic variation of a Brownian motion as the number $n$ of subdivisions of the interval $[0, t]$ grows, we encourage readers to interact with the plot below, which simulates a handful of approximate Brownian paths and their quadratic variations.

::: {#fig-interactive_quad_var fig-cap="Convergence of quadratic variation of approximate Brownian motions."}
<iframe width="600" height="500" src="https://derivatives-book-26ac36570fb8.herokuapp.com/math_finance_book_plots/quad_var_plot"></iframe>


:::

The typical functions with which we are familiar are continuously differentiable.  If $x$ is a continuously differentiable function of time, then the quadratic variation of $x$ is zero.  A simple example is a linear function:   
$x_s = as$ for all $s$ for a constant $a$. Then, using the previous partition of the interval $[0, t]$, the quadratic variation of the function from $0$ to $t$ is
$$\sum_{i=1}^n (\Delta x_{t_i})^2 = \sum_{i=1}^n  [a\,\Delta t]^2 = na^2 (\Delta t)^2 = na^2 \left(\frac{t}{n}\right)^2 = \frac{a^2t^2}{n} \rightarrow 0$$
as $n \rightarrow \infty$.  Essentially the same argument shows that the quadratic variation of any continuously differentiable function is zero, because such a function is approximately linear at each point.  Thus, the jiggling of a Brownian motion, which leads to the nonzero quadratic variation, is quite unusual. 


## Infinite Total Variation

To explain exactly how unusual the nonzero quadratic variation is, it is helpful to consider total variation, \index{total variation} which is defined in the same way as quadratic variation but with the squared changes $(\Delta B_{t_i})^2$ replaced by the absolute values of the changes $|\Delta B_{t_i}|.$  A general mathematical theorem states that, if the quadratic variation of a continuous function is nonzero, then its total variation is infinite.  Therefore, each path of a Brownian motion has infinite total variation (with probability one).  This means that, to draw a true path of a Brownian on a blackboard, we would need an infinite amount of chalk!

If we zoom in close enough in @fig-brownian-path, we can see the linear steps $\Delta B$.  However, if we could zoom in on a segment of a path of a true Brownian motion, it would look much the same as the entire picture does to the naked eye---no matter how small the segment, we would still see the characteristic jiggling.  That jiggling, even at microscopic scales, is the source of the infinite variation.

## Continuous Martingales and Levy's Theorem

One may well question why we should be interested in this curious mathematical object.  The reason is that asset pricing inherently involves martingales (variables that evolve randomly over time in such a way that their expected changes are always zero), as our fundamental pricing formula (@eq-formula) establishes.  Furthermore, continuous processes (variables whose paths are continuous functions of time) are much more tractable mathematically than are processes that can jump at some instants.  More importantly, it is possible in a mathematical model with continuous processes to define perfect hedges much more readily than it is in a model involving jump processes.  So, we are led to a study of continuous martingales.  An important fact is that any non-constant continuous martingale must have infinite total variation!  So, the normal functions with which we are familiar are left behind once we enter the study of continuous martingales.  

There remains perhaps the question of why we focus on Brownian motion within the world of continuous martingales.  The answer here is that any continuous martingale is really just a transformation of a Brownian motion.  This is a consequence of the following important fact, which is known as Levy's theorem: \index{Levy's theorem}

::: Principle
## 
A continuous martingale is a Brownian motion if and only if its quadratic variation over each interval $[s, t]$ equals $t-s$.
:::

Thus, among continuous martingales, a Brownian motion is defined by the condition that its quadratic variation over each time interval is equal to the length of the interval.  This is really just a normalization.  A different continuous martingale may have a different quadratic variation, but it can be converted to a Brownian motion by changing the clock speed to measure time according to the quadratic variation.  Furthermore, many continuous martingales can be constructed as stochastic integrals with respect to a Brownian motion.  We take up that topic in the next chapter.


## {.unnumbered}


::: Exercise
 Consider a discrete partition $0=t_0 < t_1 < \cdots t_n=t$ of the time interval $[0,t]$ with $t_i - t_{i-1} = \Delta t = t/n$ for each $i$.  Consider the function 
$$X_t=\mathrm{e}^t\; .$$
Write a function that computes and plots $\sum_{i=1}^n (\Delta X_{t_i})^2$, where 
$$\Delta X_{t_i} = X_{t_i}-X_{t_{i-1}} = \mathrm{e}^{t_i} - \mathrm{e}^{t_{i-1}}\; .$$
:::
::: Exercise
 Repeat the previous problem for the function $X_t = t^3$.  In both this and the previous problem, can you tell what happens to $\sum_{i=1}^n (\Delta X_{t_i})^2$ as $n \rightarrow \infty$?
:::
::: Exercise
 Write a function to compute $\sum_{i=1}^n (\Delta B_{t_i})^2$ from a partition of an interval $[0, t]$, for given $t$ and $n$, where $B$ is a simulated Brownian motion.  For a given $t$, what happens to the sum as $n \rightarrow \infty$?  
:::
::: Exercise
 Repeat the previous problem to compute $\sum_{i=1}^n (\Delta B_{t_i})^3$, where $B$ is a simulated Brownian motion.  For a given $t$, what happens to the sum as $n \rightarrow \infty$?  
:::
::: Exercise
 Repeat the previous problem, computing instead $\sum_{i=1}^n |\Delta B_{t_i}|$ where $| \cdot |$ denotes the absolute value.  What happens to this sum as $n \rightarrow \infty$?
:::
