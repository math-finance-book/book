# Brownian Motion {#sec-c_continuoustime}

Brownian motion is a fundamental tool for modeling uncertainty that resolves over time.  Consider predicting a future stock price.  We don't know today what the price will be tomorrow, nor what it will be the following day, nor what it will be the day after that.  We can regard the price three days from now as today's price plus the change from today to tomorrow plus the change from tomorrow to the following day plus the change from that day to the next.  Thus, there are three random changes in this small example.  A simple way to model this situation is to assume each change is a normally distributed random variable with some mean and variance.  Thus, the price in three days is viewed as today's price plus the sum of three normal increments.

Rather than predicting daily changes as in the previous paragraph, we might be interested in predicting hourly changes or even minute-to-minute changes.  This will lead to more, but smaller, increments.  A Brownian motion models changes at all frequencies simultaneously, with all changes being normally distributed.

We will ultimately deal with different means and different variances, but we start with what is called a standard Brownian motion, which is similar to beginning the study of normal random variables by studying a standard normal variable, that is, a normal random variable with a zero mean and a unit variance.  The definition of a standard Brownian motion is that its change over any time interval 

- is normally distributed
- is independent of prior changes
- has a zero mean
- has a variance equal to the length of the time interval.

We can plot an approximate path of a Brownian motion by summing up normally distributed changes.  We take an interval of time $[0, t]$ and split it up as
$$0=t_0 < t_1< \cdots < t_{N-1} < t_N=t$$
where the times $t_i$ are equally spaced, meaning that $t_i-t_{i-1} = t/N$, which we will call $\Delta t$.
We generate $N$ normally distributed random variables with zero means and variance equal to $\Delta t$ and define the Brownian motion, which we call $B$, as the cumulative sum of the normal variables.  By convention, we will start the Brownian motion at $B_0=0$.  This fits the definition of a standard Brownian motion, except that we have limited the frequency of the changes to $N$ changes within the interval.  By taking $N$ larger, we can always get a better approximation.  


```{python}
#| label: fig-brownian-path
#| fig-cap: "A Path of a Brownian Motion"
import numpy as np
import plotly.graph_objects as go

N = 1000   # number of subdivisions
t = 0.5    # last date
dt = t/N

# generate dB for each time step
dB = np.random.normal(scale = np.sqrt(dt), size=N)
B = np.zeros(N+1)

# Brownian path starts at 0 and is cumulative sum of the dB
B[1:] = dB.cumsum()

fig = go.Figure()
fig.add_trace(
  go.Scatter(
    x=np.arange(0, t+dt, dt), 
    y=B, 
    mode='lines', 
    hovertemplate='t=%{x:.2f}<br>B=%{y:.2f}<extra></extra>'  # 
    )
)

fig.update_layout(
    showlegend=False,
    xaxis_title='Time',
    yaxis_title='Brownian Motion',
    template='plotly_white',
    height=300,
)

fig.show()
```


## Quadratic Variation {#sec-s_quadraticvariation}

@fig-brownian-path illustrates a distinctive characteristic of a Brownian motion: it jiggles rapidly, moving up and down in a very erratic way.  The name Brownian motion derives from the botanist Robert Brown's observations of the erratic behavior of particles suspended in a fluid.  This has long been thought to be a reasonable model for the behavior of a stock price. The plot of other functions with which we may be familiar will be much smoother.  This is captured in the concept of quadratic variation.  

Consider a discrete partition 
$$0=t_0 < t_1 < t_2 < \cdots < t_N=t$$
of the time interval $[0,t]$ as before.  Let $B$ be a Brownian motion and calculate the sum of squared changes
$$\sum_{i=1}^N [\Delta B_{t_i}]^2\; ,$$
where $\Delta B_{t_i}$ denotes the change $B_{t_i}-B(t_{i-1}).$  If we consider finer partitions with the length of each time interval $t_i-t_{i-1}$ going to zero, the limit of the sum is called the quadratic variation of the process.  \index{quadratic variation} For a Brownian motion, the quadratic variation over an interval $[0,t]$ is equal to $t$ with probability one.  Here is a plot of the quadratic variation (that is, the cumulative sum of squared changes) of the previous approximation of a Brownian motion.  The plot shows that the approximation has quadratic variation through each date $s \le t$ that is approximately equal to $s$.

```{python}
#| label: fig-quadratic-variation
#| fig-cap: "Quadratic Variation of a Brownian Motion Path"

# quadratic variation is cumulative sum of squared changes
dQ = dB**2
Q = np.zeros(N+1)
Q[1:] = dQ.cumsum()

fig = go.Figure()
fig.add_trace(
  go.Scatter(
    x=np.arange(0, t+dt, dt), 
    y=Q, 
    mode='lines', 
    hovertemplate='t=%{x:.2f}<br>B=%{y:.2f}<extra></extra>' 
    )
)

fig.update_layout(
    showlegend=False,
    xaxis_title='Time',
    yaxis_title='Quadratic Variation',
    template='plotly_white',
    height=300
)


```


The typical functions with which we are familiar are continuously differentiable.  If $X$ is a continuously differentiable function of time, then the quadratic variation of $X$ is zero.  A simple example is a linear function: $X(t) = at$ for some constant $a$.  Then, taking $t_i-t_{i-1} = \Delta t = T/N$ for each $i$, the sum of squared changes is
$$\sum_{i=1}^N [\Delta X_{t_i}]^2 = \sum_{i=1}^N  [a\,\Delta t]^2 = Na^2 (\Delta t)^2 = Na^2 \left(\frac{T}{N}\right)^2 = \frac{a^2T^2}{N} \rightarrow 0$$
as $N \rightarrow \infty$.  Essentially the same argument shows that the quadratic variation of any continuously differentiable function is zero, because such a function is approximately linear at each point.  Thus, the jiggling of a Brownian motion, which leads to the nonzero quadratic variation, is quite unusual.  

To explain exactly how unusual the nonzero quadratic variation is, it is helpful to consider total variation, \index{total variation} which is defined in the same way as quadratic variation but with the squared changes $[\Delta B_{t_i}]^2$ replaced by the absolute value of the changes $|\Delta B_{t_i}|.$  A general mathematical theorem states that, iff the quadratic variation of a continuous function is nonzero, then its total variation is necessarily infinite, so each path of a Brownian motion has infinite total variation (with probability one).  

It was mentioned above that, with a large number of time steps in the simulation of the preceding section, one could see the distinctive jiggling property of a Brownian motion.  This is not quite right.  We can never draw a plot of a function that has infinite total variation, so we can never draw a plot of a continuous function that has nonzero quadratic variation.  Another way to understand this is to zoom in on @fig-brownian-path.  If we zoom in close enough, we can see the linear steps $\Delta B$.  However, if we could view a segment of a path of a true Brownian motion under a magnifying glass, it would look much the same as the entire picture does to the naked eye---no matter how small the segment, we would still see the characteristic jiggling.


To better visualize the convergence of the quadratic variation of a handful of simulated paths of a standard Brownian motion, we encourage readers to interact with the plot below.

::: {#fig-interactive_quad_var}
<iframe width="780" height="1000" src="https://derivatives-book-26ac36570fb8.herokuapp.com/math_finance_book_plots/quad_var_plot"></iframe>

Convergence of quadratic variation for a standard Brownian motion
:::

One may well question why we should be interested in this curious mathematical object.  The reason is that asset pricing inherently involves martingales (variables that evolve randomly over time in such a way that their expected changes are always zero), as our fundamental pricing formula (@eq-formula) establishes.  Furthermore, continuous processes (variables whose paths are continuous functions of time) are much more tractable mathematically than are processes that can jump at some instants.  More importantly, it is possible in a mathematical model with continuous processes to define perfect hedges much more readily than it is in a model involving jump processes.  So, we are led to a study of continuous martingales.  An important fact is that any non-constant continuous martingale must have infinite total variation!  So, the normal functions with which we are familiar are left behind once we enter the study of continuous martingales.  

There remains perhaps the question of why we focus on Brownian motion within the world of continuous martingales.  The answer here is that any continuous martingale is really just a transformation of a Brownian motion.  This is a consequence of the following important fact, which is known as Levy's theorem: \index{Levy's theorem}

::: {.callout-tip}
## 
A continuous martingale is a Brownian motion if and only if its quadratic variation over each interval $[0,T]$ equals $T$.
:::

Thus, among continuous martingales, a Brownian motion is defined by the condition that the quadratic variation over each interval $[0,T]$ is equal to $T$.  This is really just a normalization.  A different continuous martingale may have a different quadratic variation, but it can be converted to a Brownian motion just by deforming the time scale.  Furthermore, many continuous martingales can be constructed as stochastic integrals with respect to a Brownian motion.  We take up this topic in the next section.


## Exercises


::: {#exr-nolabel}
 Consider a discrete partition $0=t_0 < t_1 < \cdots t_N=T$ of the time interval $[0,T]$ with $t_i - t_{i-1} = \Delta t = T/N$ for each $i$.  Consider the function 
$$X(t)=\mathrm{e}^t\; .$$
Write a code, which computes and plots $\sum_{i=1}^N [\Delta X_{t_i}]^2$, where 
$$\Delta X_{t_i} = X_{t_i}-X(t_{i-1}) = \mathrm{e}^{t_i} - \mathrm{e}^{t_{i-1}}\; .$$
:::
::: {#exr-nolabel}
 Repeat the previous problem for the function $X(t) = t^3$.  In both this and the previous problem, what happens to $\sum_{i=1}^N [\Delta X_{t_i}]^2$ as $N \rightarrow \infty$?
:::
::: {#exr-nolabel}
 Either use the code provided or write a code to compute $\sum_{i=1}^N [\Delta B_{t_i}]^2$, where $B$ is a simulated Brownian motion.  For a given $T$, what happens to the sum as $N \rightarrow \infty$?  
:::
::: {#exr-nolabel}
 Repeat the previous problem to compute $\sum_{i=1}^N [\Delta B_{t_i}]^3$, where $B$ is a simulated Brownian motion.  For a given $T$, what happens to the sum as $N \rightarrow \infty$?  
:::
::: {#exr-nolabel}
 Repeat the previous problem, computing instead $\sum_{i=1}^N |\Delta B_{t_i}|$ where $| \cdot |$ denotes the absolute value.  What happens to this sum as $N \rightarrow \infty$?
:::
