{{< include macros.qmd >}}

# Ito's Formula {#sec-c_ito}

We use the changes of a Brownian motion to model randomness.  We build other stochastic process using those changes.  The general idea is
$$\text{change} = \text{mean} + \text{std dev} \times \text{change in Brownian motion}\,.$$
The mathematical foundations for this construction, using changes in infinitesimal time periods so that we can model all frequencies, were created by K. Ito.  The key concepts are called the Ito integral and Ito's formula (also called Ito's lemma).  Using these techniques, we can build quite general processes, including processes with non-normal distributions.

## From Discrete to Continuous Time {#sec_f_discrete}

We begin with some simple discrete-time examples.  Consider a discrete partition of a time interval as before
$$0=t_0 < t_1< \cdots < t_{n-1} < t_n=t$$
with equally spaced times.  Let $\Delta t$ denote the difference between successive times.  

First, we drop the randomness entirely.  Consider the equation
$$X_{t_i} - X_{t_{i-1}} = \mu X_{t_{i-1}}$$
for a constant $\mu$.  Thus, we have ``change $\,=\,$ mean,'' where the mean is proportional to the previous value.  @fig-discrete-interest presents a plot of $X$, for particular values of $\mu$, $X_0$, $t$, and $n$.

If we increase $n$, making $\Delta t$ smaller, then $X$ will converge to the solution of the ordinary differential equation
$$\d X_t = \mu X_t\,\d t\,.$$
The solution of this equation is also shown in @fig-discrete-interest.  The differential equation has a known solution, which is 
$$X_t = X_0 \e^{\mu t}\,.$$
To verify this, we only need to differentiate:
$$\frac{\d X_t}{\d t} = \mu X_0 \e^{\mu t} = \mu X_t\,.$$

Now, let's include randomness.  Let $B$ be a standard Brownian motion and consider the equation
$$X_{t_i} - X_{t_{i-1}} = \mu X_{t_{i-1}} + \sigma \Delta B_{t_i}$$
where $\sigma$ is another constant, and $\Delta B_{t_i} = B_{t_i} - B_{t_{i-1}}$.  Now, the process $X$ has random paths, due to the random noise $\Delta B_{t_i}$.  An example of a path is shown in @fig-discrete-random.
Ito showed how we can take the limit of this equation as $\Delta t$ decreases and make sense of the equation
$$\d X_t = \mu X_t\,\d t + \sigma\,\d B_t\,.$$
The solution $X$ of this equation is
$$X_t = \e^{\mu t}X_0 + \int_0^t \e^{\mu(s-t)}\,\d B_s\,.$$
The integral in this solution is called an Ito integral.
An approximate path of this process $X$ is also shown in @fig-discrete-random.  It is generated by taking $\Delta t$ very small, just as we generated approximate paths of Brownian motions in @sec-c_brownian.  

## Ito Processes {#sec-s_itoprocesses}
An Ito process is a variable $X$ that changes over time as \index{Ito process}
$$
\d  X_t = \mu_t\,\d  t+\sigma_t\,\d  B_t\;,
$$ {#eq-itoprocess}

where $B$ is a Brownian motion, and $\mu$ and $\sigma$ can also be random processes.  Some regularity conditions are needed on $\mu$ and $\sigma$ which we will omit, except for noting that $\mu_t$ and $\sigma_t$ should be known at time $t$.  In particular, constant $\mu$ and $\sigma$ are certainly acceptable.  When we add the changes over time, we get
$$X_t=X_0 + \int_0^T\mu_t\,\d  t + \int_0^T\sigma_t\,\d  B_t$$
for any $T>0$.  There are other types of random processes, in particular, processes that can jump, but we will not consider them in this book.

We will not formally define the integral $\int_0^T \sigma_t\,\d  B_t$, but it should be understood as being approximately equal to a discrete sum of the form 
$$\sum_{i=1}^N \sigma_{t_{i-1}}\,\Delta B_{t_i}\; ,$$
where $0=t_0 < \cdots t_N=T$ and the time periods $t_i-t_{i-1}$ are small.  Given that we can simulate the changes $\Delta B_{t_i}$ as random normals, we can approximately simulate the random variable $\int_0^T \sigma_t\,\d  B_t$ and hence we can approximately simulate $X_t$.

An Ito process evolves continuously over time.  We interpret $\mu_t\,\d  t$ as the expected change in $X$ in an instant $\d  t$.  The quantity $\mu_t$  is also called the drift of the process $X$ at time $t$.   \index{drift} The coefficient $\sigma_t$ is called the diffusion coefficient of $X$ at time $t$.  \index{diffusion coefficient}

If $\mu$ and $\sigma$ are constant, it is standard to refer to an Ito process $X$ as a $(\mu,\sigma)$--Brownian motion.  In this case we have
$$X_t= \mu t + \sigma B_t$$

Of course, it is not a martingale when $\mu\neq 0$.  For example, when $\mu>0$, $X$ tends to increase over time.  However, it has the jiggling property of a Brownian motion, scaled by the diffusion coefficient $\sigma$. 

A very important fact is that an Ito process such as $X$ in @eq-itoprocess can be a martingale only if $\mu=0$.  This should seem sensible, because $\mu\,\d  t$ is the expected change in $X$, and a process is a martingale only if its expected change is zero.^[If the sources of uncertainty in the market can be modeled as Brownian motions, then in fact every martingale is an Ito process with $\mu=0$.  This is some justification for the assumption we will make in this book, when studying continuous-time models, that all martingales are Ito processes.]   This observation plays a fundamental role in deriving asset pricing formulas, as we will begin to see in @sec-s_girsanov.
Conversely, if $\mu=0$ and 
$$
\E \left[\int_0^T \sigma^2_t\,\d  t\right] < \infty
$$ {#eq-regularity1}

for each $T$, then the Ito process is a continuous martingale, and the variance of its date--$T$ value, calculated with the information available at date $0$, is:
$$\mathrm{var}[X_t] = \E \left[\int_0^T \sigma^2_t\,\d  t\right]\; .$$  

Whether $\mu$ is zero or not, and independently of the assumption stated as @eq-regularity1, the quadratic variation of the Ito process $X$ is 
$$
\lim_{N \rightarrow \infty} \sum_{i=1}^N[\Delta X_{t_i}]^2 = \int_0^T \sigma^2_t\,\d  t
$$ {#eq-itoquadraticvariation}

with probability one.  Thus we obtain (when $\mu=0$ and @eq-regularity1 holds) a continuous martingale with a different quadratic variation than a Brownian motion via the diffusion function $\sigma$.  In fact, when @eq-regularity1 holds, a somewhat more precise definition of the stochastic integral is the (unique) martingale with quadratic variation given by @eq-itoquadraticvariation.

To compute the quadratic variation of an Ito process, we use the following simple and important rules (for the sake of brevity, we drop the $_t$ notation from $B_t$ here and sometimes later):

::: Rule
## 


$$
(\d  t)^2 = 0\;, 
$$ {#eq-dtsquared}

$$
(\d  t)(\d  B) =0\;, 
$$ {#eq-dB}

$$
(\d  B)^2 =\d  t\;. 
$$ {#eq-dBsquared}



:::


We apply these rules to compute the quadratic variation of $X$ as follows:

::: Rule
## 
If $\d  X = \mu\,\d  t + \sigma\,\d  B$ for a Brownian motion $B$, then
\begin{align*}
(\d  X)^2 &= (\mu\,\d  t+\sigma\,\d  B)^2\\
&= \mu^2(\d  t)^2 + 2\mu\sigma(\d  t)(\d  B) + \sigma^2(\d  B)^2\\
&= 0 + 0 + \sigma^2\,\d  t\;.
\end{align*}
:::

We integrate this from 0 to $T$ to obtain the quadratic variation @eq-itoquadraticvariation over that time period:^[In a more formal mathematical presentation, one normally writes $\d \langle X,X\rangle$ for what we are writing here as $(\d  X)^2$.  This is the differential of the quadratic variation process, and the quadratic variation through date $T$ is
$$
\langle X,X\rangle _t = \int_0^T \d \langle X,X\rangle_t = \int_0^T \sigma^2_t\,\d  t\;.
$$]
$$
\int_0^T (\d  X_t)^2 = \int_0^T \sigma^2_t\,\d  t\;.
$$ {#eq-itoquadraticvariation2}




## Ito's Formula {#sec-s_itosformula}

First we recall some facts of the ordinary calculus.  If $y=g(x)$ and $x = f_t$ with $f$ and $g$ being continuously differentiable functions, then 
$$\frac{\d  y}{\d  t} = \frac{\d  y}{\d  x}\times \frac{\d  x}{\d  t} = g'(x_t)f'_t\; .$$
Over a time period $[0,T]$, this implies that
$$y_t = y_0 + \int_0^T \frac{\d  y}{\d  t}\,\d  t = y_0 + \int_0^T g'(x_t)f'_t\,\d  t\; .$$
Substituting $\d  x_t = f'_t\,\d  t$, we can also write this as
$$
y_t = y_0 + \int_0^T g'(x_t)\,\d  x_t\;.
$$ {#eq-ordinarycalculus}


We can contrast  @eq-ordinarycalculus  with a special case of Ito's formula for the calculus of Ito processes (the more general formula will be discussed in the next section).  If $B$ is a Brownian motion and $Y = g(B)$ for a twice-continuously differentiable function $g$, then \index{Ito's formula}
$$
Y_t = Y_0 + \int_0^T g'(B_t)\,\d  B_t + \frac{1}{2}\int_0^T g''(B_t)\,\d  t\;.
$$ {#eq-itonew1}

Thus, relative to the ordinary calculus, Ito's formula has an extra term involving the second derivative $g''$.  We can write @eq-itonew1 in differential form as
$$\,\d  Y_t = \frac{1}{2}g''(B_t)\,\d  t + g'(B_t)\,\d  B_t.$$
Thus, $Y=g(B)$ is an Ito process with drift $g''(B_t)/2$ and diffusion coefficient $g'(B_t)$.

To gain some intuition for the extra term in Ito's formula, we return to the ordinary calculus.  Given dates $t<u$, the derivative defines a linear approximation of the change in $y$ over this time period; i.e., setting $\Delta x = x(u)-x_t$ and $\Delta y = y(u) - y_t$, we have the approximation
$$\Delta y \approx g'(x_t) \,\Delta x\; .$$
A better approximation is given by the second-order Taylor series expansion
$$\Delta y \approx g'(x_t)\,\Delta x + \frac{1}{2} g''(x_t)\,[\Delta x]^2\; .$$
An interpretation of  @eq-ordinarycalculus is that the linear approximation works perfectly for infinitesimal time periods $\d  t$, because we can compute the change in $y$ over the time period $[0,T]$ by summing up the infinitesimal changes $g'(x_t)\,\d  x_t$.  In other words, the second-order term $\frac{1}{2} g''(x_t)\,[\Delta x]^2$ vanishes when we consider very small time periods.

The second-order Taylor series expansion in the case of $Y=g(B)$ is 
$$\Delta Y \approx g'(B_t)\,\Delta B + \frac{1}{2} g''(B_t)\,[\Delta B]^2\; .$$
For example, given a partition $0=t_0 < t_1 < \cdots < t_N=T$ of the time interval $[0,T]$, we have, with the same notation we have used earlier,

$$
Y_t = Y_0 + \sum_{i=1}^N \Delta Y_{t_i}  
$$
$$
\approx Y_0 + \sum_{i=1}^N g'(B_{t_{i-1}})\,\Delta B_{t_i} + \frac{1}{2} \sum_{i=1}^N g''(B_{t_{i-1}})\,[\Delta B_{t_i}]^2\;.
$$ {#eq-itonew2}


If we make the time intervals $t_i-t_{i-1}$ shorter, letting $N \rightarrow \infty$, then we cannot expect that the extra term here will disappear, leading to the result  of the ordinary calculus shown in@eq-ordinarycalculus, because we know that
$$\lim_{N \rightarrow \infty} \sum_{i=1}^N [\Delta B_{t_i}]^2 = T\; ,$$
whereas for the continuously differentiable function $x_t = f_t$, the same limit is zero.  In fact it seems sensible to interpret the limit of $[\Delta B]^2$ as $(\d  B)^2 =\d  t$.
This is perfectly consistent with Ito's formula: if we take the limit in @eq-itonew2, replacing the limit of $[\Delta B_{t_i}]^2$ with $(\d  B)^2 = \d  t$, we obtain @eq-itonew1.

The code below defines a function $g(x)=e^{x}$ ($g'(x)=e^x$ and $g''(x) = e^x$) and simulates the value $e^{B_t}$ in two ways.  The first way is to simulate the Ito expansion
$$e^{B_t}=1 + \int_0^t e^{B_s} d B_s + \frac{1}{2}\int_0^t e^{B_s} ds$$
using the discretization
$$\Delta e^{B_t}= e^{B_t} \Delta B_t + \frac{1}{2} e^{B_t} \Delta t $$
```{python}
#| label: simulated_ito
#| fig-cap: "Simulated Ito Formula"

"""
import numpy as np

n = 1000
m = 1

# Define a function and its first and second derivative
G = lambda x: np.exp(x)
DG = lambda x: np.exp(x)
DDG = lambda x: np.exp(x)
# Build G'(x)\,\d  B
GdB = np.zeros(shape = (n, m))
GdB[0] = np.repeat(DG_0, m) * inc[0]
GdB[1:] = DG(Bt[0:n - 1]) * inc[1:]
SI = np.zeros(shape = (n, m))
# Stochastic Integral is cumulative sum of G'(B)dB plus initial
SI = GdB.cumsum(axis = 0) + 0.5 * (DDG(Bt[0:n])*Q).cumsum(axis =0) + G_0
# Compare Ito's Lemma 
plt.figure(figsize=(9,6))
plt.plot(t[0:n], SI[:,0])
"""
```
Below is the exact simulated solution $e^{B_t}$.  It is almost impossible to see a difference.
```{python}
#| label: simulated_exact
#| fig-cap: "Simulated Exact Solution"
#exact solution
"""
plt.figure(figsize=(9,6))
plt.plot(t[0:n], G(Bt[1:n + 1, 0]))
"""
```
Below we plot the $\int_0^t \frac{1}{2} g''(B_s) ds$ term.  Without this term the two plots above will not match.

```{python}
#| label: correction
#| fig-cap: "Second Derivative Term in Ito's Formula"
"""
QVV = np.zeros(shape = (n, m))
QVV = 0.5*(DDG(Bt[0:n]) * Q).cumsum(axis = 0)
plt.figure(figsize=(9,6))
plt.plot(t[0:n], QVV[:,0])
"""
```

To see the accuracy of Ito's approximation over different amounts of subdivisions, as well as the impact of the second derivative term $\int_0^t (1/2)g''(B_s)ds$, we encourage readers to interact with the plot below.

::: {#fig-interactive_ito}
<iframe width="780" height="1000" src="https://derivatives-book-26ac36570fb8.herokuapp.com/math_finance_book_plots/ito_approx_plot"></iframe>

Accuracy of Ito's approximation
:::


## Multiple Ito Processes

Now consider two Ito processes


$$
\d  X_t = \mu_x_t\,\d  t + \sigma_x_t\,\d  B_x_t\;,
$$ {#eq-itoprocess110}

$$
\d  Y_t = \mu_y_t\,\d  t + \sigma_y_t\,\d  B_y_t\;,
$$ {#eq-itoprocess111}



where $B_x$ and $B_y$ can be different Brownian motions.  The relation between the two Brownian motions is determined by their covariance or correlation.  Given dates $t<u$, we know that both changes $B_x(u)-B_x_t$ and $B_y(u)-B_y_t$ are normally distributed with mean 0 and variance equal to $u-t$.  There will exist a (possibly random) process $\rho$ such that the covariance \index{covariance} of these two normally distributed random variables, given the information at date $t$, is 
$$\E_t \left[\int_t^u \rho_s\,\d  s\right]\; .$$
The process $\rho$ is called the correlation coefficient of the two Brownian motions, \index{correlation coefficient} because when it is constant the correlation of the changes $B_x(u)-B_x_t$ and $B_y(u)-B_y_t$ is
$$\frac{\text{covariance}}{\text{product of standard deviations}}  = \frac{\int_t^u \rho \,\d  s}{\sqrt{u-t} \sqrt{u-t}} = \frac{(u-t)\rho}{u-t} = \rho\; .$$
Moreover, given increasingly fine partitions $0=t_0 < \cdots < t_N=T$ of an interval $[0,T]$ as before, we will have
$$\sum_{i=1}^N \Delta B_x_{t_i} \times \Delta B_y_{t_i} \rightarrow \int_0^T \rho_t\,\d  t$$
as $N \rightarrow \infty$, with probability one.  

We know that
$$\sum _{i=1}^N [\Delta X_{t_i}]^2 \rightarrow \int_0^T \sigma_x^2_t\,\d  t \quad \text{and}\quad  \sum _{i=1}^N [\Delta Y_{t_i}]^2 \rightarrow \int_0^T\sigma_y^2_t\,\d  t\;.
$$ {#eq-itoprocess112}

Furthermore, it can be shown that the sum of products satisfies
$$
\sum_{i=1}^N \Delta X_{t_i} \times \Delta Y_{t_i} \rightarrow \int_0^T \sigma_x_t\sigma_y_t\rho_t\,\d  t\;.
$$ {#eq-itoprocess113}


::: Rule
## 
By adding the rule 
$$
(\d  B_x)(\d  B_y) = \rho\,\d  t 
$$ {#eq-\,\d  B\,\d  B}
 to the rules @eq-\,\d  tsquared--@eq-\,\d  Bsquared, we can compute the limit in @eq-itoprocess113 as

$$
\lim_{N \rightarrow\infty} \sum_{i=1}^N \Delta X_{t_i} \times \Delta Y_{t_i}  = \int_0^T (\d  X)(\d  Y)
$$
$$
= \int_0^T (\mu_x\,\d  t +\sigma_x\,\d  B_x)(\mu_y\,\d  t+\sigma_y\,\d  B_y)
$$
$$
= \int_0^T\sigma_x_t\sigma_y_t \rho_t\,\d  t\;.
$$ {#eq-itojointvariation}


:::


The most general case of Ito's formula that we will need is for a function $Z_t = g(t, X_t, Y_t)$ where $X$ and $Y$ are Ito processes as in @eq-itoprocess110 - @eq-itoprocess111.  In this case, Ito's formula is^[We need to assume $g(t,x,y)$ is continuously differentiable in $t$ and twice continuously differentiable in $(x,y)$ for @eq-itogeneralnew and @eq-itogeneralnew2 to be valid.  Note also that we are using a short-hand notation here.  The partial derivatives of $g$ will generally depend on $t$, $X_t$ and $Y_t$ just as $g$ does.]

$$
Z_t = Z_0 + \int_0^T \frac{\partial g}{\partial t}\,\d  t + \int_0^T \frac{\partial g}{\partial x}\,\d  X_t + \int_0^T \frac{\partial g}{\partial y}\,\d  Y_t 
$$
$$
+ \frac{1}{2} \int_0^T \frac{\partial^2 g}{\partial x^2}\,(\d  X_t)^2 +  \frac{1}{2} \int_0^T \frac{\partial^2 g}{\partial y^2}\,(\d  Y_t)^2 
$$
$$
+  \int_0^T \frac{\partial^2 g}{\partial x\partial y}\,(\d  X_t)( \d  Y_t)\;.
$$ {#eq-itogeneralnew}


In this equation, we apply  @eq-dtsquared--@eq-dB to compute
\begin{align*}
(\d  X_t)^2&= \sigma_x^2_t\,\d  t\; ,\\
(\d  Y_t)^2 &= \sigma_y^2_t\,\d  t\; ,\\
(\d  X_t)( \d  Y_t) &= \sigma_x_t\sigma_y_t\rho_t\,\d  t\;.
\end{align*}
Ito's formula (@eq-itogeneralnew) appears a bit simpler (and easier to remember) if we write it in differential form.  We have:


::: Rule
## 
If $Z_t = g(t, X_t, Y_t)$ where $X$ and $Y$ are Ito processes as in @eq-itoprocess110 - @eq-itoprocess111, then

$$
\d  Z =  \frac{\partial g}{\partial t}\,\d  t + \frac{\partial g}{\partial x}\,\d  X +  \frac{\partial g}{\partial y}\,\d  Y + \frac{1}{2} \frac{\partial^2 g}{\partial x^2}\,(\d  X)^2 +  \frac{1}{2}  \frac{\partial^2 g}{\partial y^2}\,(\d  Y)^2 
$$
$$
+ \frac{\partial^2 g}{\partial x\partial y}\,(\d  X)(\d  Y)\;.
$$ {#eq-itogeneralnew2}



:::


## Examples of Ito's Formula {#sec-s_examples}
The following are the applications of Ito's formula that will be used most frequently in the book.  They follow from the boxed formula at the end of the previous section by taking $g(x,y)=xy$ or $g(x,y)=y/x$ or $g(x)=e^x$ or $g(x) = \log x$.




::: Rule

**Products.**
If $Z=XY$, then $\d  Z=X\,\d  Y+Y\,\d  X + (\d  X)(\d  Y)$.  We can write this as
$$
\frac{\d  Z}{Z}=\frac{\d  X}{X} + \frac{\d  Y}{Y} + \left(\frac{\d  X}{X}\right)\left(\frac{\d  Y}{Y}\right)\;.
$$ {#eq-rule2}


:::




::: Rule

**Ratios.**
If $Z=Y/X$, then 
$$\frac{\d  Z}{Z} = \frac{\d  Y}{Y} -\frac{\d  X}{X} - \left(\frac{\d  Y}{Y}\right)\left(\frac{\d  X}{X}\right) + \left(\frac{\d  X}{X}\right)^2\;.
$$ {#eq-rule4}


:::



::: Rule

**Exponentials.**
If $Z=\mathrm{e}^X$, then 
$$\frac{\d  Z}{Z}=\d  X + \frac{(\d  X)^2}{2}\;.
$$ {#eq-rule5}


:::



::: Rule

**Logarithms.**
If $Z=\log X$, then
$$
\d  Z=\frac{\d  X}{X} - \frac{1}{2}\left(\frac{\d  X}{X}\right)^2\;.
$$ {#eq-rule6}


:::



::: Rule

**Compounding/Discounting.**
Let  
$$Y_t =\exp\left(\int_0^t q_s\,\d  s\right)$$
for some (possibly random) process $q$ and define $Z=XY$ for any Ito process $X$.
The usual calculus gives us 
$\d  Y_t=q_tY_t\,\d  t$,
and the product rule above implies
$$
\frac{\d  Z}{Z}=q\,\d  t + \frac{\d  X}{X}\;.
$$ {#eq-compdisc1}

This is the same as in the usual calculus.  

:::




## Reinvesting Dividends {#sec-s_reinvestingdividends}

Frequently, we will assume that the asset underlying a derivative security pays a constant dividend yield, \index{dividend yield} which we will denote by $q$.  This means, for an asset with price $S_t$, that the dividend in an instant $\d  t$ is $q S_t\,\d  t$.  If the dividends are reinvested in new shares, the number of shares will grow exponentially at rate $q$.  To see this, consider the portfolio starting with a single share of the asset and reinvesting dividends until some date $T$.  Let $X_t$ denote the number of shares resulting from this strategy at any time $t\leq T$.  Then the dividend received at date $t$ is $q S_tX_t\,\d  t$, which can be used to purchase $q X_t\,\d  t$ new shares.  This implies that $\d  X_t=q X_t\,\d  t$, or $\d  X_t/\d  t = q X_t$, and it is easy to check (and very well known) that this equation is solved by $X_t=\mathrm{e}^{q t}X_0$.  In our case, with $X_0=1$, we have $X_t=\mathrm{e}^{q t}$.

The dollar value of the trading strategy just described will be $X_tS_t = \mathrm{e}^{q t}S_t$.  Denote this by $V_t$.  This is the value of a non-dividend-paying portfolio, because all dividends are reinvested.  From the Compounding/Discounting example in @sec-s_examples, we know that
$$ 
\frac{\d  V}{V} = q\,\d  t + \frac{\d  S}{S}\;.
$$ {#eq-reinvestingdividends}

This means that the rate of return on the portfolio is the dividend yield $q\,\d  t$ plus the return $\d  S/S$ due to capital gains.


## Geometric Brownian Motion {#sec-s_geometricbrownianmotion}
A random variable is lognormally distributed if it can be written as $\tilde{y}=  e^{\tilde{x}}$ where $\tilde{x}$ is distributed according to a normal distribution with mean $m$ and standard deviation $s$.  The expected value of $\tilde{y}$ is given by $\E[\tilde{y}] = e^{m+\frac{s^2}{2}}$.

::: Rule

**Lognormal Random Variable.**\;
If $\tilde{x}$ is normally distributed with mean $m$ and standard deviation $s$, then $e^{\tilde{x}}$ is lognormally distributed and
$$\E[e^{\tilde{x}}]=e^{m + \frac{1}{2} s^2};.
$$ {#eq-lognormal}


:::

An important stochastic process is geometric Brownian motion given by
$$
S_t=S_0\exp\left(\mu t- \sigma^2 t/2 + \sigma B_t\right)
$$ {#eq-exponential1}

for constants $\mu$ and $\sigma$, where $B$ is a Brownian motion.  Note that for each time $t$, the random variable $S_t$ in @eq-exponential is a lognormal random variable. Using the product rule and the rule for exponentials, we obtain
$$
\frac{\d  S}{S} = \mu\,\d  t+\sigma\,\d  B\;.
$$ {#eq-Y}

When we see an equation of the form @eq-Y, we should recognize @eq-exponential1 as the solution. 

The process $S$ is called a geometric Brownian motion.  \index{geometric Brownian motion} In keeping with the discussion of @sec-s_itoprocesses, we interpret @eq-Y as stating that $\mu\,\d  t$ is the expected rate of change of $S$ and $\sigma^2\,\d  t$ is the variance of the rate of change in an instant $\d  t$.  We call $\mu$ the drift and $\sigma$ the volatility.  \index{volatility} The geometric Brownian motion will grow at the average rate of $\mu$, in the sense that $\E[S_t] = \mathrm{e}^{\mu t}S_0$;  one way to verify this uses the formula for the mean of a lognormal random variable.

Taking the natural logarithm of @eq-exponential1 gives an equivalent form of the solution:
$$
\log S_t= \log S_0+\left(\mu -\frac{1}{2}\sigma^2\right)t + \sigma B_t\;.
$$ {#eq-exponential2}
  This shows that $\log S_t - \log S_0$ is a $(\mu-\sigma^2/2,\sigma)$--Brownian motion.  Given information at time $t$, the logarithm of $S(u)$ for $u>t$ is normally \index{lognormal distribution}distributed with mean $(u-t)(\mu-\sigma^2/2)$ and variance $(u-t)\sigma^2$.  Because $S$ is the exponential of its logarithm, $S$ can never be negative.  For this reason, a geometric Brownian motion is a better model for stock prices than is a Brownian motion.

The differential of @eq-exponential2 is
$$
\d  \log S_t = \left(\mu -\frac{1}{2}\sigma^2\right)\,\d  t+ \sigma\,\d  B_t\;.
$$ {#eq-exponential3}

We conclude:

::: Rule

The  equation 
$$\frac{\d  S}{S} = \mu\,\d  t+\sigma\,\d  B$$
is equivalent to the equation
$$\d  \log S = \left(\mu -\frac{1}{2}\sigma^2\right)\,\d  t+ \sigma\,\d  B\; .$$
The solution of both equations is @eq-exponential1 or the equivalent @eq-exponential2.

:::



Over a discrete time interval $\Delta t$, @eq-exponential3 implies that the change in the logarithm of $S$ is 
$$
\Delta \log S = \left(\mu -\frac{1}{2}\sigma^2\right)\Delta t+ \sigma\,\Delta B\;.
$$ {#eq-exponential11}

If $S$ is the price of a non-dividend-paying asset, then over the time period $t_{i-1}$ to $t_i$, with $t_i-t_{i-1}=\Delta t$, we have
$$
\Delta \log S = r_i\,\Delta t\;,
$$ {#eq-exponential10}

where $r_i$ is the  continuously compounded annualized rate of return \index{continuously compounded return} during the period $\Delta t$.  This follows from the definition of the continuously compounded rate of return as the constant rate over the time period $\Delta t$ that would cause $S$ to grow (or fall) from $S_{t_{i-1}}$ to $S_{t_i}$.  To be precise, $r_i$ is defined by
$$\frac{S_{t_i}}{S_{t_{i-1}}} = \mathrm{e}^{r_i\Delta t}\; ,$$
which is equivalent to @eq-exponential10.
Thus, the geometric Brownian motion model (@eq-Y)implies that the continuously compounded annualized rate of return over a period of length $\Delta t$ is given by
$$r_i = \mu -\frac{1}{2}\sigma^2+ \frac{\sigma\Delta B}{\Delta t}\; .$$
This means that $r_i$ is normally distributed with mean $\mu-\sigma^2/2$ and variance $\sigma^2/\Delta t$.  Given historical data on the rates of return, the parameters $\mu$ and $\sigma$ can be estimated by standard methods (see @sec-c_stochasticvolatility).

We can simulate a path of $S$ by simulating the changes $\Delta \log S$.  The random variable $\sigma \Delta B$  in  @eq-exponential11 has a normal distribution with zero mean and variance equal to $\sigma^2\Delta t$.  We simulate it as $\sigma\sqrt{\Delta t}$ multiplied by a standard normal.  The code below simulates $n=10000$ paths with $m=1000$ time steps. There are some features of the simulation which will prove useful later.  The drift $\mu$ is labelled the interest rate $r=0.1$.  Other parameters are $\sigma = 0.2$, and $T=0.5$.  The drift of the log stock price is labelled $drift=r-\frac{\sigma^2}{2}$.  The plot output is one of the simulated sample paths.  In practice, if we are only interested in the terminal value of the stock price we would use many fewer subdivisions, $n=1$.  Given a simulated mean zero normal random variable, $z$, changing the sign to $-z$ is also a simulated normal random variable with zero mean and the same standard deviation.  As a result, we have two simulations for the stock price labelled $St$ and $St1$, but we only plot one sample path for $St$. 

```{python}
"""
# Simulate geometric Brownian motion
import numpy as np
import matplotlib.pyplot as plt
# number of paths
n = 10000
#number of divisions
m = 1000
# Interest rate (We set the drift equal to the interest rate)
r = 0.1
# Volatility
sig = 0.2
# Initial Stock Price
S0 = 42
# Maturity
T = 0.5
# Delta t
dt = T/m
# Drift
drift = (r-0.5*sig**2)
# Volatility
vol = sig * np.sqrt(dt)

t = np.array(range(0,m + 1,1)) * dt

# seed for random generator
seed= 2020
# define a random generator
np.random.seed(seed)
inc = np.zeros(shape = (m + 1, n))
inc[1:] = np.transpose(np.random.normal(loc = 0, scale = vol,size = (n,m)))
St = np.zeros(shape = (m + 1, n))
St = S0 * np.exp(np.cumsum(inc,axis=0) + (drift * t[0:m + 1])[:,None])
St1 = S0 * np.exp(-np.cumsum(inc,axis=0) + (drift * t[0:m + 1])[:,None])
plt.figure(figsize=(9,6))
plt.plot(t,St[:,1])
"""



```
The plot below is the distribution of the simulated stock price at $T$.
```{python}
"""
plt.figure(figsize=(9,6))
a=plt.hist(St[m,:], bins=100)
"""
```




While geometric Brownian motion is an important stochastic process to model stock prices, the process with drift equal to zero given by
$$X_t = \exp\left(-\frac{\kappa^2}{2} + \kappa B_t\right)$$

satisfies $\E[X_t]=1$ and $\E[X_t|X_s]=X_s$ and is an important example of a strictly positive martingale.  Again, these facts can be verified using the formula for the expected value of a lognormal random variable.  Notice that we can write
$$\,\d  X_t= \kappa X_t \,\d  B_t\;,$$
which agrees with the martingale characterization of $\int_0^t \sigma(X_t,t) \,\d  B_t$.



## Volatilities {#sec-s_volatilities}

As mentioned in @sec-s_geometricbrownianmotion, when we encounter an equation of the form 
$$\frac{\d  S}{S} = \mu\,\d  t + \sigma\,\d  B$$
where $B$ is a Brownian motion, we will say  $\sigma$ is the volatility of $S$.   We will occasionally need to compute the volatilities of products or ratios of random processes.  These computations follow directly from Ito's formula.

Suppose 
$$\frac{\d  X}{X} = \mu_x\,\d  t + \sigma_x\,\d  B_x \qquad \text{and} \qquad 
\frac{\d  Y}{Y} = \mu_y\,\d  t + \sigma_y\,\d  B_y\; ,$$
where $B_x$ and $B_y$ are Brownian motions with correlation $\rho$, and $\mu_x$, $\mu_y$, $\sigma_x$, $\sigma_y$, and $\rho$ may be quite general random processes.  

### Products
If $Z=XY$, then @eq-rule2 gives us
$$
\frac{\d  Z}{Z} = (\mu_x+\mu_y+\rho\sigma_x\sigma_y)\,\d  t + \sigma_x\,\d  B_x + \sigma_y\,\d  B_y\;.
$$ {#eq-volproduct1}

The instantaneous variance of $\d  Z/Z$ is calculated, using the rules for products of differentials, as
\begin{align*}
\left(\frac{\d  Z}{Z}\right)^2 &= (\sigma_x\,\d  B_x + \sigma_y\,\d  B_y)^2\\
&= (\sigma_x^2 + \sigma_y^2 + 2\rho\sigma_x\sigma_y)\,\d  t\;.
\end{align*}
As will be explained below, the volatility is the square root of the instantaneous variance (dropping the $\d  t$).  This implies:

::: Rule
## 
The volatility of $XY$ is
$$
\sqrt{\sigma_x^2 + \sigma_y^2 + 2\rho\sigma_x\sigma_y}\;.
$$ {#eq-volatilityproduct}

:::



### Ratios
If $Z=Y/X$, then @eq-rule4 gives us
$$
\frac{\d  Z}{Z} = (\mu_y-\mu_x-\rho\sigma_x\sigma_y+\sigma_x^2)\,\d  t + \sigma_y\,\d  B_y - \sigma_x\,\d  B_x\;.
$$ {#eq-ratioproduct1}

The instantaneous variance of $\d  Z/Z$ is therefore
\begin{align*}
\left(\frac{\d  Z}{Z}\right)^2 &= (\sigma_y\,\d  B_y - \sigma_x\,\d  B_x)^2\\
&= (\sigma_x^2 + \sigma_y^2 - 2\rho\sigma_x\sigma_y)\,\d  t\;.
\end{align*}
This implies:

::: Rule
## 
The volatility of $Y/X$ is  
$$
\sqrt{\sigma_x^2 + \sigma_y^2 - 2\rho\sigma_x\sigma_y}\;.
$$ {#eq-volatilityratio}

:::



::: Extra
To understand why taking the square root of $(\d  Z/Z)^2$ (dropping the $\d  t$) gives the volatility, consider for example the product case $Z=XY$.  Define a random process $B$ by $B_0=0$ and 
$$
\d  B = \frac{\sigma_x}{\sigma}\,\d  B_x + \frac{\sigma_y}{\sigma}\,\d  B_y\;,
$$ {#eq-foreign\,\d  B}

where $\sigma$ is the volatility defined in @eq-volatilityproduct.
Then we can write  @eq-volproduct1 as
$$
\frac{\d  Z}{Z} = \left(\mu_x +\mu_y+ \rho\sigma_x\sigma_y\right)\,\d  t + \sigma\,\d  B\;.$$ {#eq-volproduct2}

From the discussion in @sec-s_itoprocesses, we know that $B$ is a continuous martingale.  We can compute its quadratic variation from
\begin{align*}
(\d  B)^2 &= \left(\frac{\sigma_x\,\d  B_x + \sigma_s\,\d  B_s}{\sigma}\right)^2\\
&= \frac{(\sigma_x^2 + \sigma_s^2 + 2\rho\sigma_x\sigma_s)\,\d  t}{\sigma^2}\; ,\\
&= \d  t\;.
\end{align*}
By Levy's theorem (see @sec-s_quadraticvariation), any continuous martingale with this quadratic variation is necessarily a Brownian motion.  Therefore,  @eq-volproduct2 shows that $\sigma$ is the volatility of $Z$ as defined at the beginning of the section.
:::

## {.unnumbered}


::: Exercise
 Consider a discrete partition $0=t_0 < t_1 < \cdots t_N=T$ of the time interval $[0,T]$ with $t_i - t_{i-1} = \Delta t = T/N$ for each $i$.  Consider the function 
$$X_t=\mathrm{e}^t\; .$$
Write a code, which computes and plots $\sum_{i=1}^N [\Delta X_{t_i}]^2$, where 
$$\Delta X_{t_i} = X_{t_i}-X_{t_{i-1}} = \mathrm{e}^{t_i} - \mathrm{e}^{t_{i-1}}\; .$$
:::
::: Exercise
 Repeat the previous problem for the function $X_t = t^3$.  In both this and the previous problem, what happens to $\sum_{i=1}^N [\Delta X_{t_i}]^2$ as $N \rightarrow \infty$?
:::
::: Exercise
 Either use the code provided or write a code to compute $\sum_{i=1}^N [\Delta B_{t_i}]^2$, where $B$ is a simulated Brownian motion.  For a given $T$, what happens to the sum as $N \rightarrow \infty$?  
:::
::: Exercise
 Repeat the previous problem to compute $\sum_{i=1}^N [\Delta B_{t_i}]^3$, where $B$ is a simulated Brownian motion.  For a given $T$, what happens to the sum as $N \rightarrow \infty$?  
:::
::: Exercise
 Repeat the previous problem, computing instead $\sum_{i=1}^N |\Delta B_{t_i}|$ where $| \cdot |$ denotes the absolute value.  What happens to this sum as $N \rightarrow \infty$?
:::
::: Exercise
Use Ito's Lemma to derive the stochastic differential equation for $S_t^2$.  Argue that $S_t^2$ is geometric Brownian motion and find $\E[S_t^2]$.
::: 
::: Exercise
Ito's Lemma can be used in different ways to get the same answer.  For example, let $X_t = a t + b B_t$ and use Ito's lemma on the function $e^{X_t}$.  Alternatively, let $f(t, B_t) = e^{a t + bB_t}$.  Use Ito's lemma on $f(,)$.
::: 
::: Exercise 
Use the facts $e^{x+y}=e^x \times e^y$ and $\frac{e^x}{e^y} = e^{x-y}$ to deduce the drift and volatility of the product and ratio of two geometric Brownian motions.
::: 
::: Exercise
 Consider a discrete partition $0=t_0 < t_1 < \cdots t_N=T$ of the time interval $[0,T]$ with $t_i - t_{i-1} = \Delta t = T/N$ for each $i$.  Consider a geometric Brownian motion
$$\frac{\d  Z}{Z} = \mu\,\d  t + \sigma\,\d  B\; .$$
An approximate path $\tilde{Z}_t$ of the geometric Brownian motion can be simulated as
$$
\Delta \tilde{Z}_{t_i} = \tilde{Z}_{t_{i-1}} \big[ \mu\,\Delta t + \sigma\,\Delta B\big]\;.
$$ {#eq-exponential111}
Modify the code to generate both a path $Z_t$ and an approximate path $\tilde{Z}_t$ according to @eq-exponential111, using the same $\Delta B$  for both paths and taking $\tilde{Z}_0 = Z_0$.  Plot both paths in the same figure.  How well does the approximation work for large $N$?   Warning:  
For $N$ larger than about $100 T$, the approximation will look perfect---you won't be able to tell that there are two plots in the figure.  One reason this is true is an exact formula is 
$$
 Z_{t_i} = Z_{t_{i-1}} \exp\left[ \left(\mu -\frac{\sigma^2}{2}\right)\,\Delta t + \sigma\,\Delta B\right]\;.
$$ {#eq-exponential112}
and using Taylor's Theorem for small $\Delta t$, $e^{\left(\mu-\frac{\sigma^2}{2}\right) \Delta t} \approx 1+ \left(\mu-\frac{\sigma^2}{2}\right) \Delta t$ and $e^{\sigma \Delta B_t} \approx 1+ \sigma \Delta B_t +\frac{1}{2}\sigma^2 (\Delta B_t)^2$ and $(\,\d  B_t)^2=\Delta t$.
:::
::: Exercise
Use simulation to find  $\E^*[e^{-r T}{\mathbf{1}}_{\{S_t \ge K\}}]$ in the risk-neutral probability where
\begin{equation*}
\,\d  S_t= r S_t \,\d  t + \sigma S_t \,\d  B_t^*
\end{equation*}
Verify that $S_t/e^{r t}$ is a martingale in the $*$ measure where $B^*$ is a Brownian motion.
Then use simulation to find $S_0\E^S[\frac{1}{S_t} {\mathbf{1}}_{\{S_t \ge K\}}]$ in the pricing measure which uses the share as numeraire where 
\begin{equation*}
\,\d  S_t = (r + \sigma^2) S_t \,\d  t + \sigma S_t \,\d  B_t^S
\end{equation*}
so the log satisfies
\begin{equation*}
\log(S_t) = \log(S_0) + (r + \frac{\sigma^2}{2})t + \sigma B_t^S
\end{equation*}
You should verify $e^{rt}/S_t$ is a martingale in the $S$ measure where $B^S$ is a Brownian motion.
Both estimates should be the same up to simulation error and give the time zero value of the random payoff ${\mathbf{1}}_{\{S_t \ge K\}}$ which is a random variable equal to $1$ if $S_t\ge K$ and $0$ otherwise.  You should choose the values for $r$, $\sigma$, $T$, and $K$.
::: 


