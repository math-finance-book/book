{{< include macros.qmd >}}

# Ito's Formula {#sec-c_ito}

We use the changes of a Brownian motion to model randomness.  We build other stochastic processes using those changes.  The general idea is
$$\text{change} = \text{mean} + \text{std dev} \times \text{change in Brownian motion}\,.$$
The mathematical foundations for our construction were created by K. Ito.  The key concepts are the Ito integral, Ito processes, and Ito's formula (also called Ito's lemma).  Using these foundations, we can build quite general processes from changes in Brownian motions, including processes with non-normal distributions.

## Examples {#sec_f_discrete}

We begin with some simple examples.  Consider a discrete partition of a time interval:
$$0=t_0 < t_1< \cdots < t_{n-1} < t_n=t$$
with equally spaced times.  Let $\Delta t$ denote the difference between successive times.  

First, let's drop the randomness entirely.  Consider the equation
$$X_{t_i} -  X_{t_{i-1}} = \mu X_{t_{i-1}}\Delta t$$ {#eq-ito_discrete_1}
for a constant $\mu$.  Thus, we have "change $\,=\,$ mean," where the mean is proportional to the previous value with proportionality factor $\mu \Delta t$.  @fig-discrete-interest presents a plot of $X$, for particular values of $X_0$, $\mu$, and $\Delta t$.

If we increase $n$, making $\Delta t$ smaller, then $X$ will converge to the solution of the ordinary differential equation
$$\d X_t = \mu X_t\,\d t\,.$$ {#eq-ito_discrete_2}
@eq-ito_discrete_2 has a known solution, which is 
$$X_t = X_0 \e^{\mu t}\,.$$ {#eq-ito_discrete_3}
To verify this, we only need to differentiate $X$ defined in @eq-ito_discrete_3:
$$\frac{\d X_t}{\d t} = \mu X_0 \e^{\mu t} = \mu X_t\,.$$
The function presented in @eq-ito_discrete_3 is also shown in @fig-discrete-interest.

::: Extra

To see how one might guess that @eq-ito_discrete_3 is the solution of @eq-ito_discrete_2, we can examine the logarithm of $X$.  A general rule gives us $\d \log X = \d X / X$, so $\d \log X = \mu \d t$.  We can integrate both sides of this to obtain $\log X_t - \log X_0 = \mu t$.  Now, rearranging and exponentiating gives $X_t = X_0e^{\mu t}$.  We will eventually follow similar steps to see that @eq-ito_discrete_6 is the solution of @eq-ito_discrete_5.
:::

```{python}
#| label: fig-discrete-interest
#| fig-cap: The functions $X$ satisfying @eq-ito_discrete_1 and @eq-ito_discrete_3 for X0 = 1, mu = 1, and Delta t = 0.1.

import numpy as np 
import plotly.graph_objects as go 
fig = go.Figure()
fig.update_layout(
    xaxis_title='Time',
    yaxis_title='Binomial Process',
    template='plotly_white',
    height=300,
)
fig.show()
```

Now, let's include randomness.  Let's make the noise proportional to the value of $X$,  So, let $B$ be a standard Brownian motion and consider the equation
$$X_{t_i} - X_{t_{i-1}} = \mu X_{t_{i-1}}\Delta t + \sigma X_{t_{i-1}} \Delta B_{t_i}$$ {#eq-ito_discrete_4}
where $\sigma$ is another constant, and $\Delta B_{t_i} = B_{t_i} - B_{t_{i-1}}$.  A solution $X$ of this equation will have random paths, due to the random noise $\Delta B_{t_i}$.  An example of a path is shown in @fig-discrete-random.
Ito showed how we can take the limit of this equation as we make $\Delta t$ smaller and make sense of the equation
$$
\d X_t = \mu X_t\,\d t + \sigma X_t \,\d B_t\,.
$$ {#eq-ito_discrete_5}
The solution $X$ of @eq-ito_discrete_5 is
$$X_t = \e^{(\mu  - \sigma^2/2)t + \sigma B_t}\,.$$ {#eq-ito_discrete_6}
An approximate path of this process $X$ is also shown in @fig-discrete-random.  It is generated by taking $\Delta t$ very small, just as we generated approximate paths of Brownian motions in @sec-c_brownian.  We can show that $X$ defined in @eq-ito_discrete_6 satisfies @eq-ito_discrete_5 by differentiating, as we showed that $X$ defined in @eq-ito_discrete_3 satisfies @eq-ito_discrete_2.  However, we first need to explain Ito's formula, which is a formula for differentiating functions of Brownian motions and, more generally, functions of Ito processes.

```{python}
#| label: fig-discrete-random
#| fig-cap: Paths of the processes satisfying @eq-ito_discrete_4 and @eq-ito_discrete_6 for X0 = 1, mu = 1, Delta t = 0.1, and sigma = 1.

import numpy as np 
import plotly.graph_objects as go 
fig = go.Figure()
fig.update_layout(
    xaxis_title='Time',
    yaxis_title='Binomial Process',
    template='plotly_white',
    height=300,
)
fig.show()
```

The functions and processes $X$ defined in this section have important interpretations.  @eq-ito_discrete_1 can be rewritten to say that the percent change in $X$ is $\mu \Delta t$.  This could represent the value of a savings account that earns interest of $\mu \Delta t$ in each period of length $\Delta t$.  This is the common way of calculating, for example, monthly interest, where $\mu$ is called the annual rate of interest and $\Delta t$ would be $1/12$.  The limiting @eq-ito_discrete_3 is called continuous compounding of interest.

Similarly, @eq-ito_discrete_4 can be rewritten to say that the percent change in $X$ is $\mu \Delta t + \sigma \Delta B$.  This represents a random rate of return -- for example, the return of a stock.  The expected rate of return in this case is $\mu \Delta t$, and the variance of the rate of return is $\sigma^2 \Delta t$.  The limiting @eq-ito_discrete_3 is called continuous compounding of returns.



## Ito Processes {#sec-s_itoprocesses}

The meaning of @eq-ito_discrete_2 is that, for all $t  > 0$,
$$X_t = X_0 +  \int_0^t \mu X_u \d u\,.$$
We assume the reader is familiar with integrals, so we do not explain this further.  The function of time $X$ defined in @eq-ito_discrete_3 satisfies this equation.  Similarly, the meaning of @eq-ito_discrete_5 is that, for all $t > 0$,
$$X_t = X_0 +  \int_0^t \mu X_u \d u + \int_0^t \sigma X_u \d B\,.$$
The first integral in this formula is an ordinary integral.  The second is an Ito integral, which is to be explained.  The sum of an ordinary integral and an Ito integral is called an Ito process.  An Ito process always has continuous paths. 

Let's depart from the example of the previous section and consider a process $X$ satisfying, for all $t>0$,
$$X_t = \int_0^t \alpha_s\d s + \int_0^t \theta_s \d B_s\,.$${#eq-ito1}
where $\alpha$ and $\theta$ can be stochastic processes.  The example of the previous section fits this form, because we could take $\alpha_s = \mu X_s$ and $\theta_s = \sigma X_s$.  The definition of the Ito integral
$$\int_0^t \theta_s \d B_s$$
is relatively complicated.  It is enough for our purposes to know that it can be approximated by a  discrete sum
$$\sum_{i=1}^n \theta_{t_{i-1}}(B_{t_i} - B_{t_{i-1}})\,,$$
given a partition
$$ 0 = t_0 < \cdots < t_n = t\,,$$
when $n$ is large and the time between successive dates is small.  The Ito integral exists provided $\theta$ does not anticipate the future (so $\theta_{t_{i-1}}$ is independent of the increment $B_{t_i}- B_{t_{i-1}}$) and provided $\theta$ does not explode to $\pm \infty$ in finite time, so 
$$\int_0^t \theta_s^2 \d s < \infty$$
for all $t > 0$, with probability one.

We also write @eq-ito1 as
$$
\d X_t = \alpha_t\d t + \theta_t \d B_t\,. 
$${#eq-ito2}
We interpret $\d X$ as "mean $+$ noise" with $\alpha_t \d t$ being the mean and $\theta_t\d B_t$ being the mean-zero random part.    The quantity $\alpha_t$  is also called the drift of the process $X$ at time $t$.   \index{drift} The coefficient $\sigma_t$ is called the diffusion coefficient of $X$ at time $t$.  \index{diffusion coefficient}
If $\alpha$ and $\theta$ are constant, it is standard to refer to an Ito process $X$ as a $(\alpha,\theta)$--Brownian motion.  When they are constant, we obtain
$$X_t= X_0 + \alpha t + \theta B_t\,.$$

An Ito process as in @eq-ito1 can be a martingale only if $\alpha=0$.  This should seem sensible, because $\alpha\d  t$ is the expected change in $X$, and a process is a martingale only if its expected change is zero.   This observation plays a fundamental role in deriving asset pricing formulas.  Conversely, if $\alpha=0$ and 
$$
\E \left[\int_0^t \theta^2_s\,\d  s\right] < \infty
$$ {#eq-regularity1}

for each $t$, then the Ito process is a continuous martingale, and the variance of its date--$t$ value, calculated with the information available at date $0$, is:
$$\mathrm{var}(X_t) = \E \left[\int_0^t \theta^2_t\d  s\right]\; .$$  

## Quadratic Variation of an Ito Process

The quadratic variation of the Ito process $X$ defined in @eq-ito2 through each date $t$ is 
$$
\int_0^t \theta^2_s\d  s
$$ 
with probability one.  In fact, when @eq-regularity1 holds, a somewhat more precise definition of the stochastic integral is the (unique) martingale with quadratic variation given by @eq-itoquadraticvariation.

To compute the quadratic variation of an Ito process, we use the following simple and important rules (for the sake of brevity, we drop the subscript $t$ from $B_t$ here and sometimes later).  These rules should be regarded as mnemonic devices.  The calculations we will do with them lead to the correct results, but the objects have no real mathematical meaning.

::: Rule
## 


$$
(\d  t)^2 = 0\;, 
$$ {#eq-dtsquared}

$$
(\d  t)(\d  B) =0\;, 
$$ {#eq-dB}

$$
(\d  B)^2 =\d  t\;. 
$$ {#eq-dBsquared}



:::


We apply these rules to compute the quadratic variation of $X$ as follows:

::: Rule
## 
If $\d  X = \alpha\,\d  t + \theta\,\d  B$ for a Brownian motion $B$, then
\begin{align*}
(\d  X)^2 &= (\alpha\,\d  t+\theta\,\d  B)^2\\
&= \alpha^2(\d  t)^2 + 2\alpha\theta(\d  t)(\d  B) + \theta^2(\d  B)^2\\
&= \theta^2\,\d  t\;.
\end{align*}
:::

We integrate $(\d X)^2$ over a time interval to compute the quadratic variation of $X$ over that period as:^[In a more formal mathematical presentation, one normally writes $\d \langle X,X\rangle$ for what we are writing here as $(\d  X)^2$.  This is the differential of the quadratic variation process, and the quadratic variation through date $T$ is
$$
\langle X,X\rangle _t = \int_0^T \d \langle X,X\rangle_t = \int_0^T \sigma^2_t\,\d  t\;.
$$]
$$
\int_0^t (\d  X_s)^2 = \int_0^t \theta^2_s\,\d  s\;.
$$ {#eq-itoquadraticvariation2}




## Ito's Formula {#sec-s_itosformula}

First we recall some facts of the ordinary calculus.  If $y=g(x)$ and $x = f_t$ with $f$ and $g$ being continuously differentiable functions, then 
$$\frac{\d  y}{\d  t} = \frac{\d  y}{\d  x}\times \frac{\d  x}{\d  t} = g'(x_t)f'_t\; .$$
Over a time period $[0,T]$, this implies that
$$y_t = y_0 + \int_0^T \frac{\d  y}{\d  t}\,\d  t = y_0 + \int_0^T g'(x_t)f'_t\,\d  t\; .$$
Substituting $\d  x_t = f'_t\,\d  t$, we can also write this as
$$
y_t = y_0 + \int_0^T g'(x_t)\,\d  x_t\;.
$$ {#eq-ordinarycalculus}


We can contrast  @eq-ordinarycalculus  with a special case of Ito's formula for the calculus of Ito processes (the more general formula will be discussed in the next section).  If $B$ is a Brownian motion and $Y = g(B)$ for a twice-continuously differentiable function $g$, then \index{Ito's formula}
$$
Y_t = Y_0 + \int_0^T g'(B_t)\,\d  B_t + \frac{1}{2}\int_0^T g''(B_t)\,\d  t\;.
$$ {#eq-itonew1}

Thus, relative to the ordinary calculus, Ito's formula has an extra term involving the second derivative $g''$.  We can write @eq-itonew1 in differential form as
$$\,\d  Y_t = \frac{1}{2}g''(B_t)\,\d  t + g'(B_t)\,\d  B_t.$$
Thus, $Y=g(B)$ is an Ito process with drift $g''(B_t)/2$ and diffusion coefficient $g'(B_t)$.

To gain some intuition for the extra term in Ito's formula, we return to the ordinary calculus.  Given dates $t<u$, the derivative defines a linear approximation of the change in $y$ over this time period; i.e., setting $\Delta x = x(u)-x_t$ and $\Delta y = y(u) - y_t$, we have the approximation
$$\Delta y \approx g'(x_t) \,\Delta x\; .$$
A better approximation is given by the second-order Taylor series expansion
$$\Delta y \approx g'(x_t)\,\Delta x + \frac{1}{2} g''(x_t)\,[\Delta x]^2\; .$$
An interpretation of  @eq-ordinarycalculus is that the linear approximation works perfectly for infinitesimal time periods $\d  t$, because we can compute the change in $y$ over the time period $[0,T]$ by summing up the infinitesimal changes $g'(x_t)\,\d  x_t$.  In other words, the second-order term $\frac{1}{2} g''(x_t)\,[\Delta x]^2$ vanishes when we consider very small time periods.

The second-order Taylor series expansion in the case of $Y=g(B)$ is 
$$\Delta Y \approx g'(B_t)\,\Delta B + \frac{1}{2} g''(B_t)\,[\Delta B]^2\; .$$
For example, given a partition $0=t_0 < t_1 < \cdots < t_N=T$ of the time interval $[0,T]$, we have, with the same notation we have used earlier,

$$
Y_t = Y_0 + \sum_{i=1}^N \Delta Y_{t_i}  
$$
$$
\approx Y_0 + \sum_{i=1}^N g'(B_{t_{i-1}})\,\Delta B_{t_i} + \frac{1}{2} \sum_{i=1}^N g''(B_{t_{i-1}})\,[\Delta B_{t_i}]^2\;.
$$ {#eq-itonew2}


If we make the time intervals $t_i-t_{i-1}$ shorter, letting $N \rightarrow \infty$, then we cannot expect that the extra term here will disappear, leading to the result  of the ordinary calculus shown in@eq-ordinarycalculus, because we know that
$$\lim_{N \rightarrow \infty} \sum_{i=1}^N [\Delta B_{t_i}]^2 = T\; ,$$
whereas for the continuously differentiable function $x_t = f_t$, the same limit is zero.  In fact it seems sensible to interpret the limit of $[\Delta B]^2$ as $(\d  B)^2 =\d  t$.
This is perfectly consistent with Ito's formula: if we take the limit in @eq-itonew2, replacing the limit of $[\Delta B_{t_i}]^2$ with $(\d  B)^2 = \d  t$, we obtain @eq-itonew1.

The code below defines a function $g(x)=e^{x}$ ($g'(x)=e^x$ and $g''(x) = e^x$) and simulates the value $e^{B_t}$ in two ways.  The first way is to simulate the Ito expansion
$$e^{B_t}=1 + \int_0^t e^{B_s} d B_s + \frac{1}{2}\int_0^t e^{B_s} ds$$
using the discretization
$$\Delta e^{B_t}= e^{B_t} \Delta B_t + \frac{1}{2} e^{B_t} \Delta t $$
```{python}
#| label: simulated_ito
#| fig-cap: "Simulated Ito Formula"

"""
import numpy as np

n = 1000
m = 1

# Define a function and its first and second derivative
G = lambda x: np.exp(x)
DG = lambda x: np.exp(x)
DDG = lambda x: np.exp(x)
# Build G'(x)\,\d  B
GdB = np.zeros(shape = (n, m))
GdB[0] = np.repeat(DG_0, m) * inc[0]
GdB[1:] = DG(Bt[0:n - 1]) * inc[1:]
SI = np.zeros(shape = (n, m))
# Stochastic Integral is cumulative sum of G'(B)dB plus initial
SI = GdB.cumsum(axis = 0) + 0.5 * (DDG(Bt[0:n])*Q).cumsum(axis =0) + G_0
# Compare Ito's Lemma 
plt.figure(figsize=(9,6))
plt.plot(t[0:n], SI[:,0])
"""
```
Below is the exact simulated solution $e^{B_t}$.  It is almost impossible to see a difference.
```{python}
#| label: simulated_exact
#| fig-cap: "Simulated Exact Solution"
#exact solution
"""
plt.figure(figsize=(9,6))
plt.plot(t[0:n], G(Bt[1:n + 1, 0]))
"""
```
Below we plot the $\int_0^t \frac{1}{2} g''(B_s) ds$ term.  Without this term the two plots above will not match.

```{python}
#| label: correction
#| fig-cap: "Second Derivative Term in Ito's Formula"
"""
QVV = np.zeros(shape = (n, m))
QVV = 0.5*(DDG(Bt[0:n]) * Q).cumsum(axis = 0)
plt.figure(figsize=(9,6))
plt.plot(t[0:n], QVV[:,0])
"""
```

To see the accuracy of Ito's approximation over different amounts of subdivisions, as well as the impact of the second derivative term $\int_0^t (1/2)g''(B_s)ds$, we encourage readers to interact with the plot below.

::: {#fig-interactive_ito}
<iframe width="780" height="1000" src="https://derivatives-book-26ac36570fb8.herokuapp.com/math_finance_book_plots/ito_approx_plot"></iframe>

Accuracy of Ito's approximation
:::


## Multiple Ito Processes

Now consider two Ito processes


$$
\d  X_t = \mu_x_t\,\d  t + \sigma_x_t\,\d  B_x_t\;,
$$ {#eq-itoprocess110}

$$
\d  Y_t = \mu_y_t\,\d  t + \sigma_y_t\,\d  B_y_t\;,
$$ {#eq-itoprocess111}



where $B_x$ and $B_y$ can be different Brownian motions.  The relation between the two Brownian motions is determined by their covariance or correlation.  Given dates $t<u$, we know that both changes $B_x(u)-B_x_t$ and $B_y(u)-B_y_t$ are normally distributed with mean 0 and variance equal to $u-t$.  There will exist a (possibly random) process $\rho$ such that the covariance \index{covariance} of these two normally distributed random variables, given the information at date $t$, is 
$$\E_t \left[\int_t^u \rho_s\,\d  s\right]\; .$$
The process $\rho$ is called the correlation coefficient of the two Brownian motions, \index{correlation coefficient} because when it is constant the correlation of the changes $B_x(u)-B_x_t$ and $B_y(u)-B_y_t$ is
$$\frac{\text{covariance}}{\text{product of standard deviations}}  = \frac{\int_t^u \rho \,\d  s}{\sqrt{u-t} \sqrt{u-t}} = \frac{(u-t)\rho}{u-t} = \rho\; .$$
Moreover, given increasingly fine partitions $0=t_0 < \cdots < t_N=T$ of an interval $[0,T]$ as before, we will have
$$\sum_{i=1}^N \Delta B_x_{t_i} \times \Delta B_y_{t_i} \rightarrow \int_0^T \rho_t\,\d  t$$
as $N \rightarrow \infty$, with probability one.  

We know that
$$\sum _{i=1}^N [\Delta X_{t_i}]^2 \rightarrow \int_0^T \sigma_x^2_t\,\d  t \quad \text{and}\quad  \sum _{i=1}^N [\Delta Y_{t_i}]^2 \rightarrow \int_0^T\sigma_y^2_t\,\d  t\;.
$$ {#eq-itoprocess112}

Furthermore, it can be shown that the sum of products satisfies
$$
\sum_{i=1}^N \Delta X_{t_i} \times \Delta Y_{t_i} \rightarrow \int_0^T \sigma_x_t\sigma_y_t\rho_t\,\d  t\;.
$$ {#eq-itoprocess113}


::: Rule
## 
By adding the rule 
$$
(\d  B_x)(\d  B_y) = \rho\,\d  t 
$$ {#eq-\,\d  B\,\d  B}
 to the rules @eq-\,\d  tsquared--@eq-\,\d  Bsquared, we can compute the limit in @eq-itoprocess113 as

$$
\lim_{N \rightarrow\infty} \sum_{i=1}^N \Delta X_{t_i} \times \Delta Y_{t_i}  = \int_0^T (\d  X)(\d  Y)
$$
$$
= \int_0^T (\mu_x\,\d  t +\sigma_x\,\d  B_x)(\mu_y\,\d  t+\sigma_y\,\d  B_y)
$$
$$
= \int_0^T\sigma_x_t\sigma_y_t \rho_t\,\d  t\;.
$$ {#eq-itojointvariation}


:::


The most general case of Ito's formula that we will need is for a function $Z_t = g(t, X_t, Y_t)$ where $X$ and $Y$ are Ito processes as in @eq-itoprocess110 - @eq-itoprocess111.  In this case, Ito's formula is^[We need to assume $g(t,x,y)$ is continuously differentiable in $t$ and twice continuously differentiable in $(x,y)$ for @eq-itogeneralnew and @eq-itogeneralnew2 to be valid.  Note also that we are using a short-hand notation here.  The partial derivatives of $g$ will generally depend on $t$, $X_t$ and $Y_t$ just as $g$ does.]

$$
Z_t = Z_0 + \int_0^T \frac{\partial g}{\partial t}\,\d  t + \int_0^T \frac{\partial g}{\partial x}\,\d  X_t + \int_0^T \frac{\partial g}{\partial y}\,\d  Y_t 
$$
$$
+ \frac{1}{2} \int_0^T \frac{\partial^2 g}{\partial x^2}\,(\d  X_t)^2 +  \frac{1}{2} \int_0^T \frac{\partial^2 g}{\partial y^2}\,(\d  Y_t)^2 
$$
$$
+  \int_0^T \frac{\partial^2 g}{\partial x\partial y}\,(\d  X_t)( \d  Y_t)\;.
$$ {#eq-itogeneralnew}


In this equation, we apply  @eq-dtsquared--@eq-dB to compute
\begin{align*}
(\d  X_t)^2&= \sigma_x^2_t\,\d  t\; ,\\
(\d  Y_t)^2 &= \sigma_y^2_t\,\d  t\; ,\\
(\d  X_t)( \d  Y_t) &= \sigma_x_t\sigma_y_t\rho_t\,\d  t\;.
\end{align*}
Ito's formula (@eq-itogeneralnew) appears a bit simpler (and easier to remember) if we write it in differential form.  We have:


::: Rule
## 
If $Z_t = g(t, X_t, Y_t)$ where $X$ and $Y$ are Ito processes as in @eq-itoprocess110 - @eq-itoprocess111, then

$$
\d  Z =  \frac{\partial g}{\partial t}\,\d  t + \frac{\partial g}{\partial x}\,\d  X +  \frac{\partial g}{\partial y}\,\d  Y + \frac{1}{2} \frac{\partial^2 g}{\partial x^2}\,(\d  X)^2 +  \frac{1}{2}  \frac{\partial^2 g}{\partial y^2}\,(\d  Y)^2 
$$
$$
+ \frac{\partial^2 g}{\partial x\partial y}\,(\d  X)(\d  Y)\;.
$$ {#eq-itogeneralnew2}



:::


## Examples of Ito's Formula {#sec-s_examples}
The following are the applications of Ito's formula that will be used most frequently in the book.  They follow from the boxed formula at the end of the previous section by taking $g(x,y)=xy$ or $g(x,y)=y/x$ or $g(x)=e^x$ or $g(x) = \log x$.




::: Rule

**Products.**
If $Z=XY$, then $\d  Z=X\,\d  Y+Y\,\d  X + (\d  X)(\d  Y)$.  We can write this as
$$
\frac{\d  Z}{Z}=\frac{\d  X}{X} + \frac{\d  Y}{Y} + \left(\frac{\d  X}{X}\right)\left(\frac{\d  Y}{Y}\right)\;.
$$ {#eq-rule2}


:::




::: Rule

**Ratios.**
If $Z=Y/X$, then 
$$\frac{\d  Z}{Z} = \frac{\d  Y}{Y} -\frac{\d  X}{X} - \left(\frac{\d  Y}{Y}\right)\left(\frac{\d  X}{X}\right) + \left(\frac{\d  X}{X}\right)^2\;.
$$ {#eq-rule4}


:::



::: Rule

**Exponentials.**
If $Z=\mathrm{e}^X$, then 
$$\frac{\d  Z}{Z}=\d  X + \frac{(\d  X)^2}{2}\;.
$$ {#eq-rule5}


:::



::: Rule

**Logarithms.**
If $Z=\log X$, then
$$
\d  Z=\frac{\d  X}{X} - \frac{1}{2}\left(\frac{\d  X}{X}\right)^2\;.
$$ {#eq-rule6}


:::



::: Rule

**Compounding/Discounting.**
Let  
$$Y_t =\exp\left(\int_0^t q_s\,\d  s\right)$$
for some (possibly random) process $q$ and define $Z=XY$ for any Ito process $X$.
The usual calculus gives us 
$\d  Y_t=q_tY_t\,\d  t$,
and the product rule above implies
$$
\frac{\d  Z}{Z}=q\,\d  t + \frac{\d  X}{X}\;.
$$ {#eq-compdisc1}

This is the same as in the usual calculus.  

:::



## {.unnumbered}


::: Exercise
 Consider a discrete partition $0=t_0 < t_1 < \cdots t_N=T$ of the time interval $[0,T]$ with $t_i - t_{i-1} = \Delta t = T/N$ for each $i$.  Consider the function 
$$X_t=\mathrm{e}^t\; .$$
Write a code, which computes and plots $\sum_{i=1}^N [\Delta X_{t_i}]^2$, where 
$$\Delta X_{t_i} = X_{t_i}-X_{t_{i-1}} = \mathrm{e}^{t_i} - \mathrm{e}^{t_{i-1}}\; .$$
:::
::: Exercise
 Repeat the previous problem for the function $X_t = t^3$.  In both this and the previous problem, what happens to $\sum_{i=1}^N [\Delta X_{t_i}]^2$ as $N \rightarrow \infty$?
:::
::: Exercise
 Either use the code provided or write a code to compute $\sum_{i=1}^N [\Delta B_{t_i}]^2$, where $B$ is a simulated Brownian motion.  For a given $T$, what happens to the sum as $N \rightarrow \infty$?  
:::
::: Exercise
 Repeat the previous problem to compute $\sum_{i=1}^N [\Delta B_{t_i}]^3$, where $B$ is a simulated Brownian motion.  For a given $T$, what happens to the sum as $N \rightarrow \infty$?  
:::
::: Exercise
 Repeat the previous problem, computing instead $\sum_{i=1}^N |\Delta B_{t_i}|$ where $| \cdot |$ denotes the absolute value.  What happens to this sum as $N \rightarrow \infty$?
:::
::: Exercise
Use Ito's Lemma to derive the stochastic differential equation for $S_t^2$.  Argue that $S_t^2$ is geometric Brownian motion and find $\E[S_t^2]$.
::: 
::: Exercise
Ito's Lemma can be used in different ways to get the same answer.  For example, let $X_t = a t + b B_t$ and use Ito's lemma on the function $e^{X_t}$.  Alternatively, let $f(t, B_t) = e^{a t + bB_t}$.  Use Ito's lemma on $f(,)$.
::: 
::: Exercise 
Use the facts $e^{x+y}=e^x \times e^y$ and $\frac{e^x}{e^y} = e^{x-y}$ to deduce the drift and volatility of the product and ratio of two geometric Brownian motions.
::: 
::: Exercise
 Consider a discrete partition $0=t_0 < t_1 < \cdots t_N=T$ of the time interval $[0,T]$ with $t_i - t_{i-1} = \Delta t = T/N$ for each $i$.  Consider a geometric Brownian motion
$$\frac{\d  Z}{Z} = \mu\,\d  t + \sigma\,\d  B\; .$$
An approximate path $\tilde{Z}_t$ of the geometric Brownian motion can be simulated as
$$
\Delta \tilde{Z}_{t_i} = \tilde{Z}_{t_{i-1}} \big[ \mu\,\Delta t + \sigma\,\Delta B\big]\;.
$$ {#eq-exponential111}
Modify the code to generate both a path $Z_t$ and an approximate path $\tilde{Z}_t$ according to @eq-exponential111, using the same $\Delta B$  for both paths and taking $\tilde{Z}_0 = Z_0$.  Plot both paths in the same figure.  How well does the approximation work for large $N$?   Warning:  
For $N$ larger than about $100 T$, the approximation will look perfect---you won't be able to tell that there are two plots in the figure.  One reason this is true is an exact formula is 
$$
 Z_{t_i} = Z_{t_{i-1}} \exp\left[ \left(\mu -\frac{\sigma^2}{2}\right)\,\Delta t + \sigma\,\Delta B\right]\;.
$$ {#eq-exponential112}
and using Taylor's Theorem for small $\Delta t$, $e^{\left(\mu-\frac{\sigma^2}{2}\right) \Delta t} \approx 1+ \left(\mu-\frac{\sigma^2}{2}\right) \Delta t$ and $e^{\sigma \Delta B_t} \approx 1+ \sigma \Delta B_t +\frac{1}{2}\sigma^2 (\Delta B_t)^2$ and $(\,\d  B_t)^2=\Delta t$.
:::
::: Exercise
Use simulation to find  $\E^*[e^{-r T}{\mathbf{1}}_{\{S_t \ge K\}}]$ in the risk-neutral probability where
\begin{equation*}
\,\d  S_t= r S_t \,\d  t + \sigma S_t \,\d  B_t^*
\end{equation*}
Verify that $S_t/e^{r t}$ is a martingale in the $*$ measure where $B^*$ is a Brownian motion.
Then use simulation to find $S_0\E^S[\frac{1}{S_t} {\mathbf{1}}_{\{S_t \ge K\}}]$ in the pricing measure which uses the share as numeraire where 
\begin{equation*}
\,\d  S_t = (r + \sigma^2) S_t \,\d  t + \sigma S_t \,\d  B_t^S
\end{equation*}
so the log satisfies
\begin{equation*}
\log(S_t) = \log(S_0) + (r + \frac{\sigma^2}{2})t + \sigma B_t^S
\end{equation*}
You should verify $e^{rt}/S_t$ is a martingale in the $S$ measure where $B^S$ is a Brownian motion.
Both estimates should be the same up to simulation error and give the time zero value of the random payoff ${\mathbf{1}}_{\{S_t \ge K\}}$ which is a random variable equal to $1$ if $S_t\ge K$ and $0$ otherwise.  You should choose the values for $r$, $\sigma$, $T$, and $K$.
::: 


