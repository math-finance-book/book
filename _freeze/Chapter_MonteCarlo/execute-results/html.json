{
  "hash": "50ae014ec3d10915f1f47d9a2d3b84e4",
  "result": {
    "engine": "jupyter",
    "markdown": "\\newcommand{\\d}{\\,\\mathrm{d}}\n\\newcommand{\\e}{\\mathrm{e}}\n\\newcommand{\\E}{\\mathbb{E}}\n\n\n\n## Monte Carlo Methods {#sec-c:montecarlo} \n\n::: {#8300d320 .cell execution_count=1}\n\n::: {.cell-output .cell-output-display}\n```{=html}\n        <script type=\"text/javascript\">\n        window.PlotlyConfig = {MathJaxConfig: 'local'};\n        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n        </script>\n        <script type=\"module\">import \"https://cdn.plot.ly/plotly-3.0.0.min\"</script>\n        \n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<script type=\"text/javascript\" async src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_SVG\"></script>\n```\n:::\n:::\n\n\nIn this chapter, we will introduce two principal numerical methods for valuing derivative securities: Monte Carlo and binomial models.  We will consider two applications: valuing European options in the presence of stochastic volatility with Monte Carlo and valuing American options via binomial models.   Throughout the chapter, we will assume there is a constant risk-free rate.  The last section, while quite important, could be skimmed on first reading---the rest of the book does not build upon it.\n\n## Introduction to Monte Carlo {#sec-s:mc_europeans}\n\nAccording to our risk-neutral pricing @eq-riskneutralformula, the value of a security paying an amount $x$ at date $T$ is\n$$\n\\mathrm{e}^{-rT}\\\\E^R[x]\\;.\n$$ {#eq-montecarlo1}\n\nTo estimate this by Monte-Carlo \\index{Monte Carlo} means to simulate a sample of values for the random variable\n$x$\nand to estimate the expectation by averaging the sample values.^[Boyle~[@boyle] introduced Monte-Carlo methods for derivative valuation, including the variance-reduction methods of control variates and antithetic variates to be discussed later].  Of course, for this to work, the sample must be generated from a population having a distribution consistent with the risk-neutral probabilities.\n\nThe simplest example is valuing a European option under the Black-Scholes assumptions.  Of course, for calls and puts, this is redundant, because we already have the Black-Scholes formulas.  Nevertheless, we will describe how to do this for the sake of introducing the Monte Carlo method.  In the case of a call option, the random variable $x$ in @eq-montecarlo1 is $\\max(0,S_T-K)$.  To simulate a sample of values for this random variable, we need to simulate the terminal stock price $S_T$.  This is easy to do, because, under the Black-Scholes assumptions, the logarithm of $S_T$ is normally distributed under the risk-neutral probability with mean $\\log S_0+\\mathrm{n}u T$ and variance $\\sigma^2T$, where $\\mathrm{n}u=r-q-\\sigma^2/2$.  Thus, we can simulate values for $\\log S_T$ as $\\log S_0+\\mathrm{n}u T + \\sigma\\sqrt{T}z$, where $z$ is a standard normal.  We can  average the simulated values of $\\max(0,S_T-K)$, or whatever the payoff of the derivative is, and then discount at the risk-free rate to compute the date--0 value of the derivative.  This means that we generate some number $M$ of standard normals $z_i$ and estimate the option value as $\\mathrm{e}^{-rT}\\bar{x}$, where $\\bar{x}$ is the mean of \n$$x_i = \\max\\left(0,\\mathrm{e}^{\\log S_0+\\mathrm{n}u T + \\sigma\\sqrt{T}z_i}-K\\right)\\; .$$\nTo value options that are path-dependent  we need to simulate the path of the underlying asset price.  Path-dependent options are discussed in Chaps.~\\ref{c_exotics} and~\\ref{c_montecarlo}.\n\nThere are two main drawbacks to Monte-Carlo methods.  First, it is difficult (though not impossible) to value early-exercise features.^[Monte-Carlo methods for valuing early exercise include the stochastic mesh method of Broadie and Glasserman [@BG] and the regression method of Longstaff and Schwartz [@LS01].  Glasserman [@Glasserman] provides a good discussion of these methods and the relation between them.]  To value early exercise, we need to know the value at each date if not exercised, to compare to the intrinsic value.  One could consider performing a simulation at each date to calculate the value if not exercised, but this value depends on the option to exercise early at later dates, which cannot be calculated without knowing the value of being able to exercise early at even later dates, etc.  In contrast, the binomial model (and finite difference models discussed in @sec-c:pde) can easily handle early exercise but cannot easily handle path dependencies.  \n\nThe second drawback of Monte Carlo methods is that they can be quite inefficient in terms of computation time (though, as will be explained later, they may be faster than alternative methods for derivatives written on multiple assets).  As in statistics, the standard error of the estimate depends on the sample size.  Specifically, \nwe observed in @sec-s:statistics that, given a random sample $\\{x_1,\\ldots,x_M\\}$ of size $M$ from a population with mean $\\mu$ and variance $\\sigma^2$, the best estimate of $\\mu$ is the sample mean $\\bar{x}$, and the standard error of $\\bar{x}$ (which means the standard deviation of $\\bar{x}$ in repeated samples) is best estimated by\n$$\n\\sqrt{\\frac{1}{M(M-1)}\\left(\\sum_{i=1}^{M} x_i^2-M\\bar{x}^2\\right)}\\;.\n$$ {#eq-standarderror}\n \\index{standard error}\nRecall that $\\bar{x}$ plus or minus 1.96 standard errors is a 95\\% confidence interval for $\\mu$ when the $x_i$ are normally distributed.\nIn the context of European option valuation, the expression @eq-standarderror gives the  standard error of the estimated option value at maturity, and multiplication of @eq-standarderror by $\\mathrm{e}^{-rT}$ gives the standard error of the estimated date--0 option value.\n\nTo obtain an estimate with an acceptably small standard error may require a large sample size and hence a relatively large amount of computation time.  The complexities of Monte Carlo methods arise from trying to reduce the required sample size.  Later, we will describe two such methods (antithetic variates and control variates).   For those who want to engage in a more detailed study of Monte Carlo methods, the book of Glasserman [@Glasserman] is highly recommended.  J\\\"ackel [@Jackel] is useful for more advanced readers, and Clewlow and Strickland [@CS] and  Brandimarte [@Brandimarte] are useful references that include computer code.\n\n\n### Monte Carlo Valuation of a European Call\nWe will illustrate Monte Carlo by valuing a European call under the Black-Scholes assumptions.  We will also estimate the delta by each of the methods described in @sec-s:montecarlogreeks1 and~\\ref{s_montecarlogreeks2}.  Of course, we know the call value and its delta from the Black-Scholes formulas, and they can be used to evaluate the accuracy of the Monte Carlo estimates.  We use the code in Chapter @sec-c:continuoustime.  In this circumstance, we only need to simulate the price of the underlying at the option maturity rather than the entire path of the price process. Therefore we  set $m=1$. However, we use a large number of paths, $n=10000$ to get a large sample of terminal stock prices.\n\n::: {#9f70256a .cell execution_count=2}\n``` {.python .cell-code}\n# Simulate Geometric Brownian Motion\nimport numpy as np\nimport matplotlib.pyplot as plt\n# number of paths\nn = 10000\n#number of divisions\nm = 1\n# Interest rate (We set the drift equal to the interest rate for the risk-neutral probability)\nr = 0.1\n# Volatility\nsig = 0.2\n# Initial Stock Price\nS0 = 42\n# Maturity\nT = 0.5\n#Strike Price\nK=40\n# Dividend Yield\nq=0.0\n# Delta t\ndt = T/m\n# Drift\ndrift = (r-q-0.5*sig**2)\n# Volatility\nvol = sig * np.sqrt(dt)\n\nt = np.array(range(0,m + 1,1)) * dt\n\n# seed for random generator\nseed= 2020\n# define a random generator\nnp.random.seed(seed)\ninc = np.zeros(shape = (m + 1, n))\ninc[1:] = np.transpose(np.random.normal(loc = 0, scale = vol,size = (n,m)))\nSt = np.zeros(shape = (m + 1, n))\nSt = S0 * np.exp(np.cumsum(inc,axis=0) + (drift * t[0:m + 1])[:,None])\nSt1 = S0 * np.exp(-np.cumsum(inc,axis=0) + (drift * t[0:m + 1])[:,None])\n```\n:::\n\n\nAs before, this code generates two samples $St$, which adds the simulated standard (zero mean) normal random variable, and $St1$ which subtracts the simulated (zero mean) standard normal random variable.  Each sample produces and estimate for the Black-Scholes European call option.\n\n::: {#7ae5c553 .cell execution_count=3}\n``` {.python .cell-code}\ncc=np.maximum(St[m,:]-K,0)\ncp = np.mean(cc) * np.exp(-r * T)\ncc1=np.maximum(St1[m,:]-K,0)*np.exp(-r * T)\ncp1= np.mean(np.maximum(St1[m,:]-K,0)) * np.exp(-r * T)\n\nprint('The first sample gives an estimated call price=',cp)\nprint('The second sample gives an estimated call price=',cp1)\nbsc = (cp+cp1)/2\nprint('The average of the two estimates=',bsc)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThe first sample gives an estimated call price= 4.791646287615179\nThe second sample gives an estimated call price= 4.687624646438364\nThe average of the two estimates= 4.739635467026771\n```\n:::\n:::\n\n\nThe true call price is given by\n\n::: {#27298125 .cell execution_count=4}\n``` {.python .cell-code}\nfrom scipy.stats import norm\nimport numpy as np\nfrom scipy.optimize import minimize, minimize_scalar\n\ndef blackscholes(S0, K, r, q, sig, T, call = True):\n    '''Calculate option price using B-S formula.\n    \n    Args:\n        S0 (num): initial price of underlying asset.\n        K (num): strick price.\n        r (num): risk free rate\n        q (num): dividend yield\n        sig (num): Black-Scholes volatility.\n        T (num): maturity.\n        call (bool): True returns call price, False returns put price.\n        \n    Returns:\n        num\n    '''\n    d1 = (np.log(S0/K) + (r -q + sig**2/2) * T)/(sig*np.sqrt(T))\n    d2 = d1 - sig*np.sqrt(T)\n    if call:\n        return np.exp(- q *T) * S0 * norm.cdf(d1,0,1) - K * np.exp(-r * T) * norm.cdf(d2,0, 1) \n    else:\n        return -np.exp(-q * T) * S0 * norm.cdf(-d1,0,1) + K * np.exp(-r * T) * norm.cdf(-d2,0, 1)\n\ntruebsc=blackscholes(S0, K, r, q, sig, T, call = True)\nprint('The black scholes fromula=',truebsc)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThe black scholes fromula= 4.759422392871532\n```\n:::\n:::\n\n\n  Notice that even with 10000 data points for each sample the individual estimates are not very accurate compared to the exact Black Scoles price.  This is a well known problem that is difficult to estimate the mean, even with a lot of data and is a drawback to Monte Carlo as discussed earlier. However, the average of the two prices is sgnificantly more accurate.  This is an example of an antithetic variable which is discussed later.  One simple intution is the two samples yield negatively correlated errors; if the plus sample is two high, then the minus sample will be too low.  Combined, the simulation error will cancel out.  Another intution is that each individual sample has a wrong estimate of the mean.  However, the combined sample has zero mean by construction.  Therefore combining the samples give the right mean of the simulated standard normal random variable.  Nevertheless, there is still sampling error since we are estimating the mean of the discounted call payoffs, not the mean of the standard normal.  This method and other methods to reduce sampling error are discussed next.\n\n  ## Antithetic Variates in Monte Carlo\n\nIn this and the following section, we will discuss two methods to increase the efficiency of the Monte Carlo method.  These are two of the simplest methods.  They are used extensively, but there are other important methods that are also widely used.  J\\\"ackel [@Jackel] and Glasserman [@Glasserman] provide a wealth of information on this topic.\n\nThe Monte Carlo method estimates the mean $\\mu$ of a random variable $x$ as the sample average of randomly generated values of $x$.  An antithetic variate \\index{antithetic variate} is a random variable $y$ with the same mean as $x$ and a negative correlation with $x$.  It follows that the random variable $z=(x+y)/2$ will have the same mean as $x$ and a lower variance.  Therefore the sample mean of $M$ simulations of $z$ will be an unbiased estimate of $\\mu$ and will have a lower standard error than the sample mean of $M$ simulations of $x$.  Thus, we should obtain a more efficient estimator of $\\mu$ by simulating $z$ instead of $x$.^[\nThe negative correlation between $x$ and $y$ is essential for this method to generate a real gain in efficiency.  To generate $M$ simulations of $z$, one must generate $M$ simulations of $x$ and $M$ of $y$, which will generally require about as much computation time as generating $2M$ simulations of $x$.  If $x$ and $y$ were independent, the standard error from $M$ simulations of $z$ would be the same as the standard error from $2M$ simulations of $x$, so using the antithetic variate would be no better than just doubling the sample size for $x$.]\n\nIn the context of derivative valuation, the standard application of this idea is to generate two negatively correlated underlying asset prices (or price paths, if the derivative is path dependent).  The terminal value of the derivative written on the first asset serves as $x$ and the terminal value of the derivative written on the second serves as $y$.  Because both asset prices have the same distribution, the means of $x$ and $y$ will be the same, and the discounted mean is the date--0 value of the derivative. \n\nConsider for example a non-path-dependent option in a world with constant volatility.  In each simulation $i$ ($i=1,\\ldots,M$), we would generate a standard normal $Z_i$ and compute\n\\begin{align*}\n\\log S_i_T &= \\log S_0 + \\left(r-q-\\frac{1}{2}\\sigma^2\\right)T + \\sigma\\sqrt{T}Z_i\\; ,\\\\\n\\log S_i'_T &= \\log S_0 + \\left(r-q-\\frac{1}{2}\\sigma^2\\right)T - \\sigma\\sqrt{T}Z_i\\;.\n\\end{align*}\nGiven the first terminal price, the value of the derivative will be some number $x_i$ and given the second it will be some number $y_i$.  The date--0 value of the derivative is estimated as\n$$\\mathrm{e}^{-rT}\\frac{1}{M}\\sum_{i=1}^M\\frac{x_i+y_i}{2}\\; .$$\n\n\n## Control Variates in Monte Carlo {#sec-s:controlvariates}\n\\index{control variate}\nAnother approach to increasing the efficiency of the Monte Carlo method is to adjust the estimated mean (option value) based on the known mean of another related variable.  We can explain this in terms of linear regression in statistics.  Suppose we have a random sample $\\{x_1,\\ldots,x_M\\}$ of a variable $x$ with unknown mean $\\mu$, and suppose we have a corresponding sample $\\{y_1,\\ldots,y_M\\}$ of another variable $y$ with known mean $\\phi$.  Then an efficient estimate of $\\mu$ is $\\hat{\\mu} = \\bar{x} + \\hat{\\beta} (\\phi-\\bar{y})$, where $\\bar{x}$ and $\\bar{y}$ denote the sample means of $x$ and $y$, and where $\\hat{\\beta}$ is the coefficient of $y$ in the linear regression of $x$ on $y$ (i.e., the estimate of $\\beta$ in the linear model $x = \\alpha +\\beta y + \\varepsilon$).  The standard Monte Carlo method, which we have described thus far, simply estimates the mean of $x$ as $\\bar{x}$.  The control variate method adjusts the estimate by adding $\\hat{\\beta} (\\phi-\\bar{y})$.  To understand this correction, assume for example that the true $\\beta$ is positive.  If the random sample is such that $\\bar{y}<\\phi$, then it must be that small values of $y$ were over-represented in the sample.  Since $x$ and $y$ tend to move up and down together (this is the meaning of a positive $\\beta$) it is likely that small values of $x$ were also over-represented in the sample.  Therefore, one should adjust the sample mean of $x$ upwards in order to estimate $\\mu$.  The best adjustment will take into account the extent to which small values of $y$ were over-represented (i.e., the difference between $\\bar{y}$ and $\\phi$) and the strength of the relation between $x$ and $y$ (which the estimate $\\hat{\\beta}$ represents).  The efficient correction of this sort is also the simplest:  just add $\\hat{\\beta}(\\phi-\\bar{y})$ to $\\bar{x}$.  In practice, the estimation of $\\hat{\\beta}$ may be omitted and one may simply take $\\hat{\\beta}=1$, if the relationship between $x$ and $y$ can be assumed to be one-for-one.  If $\\beta$ is to be estimated, the estimate (by ordinary least squares) is\n$$\\hat{\\beta} = \\frac{\\sum_{i=1}^M x_iy_i - M\\bar{x}\\bar{y}}{\\sum_{i=1}^M y_i^2 - M\\bar{y}^2}\\; .$$\nIn general, the correction term $\\hat{\\beta}(\\phi-\\bar{y})$ will have a nonzero mean, which introduces a bias in the estimate of $\\mu$.  To eliminate the bias, one can compute $\\hat{\\beta}$ from a pre-sample of $\\{x,y\\}$ values.  \n\nAs an example of a control variate, in our simulation code to estimate the Black Scholes price for a call option we can use the stock price itself.  The known stock price is the inout price $S0$.  The simulation also produces an estimate for the stock price as the dicsounted expected value of the terminal stock price  $\\hat{S}=\\sum_{i=1}^{n} e^{- r T } St(m,i)$ where $St(m,i)$ is the $i$th simulated stock price at time $T$.  Theoretically these should be the same umber, but due to error they typically wil not be the same.\n\n::: {#a3360ec2 .cell execution_count=5}\n``` {.python .cell-code}\nSS=np.mean(St[m,:])*np.exp(-r*T)\nprint('The Estimated Stock Price for the first sample is =', SS)\nprint('The actual stock price should be=', S0)\nprint('The error is =', S0-SS)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThe Estimated Stock Price for the first sample is = 42.05899999577932\nThe actual stock price should be= 42\nThe error is = -0.058999995779316805\n```\n:::\n:::\n\n\nThe error is $S0-\\hat{S}$ which corresponds to $\\phi-y$ above.  We then compute $\\hat{\\beta}$ and comute the improved estimate\n$$ \\text{new estimate}= \\text{original estimate} +\\hat{\\beta}(S0-\\hat{S}) $$\nIn the code below we do this procedure for both samples and average the updates.\n\n::: {#e5e3fb10 .cell execution_count=6}\n``` {.python .cell-code}\nhatbeta= np.cov(St[m,:],cc)[0,1]/np.cov(St[m,],cc)[1,1]\nhatbeta1=np.cov(St1[m,:],cc1)[0,1]/np.cov(St1[m,],cc1)[1,1]\ncorrection =hatbeta*(S0-SS)\nupdate=cp + correction\nprint('hatbeta=',hatbeta)\nprint('The original estimate for the call price from the first sample=',cp)\nprint('The original estimate for the call price from the second sample=',cp1)\nprint('The updated estimate from the first sample is=',update)\nSS1=np.mean(St1[m,:])*np.exp(-r*T)\nupdate1=cp1+hatbeta1*(S0-SS1)\nprint('The updated estimate from the second sample is=',update1)\nprint('The average of the updated estimates =',(update+update1)/2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nhatbeta= 1.1541186403411716\nThe original estimate for the call price from the first sample= 4.791646287615179\nThe original estimate for the call price from the second sample= 4.687624646438364\nThe updated estimate from the first sample is= 4.723553292706219\nThe updated estimate from the second sample is= 4.780385012196883\nThe average of the updated estimates = 4.751969152451551\n```\n:::\n:::\n\n\nWe can compare this to the exact Black Scholes formula from before.\n\n::: {#e2cff104 .cell execution_count=7}\n``` {.python .cell-code}\nprint('The exact Black Scholes Price is=', truebsc)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThe exact Black Scholes Price is= 4.759422392871532\n```\n:::\n:::\n\n\nAs another example,  consider the classic case of estimating the value of a discretely-sampled average-price call, using a discretely-sampled geometric-average-price call \\index{average-price option} \\index{geometric-average option} as a control variate.  Let $\\tau$ denote the amount of time that has elapsed since the call was issued and $T$ the amount of time remaining before maturity, so the total maturity of the call is $T+\\tau$.  To simplify somewhat,  assume date $0$ is the beginning of a period between observations.  Let $t_1, \\ldots, t_N$ denote the remaining sampling dates, with $t_1 = \\Delta t$, $t_i-t_{i-1}=\\Delta t = T/N$ for each $i$, and $t_N=T$.  We will input the average price $A_0$ computed up to date $0$, assuming this average includes the price $S_0$ at date $0$.  The average price at date $T$ will be \n$$A_T = \\frac{\\tau}{T+\\tau}A_0 + \\frac{T}{T+\\tau}\\left(\\frac{\\sum_{i=1}^N S_{t_i}}{N}\\right)\\; .$$\nThe average-price call pays $\\max(0,A_T-K)$ at its maturity $T$, and we can write this as\n\\begin{align*}\n\\max(A_T-K,0) &= \\max\\left(\\frac{T}{T+\\tau}\\left( \\frac{\\sum_{i=1}^N S_{t_i}}{N}\\right) - \\left(K - \\frac{\\tau}{T+\\tau}A_0\\right), 0\\right)\\\\\n&= \\frac{T}{T+\\tau} \\max \\left(\\frac{\\sum_{i=1}^N S_{t_i}}{N} - K^*,0\\right)\\;,\n\\end{align*}\nwhere \n$$K^* = \\frac{T+\\tau}{T}K - \\frac{\\tau}{T}A_0\\; .$$\nTherefore, the value at date $0$ of the discretely-sampled average-price call is\n$$\\frac{T}{T+\\tau} \\,\\mathrm{e}^{-rT} \\\\E^R\\left[\\max \\left(\\frac{\\sum_{i=1}^N S_{t_i}}{N} - K^*,0\\right)\\right]\\; .$$\nIn terms of the discussion above, the random variable  the mean of which we want to estimate is\n$$x = \\mathrm{e}^{-rT}\\max \\left(\\frac{\\sum_{i=1}^N S_{t_i}}{N} - K^*,0\\right)\\; .$$\nA random variable $y$ that will be closely correlated to $x$ is\n$$y =\\mathrm{e}^{-rT}\\max \\left(\\mathrm{e}^{\\sum_{i=1}^N \\log S_{t_i}/N} - K^*,0\\right)\\; .$$\nThe mean $\\phi$ of $y$ under the risk-neutral probability is given in the pricing @eq-disc_geom_avg_call. \nWe can use the sample mean of $y$ and its known mean $\\phi$ to adjust the sample mean of $x$ as an estimator of the value of the average-price call.  Generally, the estimated adjustment coefficient $\\hat{\\beta}$ will be quite close to 1.  \n\n## Monte Carlo Greeks I: Difference Ratios {#sec-s:montecarlogreeks1}\n\nGreeks can be calculated by Monte Carlo by running the valuation program twice and computing a difference ratio, for example $(C_u-C_d)/(S_u-S_d)$ to estimate a delta.  However, to minimize the error, and minimize the number of computations required, one should use the same set of random draws to estimate the derivative value for different values of the parameter.  For path-independent options (e.g., European puts and calls) under the Black-Scholes assumptions, we only need to generate $S_T$ and then we can compute $S_u_T$ as $[S_u_0/S_0] \\times S_T$ and $S_d_T$ as $[S_u_0/S_0] \\times S_T$.  We can estimate standard errors for the Greeks in the same way that we estimate the standard error of the derivative value.  \n\nActually, there is often a better method available that is just as simple.  This is called pathwise calculation.  We will explain this in the next section.   Here we will describe how to estimate the delta and gamma of a derivative as sample means of difference ratios.\n\nConsider  initial prices for the underlying $S_u>S>S_d$.  Denote the underlying price at the option maturity in a given simulation by $S_u_T$  when the initial underlying price is $S_u$, by $S_T$  when the initial underlying price is $S$, and by $S_d_T$  when the initial underlying price is $S_d$.   Under the Black-Scholes assumptions, the logarithm of the stock price at date $T$ starting from the three initial prices $S_d$, $S$ and $S_u$ is\n\\begin{align*}\n\\log S_d_T &= \\log S_d + \\left(r-q-\\frac{1}{2}\\sigma^2\\right)T + \\sigma B_T\\; ,\\\\\n\\log S_T &= \\log S + \\left(r-q-\\frac{1}{2}\\sigma^2\\right)T + \\sigma B_T\\; ,\\\\\n\\log S_u _T &= \\log S_u + \\left(r-q-\\frac{1}{2}\\sigma^2\\right)T + \\sigma B_T\\;,\n\\end{align*}\nso \n$$\\log S_d_T = \\log S_T + \\log S_d - \\log S\\Longrightarrow S_d_T = \\left(\\frac{S_d}{S}\\right) S_T\\; ,$$\nand\n$$\\log S_u_T = \\log S_T + \\log S_u - \\log S \\Longrightarrow S_u_T = \\left(\\frac{S_u}{S}\\right) S_T\\; .$$\nTherefore, under the Black-Scholes assumptions, we only need to simulate $S_T$ and then perform the multiplications indicated above to obtain $S_d_T$ and $S_u_T$. \n\nConsider a particular simulation and let $C_d_T$ denote the value of the derivative at maturity  when the initial asset price is $S_d$, let  $C_T$ denote the value of the derivative at maturity  when the initial asset price is $S$, and let $C_u_T$ denote the value of the derivative at maturity  when the initial asset price is $S_u$.  For path-independent derivatives under the Black-Scholes assumptions, these can be computed directly from the simulation of $S_T$ as just described.  However, the following applies to general European derivatives under general assumptions about the underlying asset price (for example, it could follow a GARCH process).\n\nThe estimates $C_d$, $C$ and $C_u$ of the date--0 derivative values, for the different initial prices of the underlying, are the discounted sample means of the $C_d_T$, $C_T$ and $C_u_T$.\nOne way to estimate the delta is $(C_u-C_d)/(S_u-S_d)$.  This is a difference of discounted sample means, multiplied by the reciprocal of $S_u-S_d$.  Equivalently, it is the sample mean of the differences $C_u_T-C_d_T$, multiplied by $\\mathrm{e}^{-rT}/(S_u-S_d)$.  As a sample mean, its standard error can be estimated as described in @sec-c:stochasticvolatility.   The standard error is\n$$\\frac{\\mathrm{e}^{-rT}}{S_u-S_d}\\sqrt{\\frac{1}{M(M-1)}\\left(\\sum_{i=1}^M \\left[C_{ui}_T-C_{di}_T\\right]^2 - M\\left[\\overline{C_{u}_T}-\\overline{C_{d}_T}\\right]^2\\right)}\\; ,$$ \\index{standard error}\nwhere the overline denotes the sample mean and where $C_{ui}_T$ [respectively, $C_{di}_T$] denotes the value of the derivative at maturity in simulation $i$ when the initial asset price is $S_u$ [respectively, $S_d$].\n\nThe corresponding Monte Carlo estimate of the gamma is also a sample mean.  Simple algebra shows that @eq-binomialgamma100 is equivalent to\n$$\n\\Gamma = \\frac{2}{(S_u-S)(S_u-S_d)}C_u - \\frac{2}{(S_u-S)(S-S_d)}C +\\frac{2}{(S-S_d)(S_u-S_d)}C_d\\;.\n$$ {#eq-binomialgamma200}\n\nNormally one would take $S_u=(1+\\alpha)S$ and $S_d = (1-\\alpha)S$ for some $\\alpha$ (e.g., $\\alpha=0.01$).  In this case  @eq-binomialgamma200\nsimplifies to\n$$\n\\Gamma = \\frac{C_u - 2C + C_d}{\\alpha^2S^2}\\;,\n$$ {#eq-binomialgamma300}\n\nand the standard error of the gamma is\n\n\\begin{multline*}\\frac{\\mathrm{e}^{-rT}}{\\alpha^2S^2}\\sqrt{\\frac{1}{M(M-1)}}\\\\\n\\times \\sqrt{\\sum_{i=1}^M \\left[C_{ui}_T-2C_i_T+C_{di}_T\\right]^2 -M\\left[\\overline{C_{u}_T}-2\\overline{C_T}+\\overline{C_{d}_T}\\right]^2}\\; .\n\\end{multline*}\n\n\n## Monte Carlo Greeks II: Pathwise Estimates {#sec-s:montecarlogreeks2}\nWe will examine the bias in the Monte Carlo delta estimate discussed in the preceding section and explain  pathwise estimation of Greeks. By biased, we mean that the expected value of an estimate is different from the true value. \\index{bias} It is important to recognize that if a Monte Carlo estimate is biased, then, even if a large number of simulations is used and the standard error is nearly zero, the answer provided by the Monte Carlo method will be incorrect.   For simplicity, consider a European call under the Black-Scholes assumptions.  \n\nThe delta estimate we have considered is the discounted sample mean of \n$$\n\\frac{C_u_T - C_d_T}{S_u-S_d}\\;.$$ {#eq-montecarlodelta2}\n\n\nThis ratio takes on one of three values, depending on $S_T$:\n\n\n- If $S_u_T \\leq K$ then the option is out of the money in both the up and down cases; i.e., \n$$C_u_T = C_d_T = 0\\; ,$$\nso the ratio @eq-montecarlodelta2 is zero.\n- If $S_d_T \\geq K$ then the option is in the money in both the up and down cases; i.e.,\n\\begin{align*} C_u_T &= S_u_T - K =\\left(\\frac{S_u}{S}\\right)S_T - K\\; ,\\\\\nC_d_T &= S_d_T - K = \\left(\\frac{S_d}{S}\\right)S_T - K\\;,\n\\end{align*}\nso the ratio  @eq-montecarlodelta2 equals $S_T/S$.\n- If $S_u_T > K > S_d_T$, then the option is in the money in only the up case; i.e.,\n\\begin{align*}\nC_u_T &= S_u_T - K = \\left(\\frac{S_u}{S}\\right)S_T - K\\; ,\\\\\nC_d_T &= 0\\;,\n\\end{align*}\nso the ratio @eq-montecarlodelta2 equals \n$$\\frac{\\left(\\frac{S_u}{S}\\right)S_T - K}{S_u-S_d} < \\frac{S_T}{S}\\; .$$\n\n\nThe bias is induced by the third case above.  We can see this as follows.  We are trying to estimate\n$$\n\\frac{\\partial }{\\partial S} \\mathrm{e}^{-rT}\\\\E^R \\big[\\max(0,S_T-K)\\big] = \\mathrm{e}^{-rT}\\\\E^R  \\left[ \\frac{\\partial }{\\partial S} \\max(0,S_T-K)\\right]\\;.\n$$ {#eq-montecarlodelta4}\n\nThe delta estimate $(C_u-C_d)/(S_u-S_d)$ replaces the mean $\\\\E^R$ with the sample mean and replaces\n$$\n\\frac{\\partial }{\\partial S} \\max(0,S_T-K)\n$$ {#eq-montecarlodelta3}\n\nwith the ratio @eq-montecarlodelta2.  The derivative @eq-montecarlodelta3 takes on two possible values, depending on $S_T$---we can ignore the case $S_T=K$ because it occurs with zero probability:\n\n\n- If $S_T < K$, then $\\max(0,S_T-K) = 0$ and the derivative is zero.\n- If $S_T>K$,  then $\\max(0,S_T-K) = S_T-K$ and the derivative equals \n$$\\frac{\\partial S_T}{\\partial S}=\\mathrm{e}^{(r-q-\\sigma^2/2)T + \\sigma B_T} = \\frac{S_T}{S}\\; .$$\n\nTherefore, the true delta---the expectation @eq-montecarlodelta4---equals^[By changing numeraires, we can show that @eq-montecarlodelta5 equals $\\mathrm{e}^{-qT}\\\\E^V[x] = \\mathrm{e}^{-qT}\\mathrm{N}(d_1)$, as we know from @sec-c:blackscholes is the delta of a European call in the Black-Scholes model (here, as in @sec-c:blackscholes, $V_t=\\mathrm{e}^{qt}S_t$ denotes the value of the dividend-reinvested portfolio created from the stock).] \n$$\n\\mathrm{e}^{-rT}\\\\E^R\\left[\\frac{S_T}{S} x\\right]\\;,\n$$ {#eq-montecarlodelta5}\n\nwhere $x$ is the random variable defined as\n\\begin{equation*}\nx =  \\begin{cases} 1 & \\text{if $S_T>K$}\\; ,\\\\\n0 & \\text{otherwise}\\;.\n\\end{cases}\n\\end{equation*}\n On the other hand, our  analysis of the ratio @eq-montecarlodelta2 shows that the expected value of the delta estimate $(C_u-C_d)/(S_u-S_d)$ is\n$$\n\\mathrm{e}^{-rT}\\\\E^R\\left[\\frac{S_T}{S} y\\right] + \\mathrm{e}^{-rT}\\\\E^R\\left[\\frac{S_uS_T-SK}{S(S_u-S_d)}z\\right]\\;,\n$$ {#eq-montecarlodelta6}\n\nwhere\n\\begin{align*}\ny &=  \\begin{cases} 1 & \\text{if} S_d_T>K\\; ,\\\\\n0 & \\text{otherwise}\\;.\n\\end{cases}\n\\end{align*}\nand\n\\begin{align*}\nz &=  \\begin{cases} 1 & \\text{if} S_u_T>K>S_d_T\\; ,\\\\\n0 & \\text{otherwise}\\;.\n\\end{cases}\n\\end{align*}\nTo contrast @eq-montecarlodelta5 and @eq-montecarlodelta6, note that if $y=1$ then $x=1$, so the term \n$\\\\E^R\\left[\\frac{S_T}{S} y\\right]$ in @eq-montecarlodelta6 is part of @eq-montecarlodelta5.  However, there are two partially offsetting errors in @eq-montecarlodelta6: $z$ sometimes equals one when $x$ is zero, and when both $z$ and $x$ are one, then the factor multiplying $z$ is smaller than the factor multiplying $x$.  In any case, the expected value @eq-montecarlodelta6  is not the same as the true delta @eq-montecarlodelta5.  As noted before, this implies that the delta estimate will be incorrect even if its standard error is zero.  The bias can be made as small as one wishes by taking the magnitude $S_u-S_d$ of the perturbation to be small, but taking the perturbation to be very small will introduce unacceptable roundoff error.\n\nThe obvious way to estimate the delta in this situation is simply to compute the discounted sample average of $[S_T/S]x$.  This is called a pathwise estimate \\index{pathwise Monte Carlo Greeks} of the delta, because it only uses the sample paths of $S_t$ rather than considering up and down perturbations.  This method is due to Broadie and Glasserman [@bg2]. Because the pathwise estimate is a sample average, its standard error can be computed in the usual way.\n\nTo compute pathwise estimates in other models and for other Greeks, we need the Greek to be an expectation as on the right-hand side of @eq-montecarlodelta4.  Additional examples can be found in  Glasserman [@Glasserman] and J\\\"ackel [@Jackel].\n\n\n\n## Monte Carlo Models for Path-Dependent Options\nA derivative is said to be path dependent \\index{path-dependent option} if its value depends on the path of the underlying asset price rather than just on the  price at the time of exercise.  Examples of path-dependent options are lookbacks, barrier options, and Asians.\nTo value a path-dependent option by Monte Carlo, we need to simulate an approximate path of the stock price.  We do this by considering time periods of length $\\Delta t = T/N$ for some integer $N$.  Under the risk-neutral probability, the logarithm of the stock price changes over such a time period by\n$$\n\\Delta \\log S = \\nu\\,\\Delta t + \\sigma\\sqrt{\\Delta t}\\,z\\;,\n$$ {#eq-pathdependent}\n\nwhere $\\nu = r-q-\\sigma^2/2$ and $z$ is a standard normal.  Given that there are $N$ time periods of length $\\Delta t$, we need to generate $N$ standard normals to generate a stock price path.  If we generate $M$ paths to obtain a sample of $M$ option values, then we will need to generate $MN$ standard normals.  \n\n\nConsider for example a floating-strike lookback call. \\index{lookback option} The formula for this option given in @sec-s:lookbacks assumes the minimum stock price is computed over the entire path of the stock price, i.e., with continuous sampling of the stock price.  In practice, the minimum will be computed by recording the price at a discrete number of dates.  We can value the discretely sampled lookback using Monte-Carlo by choosing $\\Delta t$ to be the interval of time (e.g., a day or week) at which the price is recorded.  For example, if the contract calls for weekly observation, we will attain maximum precision by setting $N$ to be the number of weeks before the option matures.\n\nFor most path dependent options, a possible starting point is to generate an array of $n$ paths but since we want the entire path we choose the number of time steps that is appropriate for our application.  We can use the same code as in Section @#sec-s:mc_europeans if we are working in a Black Scholes setting.\n\n::: {#79238edb .cell execution_count=8}\n``` {.python .cell-code}\n# Simulate Geometric Brownian Motion\nimport numpy as np\nimport matplotlib.pyplot as plt\n# number of paths\nn = 1000\n#number of divisions\nm = 1000\n# Interest rate (We set the drift equal to the interest rate for the risk-neutral probability)\nr = 0.1\n# Dividend yield\nq=0.0\n# Volatility\nsig = 0.2\n# Initial Stock Price\nS0 = 42\n# Maturity\nT = 0.5\n#Strike Price\nK=40\n# Delta t\ndt = T/m\n# Drift\ndrift = (r-q-0.5*sig**2)\n# Volatility\nvol = sig * np.sqrt(dt)\n\nt = np.array(range(0,m + 1,1)) * dt\n\n# seed for random generator\nseed= 2024\n# define a random generator\nnp.random.seed(seed)\ninc = np.zeros(shape = (m + 1, n))\ninc[1:] = np.transpose(np.random.normal(loc = 0, scale = vol,size = (n,m)))\nSt = np.zeros(shape = (m + 1, n))\nSt = S0 * np.exp(np.cumsum(inc,axis=0) + (drift * t[0:m + 1])[:,None])\nSt1 = S0 * np.exp(-np.cumsum(inc,axis=0) + (drift * t[0:m + 1])[:,None])\n```\n:::\n\n\nAs before this code generates two samples the original and the antithetic.  The output is an array of $n$ sample paths with $m$ time steps.  The sample can also be used to find the value of a floating strike lookback call.\n\n::: {#92fadded .cell execution_count=9}\n``` {.python .cell-code}\ndef floating_strike_call(S, r, sigma, q, T, SMin):\n    d1 = (np.log(S / SMin) + (r - q + 0.5 * sigma ** 2) * T) / (sigma * np.sqrt(T))\n    d2 = d1 - sigma * np.sqrt(T)\n    d2prime = (np.log(SMin / S) + (r - q - 0.5 * sigma ** 2) * T) / (sigma * np.sqrt(T))\n    N1 = norm.cdf(d1)\n    N2 = norm.cdf(d2)\n    N2prime = norm.cdf(d2prime)\n    x = 2 * (r - q) / (sigma ** 2)\n    return np.exp(-q * T) * S * N1 - np.exp(-r * T) * SMin * N2 + (1 / x) * (SMin / S) ** x * np.exp(-r * T) * SMin * N2prime - (1 / x) * np.exp(-q * T) * S * (1 - N1)\n\nS = 100\nr = 0.05\nsigma = 0.2\nq = 0.02\nT=1\n\nStmin=St[m:]-np.minimum(np.min(St,axis=0),S0)\nSt1min=St1[m:]-np.minimum(np.min(St1,axis=0),S0)\nfloatlkbk=np.exp(-r*T)*np.mean(Stmin)\nfloatlkbk1=np.exp(-r*T)*np.mean(St1min)\n\nprint('The first estimate is=',floatlkbk)\nprint('The second estimate is=',floatlkbk1)\nprint('The average estimate is=',(floatlkbk+floatlkbk1)/2)\nprint('The exact formula is=',floating_strike_call(S0, r, sigma, 0, T, S0))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThe first estimate is= 5.45244209168367\nThe second estimate is= 5.468030697490039\nThe average estimate is= 5.460236394586854\nThe exact formula is= 7.231056939691567\n```\n:::\n:::\n\n\nTo value the fixed strike lookback call option with time $T$ payoff $\\max(\\max_{0\\le t \\le T} S_t.0)$, we simply add the following \n\n::: {#6816746a .cell execution_count=10}\n``` {.python .cell-code}\nStmax=np.maximum(np.max(St,axis=0)-K,0)\nSt1max=np.maximum(np.max(St1,axis=0)-K,0)\nlookbck = np.exp(-r*T) *np.mean(Stmax)\nlookbck1=np.exp(-r * T)*np.mean(St1max)\nprint('The first estimate is=',lookbck)\nprint('The second estimate is=',lookbck1)\nprint('The average estimate is=', (lookbck + lookbck1)/2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThe first estimate is= 7.716467940991822\nThe second estimate is= 7.769558237964809\nThe average estimate is= 7.743013089478316\n```\n:::\n:::\n\n\nAsian and barrier options are also subject to discrete rather than continuous sampling and can be valued by Monte-Carlo in the same way as lookbacks. \n\n\nAs another example,  consider the classic case of estimating the value of a discretely-sampled average-price call, using a discretely-sampled geometric-average-price call \\index{average-price option} \\index{geometric-average option} as a control variate.  Let $\\tau$ denote the amount of time that has elapsed since the call was issued and $T$ the amount of time remaining before maturity, so the total maturity of the call is $T+\\tau$.  To simplify somewhat,  assume date $0$ is the beginning of a period between observations.  Let $t_1, \\ldots, t_N$ denote the remaining sampling dates, with $t_1 = \\Delta t$, $t_i-t_{i-1}=\\Delta t = T/N$ for each $i$, and $t_N=T$.  We will input the average price $A_0$ computed up to date $0$, assuming this average includes the price $S_0$ at date $0$.  The average price at date $T$ will be \n$$\nA_T = \\frac{\\tau}{T+\\tau}A_0 + \\frac{T}{T+\\tau}\\left(\\frac{\\sum_{i=1}^N S_{t_i}}{N}\\right)\\;.\n$$\nThe average-price call pays $\\max(0,A_T-K)$ at its maturity $T$, and we can write this as\n\\begin{align*}\n\\max(A_T-K,0) &= \\max\\left(\\frac{T}{T+\\tau}\\left( \\frac{\\sum_{i=1}^N S_{t_i}}{N}\\right) - \\left(K - \\frac{\\tau}{T+\\tau}A_0\\right), 0\\right)\\\\\n&= \\frac{T}{T+\\tau} \\max \\left(\\frac{\\sum_{i=1}^N S_{t_i}}{N} - K^*,0\\right)\\;,\n\\end{align*}\nwhere \n$$\nK^* = \\frac{T+\\tau}{T}K - \\frac{\\tau}{T}A_0\\;.\n$$\nTherefore, the value at date $0$ of the discretely-sampled average-price call is\n$$\n\\frac{T}{T+\\tau} \\,\\mathrm{e}^{-rT} \\\\E^R\\left[\\max \\left(\\frac{\\sum_{i=1}^N S_{t_i}}{N} - K^*,0\\right)\\right]\\;.\n$$\nIn terms of the discussion above, the random variable  the mean of which we want to estimate is\n$$\nx = \\mathrm{e}^{-rT}\\max \\left(\\frac{\\sum_{i=1}^N S_{t_i}}{N} - K^*,0\\right)\\;.\n$$\nA random variable $y$ that will be closely correlated to $x$ is\n$$\ny =\\mathrm{e}^{-rT}\\max \\left(\\mathrm{e}^{\\sum_{i=1}^N \\log S_{t_i}/N} - K^*,0\\right)\\;.\n$$\nThe mean $\\phi$ of $y$ under the risk-neutral probability is given in the pricing @eq-disc_geom_avg_call. \nWe can use the sample mean of $y$ and its known mean $\\phi$ to adjust the sample mean of $x$ as an estimator of the value of the average-price call.  Generally, the estimated adjustment coefficient $\\hat{\\beta}$ will be quite close to 1.\n\nAgain we can get a sample of payoffs using our stock price samples.\n\n::: {#67f05c7b .cell execution_count=11}\n``` {.python .cell-code}\naverage = np.mean(St,axis=0)\naverage1 = np.mean(St1,axis=0)\ndpayoff=np.exp(-r*T)*np.mean(np.maximum(average-K,0))\ndpayoff1=np.exp(-r*T)*np.mean(np.maximum(average1-K,0))\nprint('The first estimate is=',dpayoff)\nprint('The second estimate is=',dpayoff1)\nprint('The average of the estimates=',(dpayoff+dpayoff1)/2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThe first estimate is= 3.231154315344899\nThe second estimate is= 3.296876297130776\nThe average of the estimates= 3.2640153062378374\n```\n:::\n:::\n\n\nWe now construct a control variate, the geometric asian option which has a known formula for its value.\n\n::: {#d91c430e .cell execution_count=12}\n``` {.python .cell-code}\ndef black_scholes_call(S, K, r, sigma, q, T):\n    \"\"\"\n    Inputs:\n    S = initial stock price\n    K = strike price\n    r = risk-free rate\n    sigma = volatility\n    q = dividend yield\n    T = time to maturity\n    \"\"\"\n    if sigma == 0:\n        return max(0, np.exp(-q * T) * S - np.exp(-r * T) * K)\n    else:\n        d1 = (np.log(S / K) + (r - q + 0.5 * sigma ** 2) * T) / (sigma * np.sqrt(T))\n        d2 = d1 - sigma * np.sqrt(T)\n        N1 = norm.cdf(d1)\n        N2 = norm.cdf(d2)\n        return np.exp(-q * T) * S * N1 - np.exp(-r * T) * K * N2\n\ndef discrete_geom_average_price_call(S, K, r, sigma, q, T, N):\n    dt = T / N\n    nu = r - q - 0.5 * sigma ** 2\n    a = N * (N + 1) * (2 * N + 1) / 6\n    V = np.exp(-r * T) * S * np.exp(((N + 1) * nu / 2 + sigma ** 2 * a / (2 * N ** 2)) * dt)\n    sigavg = sigma * np.sqrt(a) / (N ** 1.5)\n    return black_scholes_call(V, K, r, sigavg, q, T)\n\ngeom=np.exp((np.mean(np.log(St),axis=0)))\ngeom1=np.exp((np.mean(np.log(St1),axis=0)))\ngeomavgpo=np.maximum(geom-K,0)\ngeomavg1po=np.maximum(geom1-K,0)\nvalue=np.mean(geomavgpo)*np.exp(-r*T)\nvalue1=np.mean(geomavg1po)*np.exp(-r*T)\ntga=discrete_geom_average_price_call(S0, K, r, sigma, q, T, m)\nerror =tga-value\nerror1=tga-value1\nprint('The estimate from the first sample=',value)\nprint('The estimate from the second sample=',value1)\nprint('The average of the two estimates is=',(value+value1)/2)\nprint('The value from the exact formula=',tga)\nprint('The error in the first estimate=',error)\nprint('The error in the second estimate=',error1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThe estimate from the first sample= 3.172076049997697\nThe estimate from the second sample= 3.236566795172543\nThe average of the two estimates is= 3.20432142258512\nThe value from the exact formula= 2.6835589764289125\nThe error in the first estimate= -0.4885170735687847\nThe error in the second estimate= -0.5530078187436307\n```\n:::\n:::\n\n\nNext we estimate the beta.  As discussed before, we could simply set beta=1. Alternatively, if we estimate beta from the  simulated sample, then our update could be biased.  Instead we compute an independent sample from which we estimate beta.  We then estimate the updated estimate for both samples from the formula\n$$\n \\text{new estimate} = \\text{original estimate} + \\beta * \\text{error}\n $$\n\n::: {#0eda498c .cell execution_count=13}\n``` {.python .cell-code}\nincpre = np.zeros(shape = (m + 1, n))\nincpre[1:] = np.transpose(np.random.normal(loc = 0, scale = vol,size = (n,m)))\nStpre = np.zeros(shape = (m + 1, n))\nSt1pre=np.zeros(shape = (m + 1, n))\nStpre = S0 * np.exp(np.cumsum(inc,axis=0) + (drift * t[0:m + 1])[:,None])\nSt1pre = S0 * np.exp(-np.cumsum(inc,axis=0) + (drift * t[0:m + 1])[:,None])\n\namean=np.mean(Stpre,axis=0)\namean1=np.mean(St1pre,axis=0)\napo = np.maximum(amean-K,0)\na1po=np.maximum(amean1-K,0)\ngmean=np.exp(np.mean(np.log(St),axis=0))\ng1mean=np.exp(np.mean(np.log(St1),axis=0))\ngpo=np.maximum(gmean-K,0)\ng1po=np.maximum(g1mean-K,0)\nbeta=np.cov(gpo,apo)[0,1]/np.cov(gpo,apo)[1,1]\nbeta1=np.cov(g1po,a1po)[0,1]/np.cov(g1po,a1po)[1,1]\nupdate=dpayoff +beta*error\nupdate1=dpayoff1+beta1*error1\n\nprint('The updated estimate for the first sample=',update)\nprint('The updated value for the second sample=',update1)\nprint('The average of the updated values is=',(update +update1)/2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThe updated estimate for the first sample= 2.7518403446698483\nThe updated value for the second sample= 2.7538925235582683\nThe average of the updated values is= 2.7528664341140585\n```\n:::\n:::\n\n\n## Monte Carlo Valuation of Basket and Spread Options {#sec-montecarlomultiple}\n\n\\index{basket option} \\index{spread option} \\index{Monte Carlo} In this section, we will consider the valuation of European spread and basket options by the Monte Carlo method.  As noted in @sec-s:baskets, there are no simple formulas for these options. In each simulation, we will generate a terminal price for each of the underlying assets and compute the value of the option at its maturity. \nDiscounting the average terminal value gives the estimate of the option value as usual.  \n\nThe difference between binomial and Monte Carlo methods for options written on multiple assets can be understood as follows.  Both methods attempt to estimate the discounted expected value of the option (under the risk-neutral probability).  In an $N$--period model, the binomial model produces $N+1$ values for the terminal price of each underlying asset.  Letting $k$ denote the number of underlying assets, this produces $(N+1)^k$ combinations of asset prices.  Of course, each combination has an associated probability.  In contrast, the Monte Carlo method produces $M$ combinations of terminal prices, where $M$ is the number of simulations.  Each combination is given the same weight ($1/M$) when estimating the expected value.  \n\nWith a single underlying asset, the binomial model is more efficient, as discussed in @sec-s:introbinomial, because the specifically chosen terminal prices in the binomial model sample the set of possible terminal prices more efficiently than randomly generated terminal prices.  However, this advantage disappears, and the ranking of the methods can be reversed, when there are several underlying assets.  The reason is that many of the $(N+1)^k$ combinations of prices in the binomial model will have very low probabilities.  For example, with two assets that are positively correlated, it is very unlikely that one asset will be at its highest value in the binomial model and the other asset simultaneously at its lowest.  It is computationally wasteful to evaluate the option for such a combination, because the probability-weighted value will be very small and hence contribute little to the estimate of the expected value.  On the other hand, each set of terminal prices generated by the Monte Carlo method will be generated from a distribution having the assumed correlation.  Thus, only relatively likely combinations will typically be generated, and time is not wasted on evaluating unlikely combinations.  However, it should not be concluded that Monte Carlo valuation of a derivative on multiple assets will be quick and easy---even though the computation time required for more underlying assets does not increase as much with Monte Carlo as for binomial models, it can nevertheless be substantial.\n\nTo implement Monte Carlo valuation of options on multiple assets, we must first explain how to simulate correlated asset prices.\nAs observed in @sec-s:stochasticvolatility, we can simulate the changes in two Brownian motions $B_1$ and $B_2$ that have correlation $\\rho$ by generating two independent standard normals $Z_1$ and $Z_2$ and defining\n$$\n\\Delta B_1 = \\sqrt{\\Delta t}\\,Z_1\\;, \\qquad \\text{and} \\qquad \\Delta B_2 = \\sqrt{\\Delta t}\\,Z\\; ,\n$$\nwhere $Z$ is defined as \n$$\nZ = \\rho Z_1 + \\sqrt{1-\\rho^2}\\,Z_2\\;.\n$$\nThe random variable $Z$ is also a standard normal, and the correlation between $Z_1$ and $Z$ is $\\rho$.  \n\n::: {#66b27962 .cell execution_count=14}\n``` {.python .cell-code}\n# Simulate 2 Geometric Brownian Motions\nimport numpy as np\nimport matplotlib.pyplot as plt\n# number of paths\nn = 1000\n#number of divisions\nm = 1000\n# Interest rate (We set the drift equal to the interest rate for the risk-neutral probability)\nr = 0.1\n# Dividend yield\nq1=0.0\nq2=0\n# Volatility\nsig1 = 0.2\nsig2=.3\n# correlation\nrho=0.5\n# Initial Stock Price\nS0 = 42\nV0 = 50\n# Maturity\nT = 0.5\n\n# Delta t\ndt = T/m\n# Drift\ndrift1 = (r-q1-0.5*sig1**2)\ndrift2 = (r-q2-0.5*sig2**2)\n# Volatility\nvol = np.sqrt(dt)\n\nt = np.array(range(0,m + 1,1)) * dt\n\n# seed for random generator\nseed= 2024\n# define a random generator\nnp.random.seed(seed)\ninc = np.zeros(shape = (m + 1, n))\ninc[1:] = np.transpose(np.random.normal(loc = 0, scale = vol,size = (n,m)))\ninc1 = np.zeros(shape = (m + 1, n))\ninc1[1:] = np.transpose(np.random.normal(loc = 0, scale = vol,size = (n,m)))\nincr = np.zeros(shape = (m + 1, n))\nincr = rho*inc + np.sqrt(1-rho**2)*inc1\n```\n:::\n\n\nThus, we can simulate the changes in the logarithms of two correlated asset prices as\n\\begin{align*}\n\\Delta \\log S_1 &= \\nu_1\\Delta t + \\sigma_1\\sqrt{\\Delta t}Z_1 \\; ,\\\\\n\\Delta \\log S_2 &= \\nu_2\\Delta t + \\sigma_2\\rho\\sqrt{\\Delta t}Z_1 + \\sigma_2\\sqrt{1-\\rho^2}\\sqrt{\\Delta t}Z_2\\;,\n\\end{align*}\nwhere $\\nu_i = r-q_1-\\sigma_i^2/2$ and the $Z_i$ are independent standard normals. \n\n::: {#150a4453 .cell execution_count=15}\n``` {.python .cell-code}\nSt1 = np.zeros(shape = (m + 1, n))\nSt2 = np.zeros(shape = (m + 1, n))\nSt1 = S0 * np.exp(sig1*np.cumsum(inc,axis=0) + (drift1 * t[0:m + 1])[:,None])\nSt2 = V0 * np.exp(sig2*np.cumsum(incr,axis=0) + (drift2 * t[0:m + 1])[:,None])\n```\n:::\n\n\nWe can also construct antithetic variables.\n\n::: {#aa1e3dbe .cell execution_count=16}\n``` {.python .cell-code}\nSt1a = np.zeros(shape = (m + 1, n))\nSt2a = np.zeros(shape = (m + 1, n))\nSt1a = S0 * np.exp(-sig1*np.cumsum(inc,axis=0) + (drift1 * t[0:m + 1])[:,None])\nSt2a = V0 * np.exp(-sig2*np.cumsum(incr,axis=0) + (drift2 * t[0:m + 1])[:,None])\n```\n:::\n\n\nGiven this sample, we can estimate the value of a best of 2 option with payoff $\\max(S_{1T},S_{2T})$.\n\n::: {#18fe51e3 .cell execution_count=17}\n``` {.python .cell-code}\npayoff = np.maximum(St1[m,:],St2[m,:])\npayoffa = np.maximum(St1a[m,:],St2a[m,:])\nvalue= np.exp(-r*T)*np.mean(payoff)\nvaluea= np.exp(-r*T)*np.mean(payoffa)\n\nprint('The first estmate is =',value)\nprint('The second estimate is =',valuea)\nprint('The avergae of the estimates is=',(value+valuea)/2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThe first estmate is = 50.11374784508302\nThe second estimate is = 51.46596027225067\nThe avergae of the estimates is= 50.78985405866685\n```\n:::\n:::\n\n\nTo generalize this idea to more than two assets, we introduce some additional notation.  The simulation for the case of two assets can be written as\n\n\n$$\n\\Delta \\log S_1 = \\nu_1\\Delta t + a_{11}\\sqrt{\\Delta t}Z_1 + a_{12}\\sqrt{\\Delta t}Z_2\\;,\n$$ {#eq-mc_twoa}\n\n$$\n\\Delta \\log S_2 = \\nu_2\\Delta t + a_{21}\\sqrt{\\Delta t}Z_1 + a_{22}\\sqrt{\\Delta t}Z_2\\;,\n$$ {#eq-mc_twob}\n\n\n\nwhere\n$$\\begin{array}{rclcrcl}\na_{11}&=&\\sigma_1\\;, &\\qquad & a_{12}&=&0\\; ,\\\\\na_{21}&=&\\sigma_2\\rho\\;, &\\qquad & a_{22} &= &\\sigma_2\\sqrt{1-\\rho^2}\\;.\n\\end{array}\n$$\n\nThese are not the only possible choices for the constants $a_{ij}$.  Given that $Z_1$ and $Z_2$ are independent standard normals, the conditions the $a_{ij}$ must satisfy in order to match the variances $\\sigma_i^2\\Delta t$ and correlation $\\rho$ of the changes in the logarithms are\n\n\n$$\na_{11}^2+a_{12}^2 =\\sigma_1^2\\;,\n$$ {#eq-a1}\n\n$$\na_{21}^2+a_{22}^2 =\\sigma_2^2\\;,\n$$ {#eq-a2}\n\n$$\na_{11}a_{21}+a_{12}a_{22} = \\sigma_1\\sigma_2\\rho\\;.\n$$ {#eq-a3}\n\n\n\nThese three equations in the four coefficients $a_{ij}$ leave one degree of freedom.  We choose to take $a_{12}=0$ and then solve for the other three.\n\nIn matrix notation, the system @eq-a1 - @eq-a3 plus the condition $a_{12}=0$ can be written as the equation\n$$\n\\begin{pmatrix}a_{11} & 0 \\\\a_{21} & a_{22}\\end{pmatrix}\\begin{pmatrix}a_{11} & 0 \\\\a_{21} & a_{22}\\end{pmatrix}^\\top = \\begin{pmatrix}\\sigma_1^2 & \\rho\\sigma_1\\sigma_2 \\\\\\rho\\sigma_1\\sigma_2 & \\sigma_2^2\\end{pmatrix}\\; ,\n$$\nwhere $^\\top$ denotes the matrix transpose.  The matrix on the right hand side is the covariance matrix \\index{covariance matrix} of the continuously-compounded annual returns (changes in log asset prices).  Choosing the $a_{ij}$ so that the lower triangular matrix \\index{lower triangular matrix}\n$$\nA \\equiv \\begin{pmatrix}a_{11} & 0 \\\\a_{21} & a_{22}\\end{pmatrix}\n$$\nsatisfies \n$$\nAA^\\top = \\text{covariance matrix}\n$$\nis called the \\index{Cholesky decomposition}\nthe Cholesky decomposition of the covariance matrix.  Given any number $L$ of assets, provided none of the assets is redundant (perfectly correlated with a portfolio of the  others), the Cholesky decomposition of the $L\\times L$ covariance matrix always exists. An algorithm for computing the Cholesky decomposition in numpy is np.linalg.cholesky. \n\nWe can use the Cholesky decomposition to perform Monte-Carlo valuation of a basket or spread option.^[For a spread option, take $L=2$, $w_1=1$ and $w_2=-1$.]  If there were some path dependency in the option value, we would simulate the paths of the asset prices as in @eq-mc_twoa - @eq-mc_twob.  However a standard basket option is not path dependent, so we only need to simulate the asset prices at the option maturity date $T$, as in @sec-s:mc_europeans.  The value of a basket call option at its maturity $T$ is \n$$\n\\max\\left(0,\\;\\sum_{i=1}^L w_iS_i_T-K\\right)\\; ,\n$$\nwhere $L$ is the number of assets in the basket (portfolio) and $w_i$ is the weight of the $i$--th asset in the basket.\nThe logarithm of the $i$--th asset price at maturity is simulated as\n$$\n\\log S_i_T = \\log S_i_0 +\\nu_iT + \\sqrt{T} \\sum_{j=1}^L a_{ij}Z_j\\; ,\n$$\nwhere the $Z_j$ are independent standard normals.  Given the simulated values of the $\\log S_i_T$, the value at maturity of the basket option is readily computed.  The estimate of the date--0 value is then computed as the discounted average of the simulated values at maturity.  \n\nFor our two asset example we compute the value of a call opttion on an equally weighted porfotlio.\n\n::: {#fd5c89f7 .cell execution_count=18}\n``` {.python .cell-code}\nw=0.5\nK=45\nbasketpo=np.maximum(w*St1[m,:]+(1-w)*St2[m,:]-K,0)\nbasketpoa=np.maximum(w*St1a[m,:]+(1-w)*St2a[m,:]-K,0)\nestimate=np.exp(-r*T)*np.mean(basketpo)\nestimatea=np.exp(-r*T)*np.mean(basketpoa)\nprint('The first estimate is =',estimate)\nprint('The second estimate is =',estimatea)\nprint('The average of the estimates=',(estimate+estimatea)/2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThe first estimate is = 4.4030641748675095\nThe second estimate is = 4.945665333101932\nThe average of the estimates= 4.674364753984721\n```\n:::\n:::\n\n\nBelow is a three asset basket option whihc uses the numpy cholesky decomposition.  In contrast to the above routine, this routine is does not have the option to  generate the entire path, although this can be easily modeified.\n\n::: {#7607352d .cell execution_count=19}\n``` {.python .cell-code}\nimport numpy as np\n#risk free rate\nr=0.1\n# number of assets\nk=3\n\n# number of paths\nn=100000\n# Horizon\nT=0.5\n\n# Initial price\n\nS0=[42,50,45]\n\n# Basket Weights\nw=[.25,.5,.25]\n\n#Strike Price\n\nK=45\n\n#  put in volatilities\nsig1=.2\nsig2=.3\nsig3=.4\n\n#create diagonal\nsig=[sig1,sig2,sig3]\n\nS=np.diag(sig)\n\n# drift of log returns\n\ndrift= r*np.ones(k) -0.5*np.dot(S@S,np.ones(k))\n\n\n# correlation matrix\n\nrho=np.array([[1.0, 0.5, 0.3],\n                  [0.5, 1.0, 0.2],\n                  [0.3, 0.2, 1.0]])\n# covariance matrix\n\nV = S@rho@S\n\n# generate uniform n*k normal uncorrelated random variables\n\nseed=2024\nnp.random.seed(seed)\n\ninc1=np.transpose(np.random.normal(loc = 0, scale = np.sqrt(T),size = (n,k)))\n \n\n\n# create correlated random variables\nZ=np.linalg.cholesky(V)\nincr=np.dot(Z,inc1)\n\nprint('The sample correlation matrix =',np.corrcoef(incr))\nprint('The input correlation matrix =',rho)\n\n\n\n\nSt = S0 * np.exp(drift *T + np.transpose(incr))\n#antithetic sample\nSt1 = S0 * np.exp( drift * T - np.transpose(incr))\n\nestimate=np.mean(St,axis=0)*np.exp(-r*T)\nestimate1=np.mean(St1,axis=0)*np.exp(-r*T)\nprint('The average discounted stock price averaged over both samples=',(estimate+estimate1)/2)\nprint('The initial Srock Price input =',S0)\n\nbasketpo=np.maximum(w@np.transpose(St)-K,0)\nbasketpo1=np.maximum(w@np.transpose(St1)-K,0)\nvalue=np.mean(basketpo)*np.exp(-r*T)\nvalue1=np.mean(basketpo1)*np.exp(-r*T)\nprint('The first sample estimate of the basket option value=',value)\nprint('The second sample estimate of the basket option value=',value1)\nprint('The average estimate of the basket option value=',(value+value1)/2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThe sample correlation matrix = [[1.         0.50356746 0.30497838]\n [0.50356746 1.         0.20383175]\n [0.30497838 0.20383175 1.        ]]\nThe input correlation matrix = [[1.  0.5 0.3]\n [0.5 1.  0.2]\n [0.3 0.2 1. ]]\nThe average discounted stock price averaged over both samples= [42.00560021 50.00484037 45.01680115]\nThe initial Srock Price input = [42, 50, 45]\nThe first sample estimate of the basket option value= 5.335894164783821\nThe second sample estimate of the basket option value= 5.289353051200051\nThe average estimate of the basket option value= 5.312623607991936\n```\n:::\n:::\n\n\nWe can generate the entire path of multiple assets to value, for example, lookback options on a basket.  The code below values the same European basket option as above only it calculates $m=2$ time steps;  a lookback can be created by changing the payoffs and increasing $m$.\n\n::: {#644c9bad .cell execution_count=20}\n``` {.python .cell-code}\nimport numpy as np\n#number of time steps\nm=2\n# number of assets\nk=3\n# number of sample paths\nn=100000\n\n#risk free rate\nr=0.1\n\n\n\n# Horizon\nT=0.5\n# delta t\ndt=T/m\n# Initial price\n\nS0=[42,50,45]\n\n#Strike Price\n\nK=45\n\n#  put in volatilities\nsig1=.2\nsig2=.3\nsig3=.4\n\n#create diagonal\nsig=[sig1,sig2,sig3]\n\nS=np.diag(sig)\n\n\n# correlation matrix\n\nrho=np.array([[1.0, 0.5, 0.3],\n                  [0.5, 1.0, 0.2],\n                  [0.3, 0.2, 1.0]])\n\n# covariance matrix\n\nV = S@rho@S\n\n# drift of log returns\ndrift= np.array(r*np.ones(k) -0.5*np.dot(S@S,np.ones(k)))*dt\n\n# times vector\nt=np.array(range(1,m + 1,1))\n\n\ndriftv = np.transpose(np.kron(drift,t).reshape(3,m))\n\n# generate uniform n(paths)*k(assets)*m(time steps) normal uncorrelated random variables\n\nseed=2024\nnp.random.seed(seed)\n\ninc=np.random.normal(loc = 0, scale = np.sqrt(dt),size = (n,k,m))\n\n#create correlated random increments\nZ=np.linalg.cholesky(V)\n# numpy matmul assumes last two define matrix multiplication\nincr=np.matmul(Z,inc)\n\n\n\nSSt=S0*np.exp(driftv)\n\n# generate returns along path and antithetic path\n# first e^{cumsum(increments)} gives e^sigma B_t for different t\n\nStb = np.exp(np.cumsum(incr[:,:,],axis=2))\nStb1 = np.exp(-np.cumsum(incr[:,:,],axis=2))\n\n\n#Multiply by S0 e^drift for each t\nSt=np.multiply(Stb,np.transpose(SSt))\nSt1=np.multiply(Stb1,np.transpose(SSt))\n\n#Last date returns\nStm=St[:,:,m-1]\nStm1=St1[:,:,m-1]\n\n#define payoff\n# Basket Weights\nw=[.25,.5,.25]\n\n\npayoff= np.maximum(np.matmul(Stm,np.transpose(w))-K,0)\npayoff1= np.maximum(np.matmul(Stm1,np.transpose(w))-K,0)\n\n\nvalue= np.exp(-r*T)*np.mean(payoff)\nvalue1= np.exp(-r*T)*np.mean(payoff1)\nprint('The estimate for the first sample value=',value)\nprint('The estimate for the second sample value=',value1)\nprint('The average estimate for the value=',(value+value1)/2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThe estimate for the first sample value= 5.310173600480473\nThe estimate for the second sample value= 5.287928240443306\nThe average estimate for the value= 5.299050920461889\n```\n:::\n:::\n\n\n## {.unnumbered}\n\n",
    "supporting": [
      "Chapter_MonteCarlo_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}