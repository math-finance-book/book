{
  "hash": "f251bbdfdc1bbc64265d9db963badd15",
  "result": {
    "engine": "jupyter",
    "markdown": "\\newcommand{\\d}{\\,\\mathrm{d}}\n\\newcommand{\\e}{\\mathrm{e}}\n\\newcommand{\\E}{\\mathbb{E}}\n\n\n\n# Ito's Formula {#sec-c_ito}\n\nWe use the changes of a Brownian motion to model randomness.  We build other stochastic process using those changes.  The general idea is\n$$\\text{change} = \\text{mean} + \\text{std dev} \\times \\text{change in Brownian motion}\\,.$$\nThe mathematical foundations for this construction, using changes in infinitesimal time periods so that we can model all frequencies, were created by K. Ito.  The key concepts are called the Ito integral and Ito's formula (also called Ito's lemma).  Using these techniques, we can build quite general processes, including processes with non-normal distributions.\n\n## From Discrete to Continuous Time {#sec_f_discrete}\n\nWe begin with some simple discrete-time examples.  Consider a discrete partition of a time interval as before\n$$0=t_0 < t_1< \\cdots < t_{n-1} < t_n=t$$\nwith equally spaced times.  Let $\\Delta t$ denote the difference between successive times.  \n\nFirst, we drop the randomness entirely.  Consider the equation\n$$X_{t_i} - X_{t_{i-1}} = \\mu X_{t_{i-1}}$$\nfor a constant $\\mu$.  Thus, we have ``change $\\,=\\,$ mean,'' where the mean is proportional to the previous value.  @fig-discrete-interest presents a plot of $X$, for particular values of $\\mu$, $X_0$, $t$, and $n$.\n\nIf we increase $n$, making $\\Delta t$ smaller, then $X$ will converge to the solution of the ordinary differential equation\n$$\\d X_t = \\mu X_t\\,\\d t\\,.$$\nThe solution of this equation is also shown in @fig-discrete-interest.  The differential equation has a known solution, which is \n$$X_t = X_0 \\e^{\\mu t}\\,.$$\nTo verify this, we only need to differentiate:\n$$\\frac{\\d X_t}{\\d t} = \\mu X_0 \\e^{\\mu t} = \\mu X_t\\,.$$\n\nNow, let's include randomness.  Let $B$ be a standard Brownian motion and consider the equation\n$$X_{t_i} - X_{t_{i-1}} = \\mu X_{t_{i-1}} + \\sigma \\Delta B_{t_i}$$\nwhere $\\sigma$ is another constant, and $\\Delta B_{t_i} = B_{t_i} - B_{t_{i-1}}$.  Now, the process $X$ has random paths, due to the random noise $\\Delta B_{t_i}$.  An example of a path is shown in @fig-discrete-random.\nIto showed how we can take the limit of this equation as $\\Delta t$ decreases and make sense of the equation\n$$\\d X_t = \\mu X_t\\,\\d t + \\sigma\\,\\d B_t\\,.$$\nThe solution $X$ of this equation is\n$$X_t = \\e^{\\mu t}X_0 + \\int_0^t \\e^{\\mu(s-t)}\\,\\d B_s\\,.$$\nThe integral in this solution is called an Ito integral.\nAn approximate path of this process $X$ is also shown in @fig-discrete-random.  It is generated by taking $\\Delta t$ very small, just as we generated approximate paths of Brownian motions in @sec-c_brownian.  \n\n## Ito Processes {#sec-s_itoprocesses}\nAn Ito process is a variable $X$ that changes over time as \\index{Ito process}\n$$\n\\d  X_t = \\mu_t\\,\\d  t+\\sigma_t\\,\\d  B_t\\;,\n$$ {#eq-itoprocess}\n\nwhere $B$ is a Brownian motion, and $\\mu$ and $\\sigma$ can also be random processes.  Some regularity conditions are needed on $\\mu$ and $\\sigma$ which we will omit, except for noting that $\\mu_t$ and $\\sigma_t$ should be known at time $t$.  In particular, constant $\\mu$ and $\\sigma$ are certainly acceptable.  When we add the changes over time, we get\n$$X_t=X_0 + \\int_0^T\\mu_t\\,\\d  t + \\int_0^T\\sigma_t\\,\\d  B_t$$\nfor any $T>0$.  There are other types of random processes, in particular, processes that can jump, but we will not consider them in this book.\n\nWe will not formally define the integral $\\int_0^T \\sigma_t\\,\\d  B_t$, but it should be understood as being approximately equal to a discrete sum of the form \n$$\\sum_{i=1}^N \\sigma_{t_{i-1}}\\,\\Delta B_{t_i}\\; ,$$\nwhere $0=t_0 < \\cdots t_N=T$ and the time periods $t_i-t_{i-1}$ are small.  Given that we can simulate the changes $\\Delta B_{t_i}$ as random normals, we can approximately simulate the random variable $\\int_0^T \\sigma_t\\,\\d  B_t$ and hence we can approximately simulate $X_t$.\n\nAn Ito process evolves continuously over time.  We interpret $\\mu_t\\,\\d  t$ as the expected change in $X$ in an instant $\\d  t$.  The quantity $\\mu_t$  is also called the drift of the process $X$ at time $t$.   \\index{drift} The coefficient $\\sigma_t$ is called the diffusion coefficient of $X$ at time $t$.  \\index{diffusion coefficient}\n\nIf $\\mu$ and $\\sigma$ are constant, it is standard to refer to an Ito process $X$ as a $(\\mu,\\sigma)$--Brownian motion.  In this case we have\n$$X_t= \\mu t + \\sigma B_t$$\n\nOf course, it is not a martingale when $\\mu\\neq 0$.  For example, when $\\mu>0$, $X$ tends to increase over time.  However, it has the jiggling property of a Brownian motion, scaled by the diffusion coefficient $\\sigma$. \n\nA very important fact is that an Ito process such as $X$ in @eq-itoprocess can be a martingale only if $\\mu=0$.  This should seem sensible, because $\\mu\\,\\d  t$ is the expected change in $X$, and a process is a martingale only if its expected change is zero.^[If the sources of uncertainty in the market can be modeled as Brownian motions, then in fact every martingale is an Ito process with $\\mu=0$.  This is some justification for the assumption we will make in this book, when studying continuous-time models, that all martingales are Ito processes.]   This observation plays a fundamental role in deriving asset pricing formulas, as we will begin to see in @sec-s_girsanov.\nConversely, if $\\mu=0$ and \n$$\n\\E \\left[\\int_0^T \\sigma^2_t\\,\\d  t\\right] < \\infty\n$$ {#eq-regularity1}\n\nfor each $T$, then the Ito process is a continuous martingale, and the variance of its date--$T$ value, calculated with the information available at date $0$, is:\n$$\\mathrm{var}[X_t] = \\E \\left[\\int_0^T \\sigma^2_t\\,\\d  t\\right]\\; .$$  \n\nWhether $\\mu$ is zero or not, and independently of the assumption stated as @eq-regularity1, the quadratic variation of the Ito process $X$ is \n$$\n\\lim_{N \\rightarrow \\infty} \\sum_{i=1}^N[\\Delta X_{t_i}]^2 = \\int_0^T \\sigma^2_t\\,\\d  t\n$$ {#eq-itoquadraticvariation}\n\nwith probability one.  Thus we obtain (when $\\mu=0$ and @eq-regularity1 holds) a continuous martingale with a different quadratic variation than a Brownian motion via the diffusion function $\\sigma$.  In fact, when @eq-regularity1 holds, a somewhat more precise definition of the stochastic integral is the (unique) martingale with quadratic variation given by @eq-itoquadraticvariation.\n\nTo compute the quadratic variation of an Ito process, we use the following simple and important rules (for the sake of brevity, we drop the $_t$ notation from $B_t$ here and sometimes later):\n\n::: Rule\n## \n\n\n$$\n(\\d  t)^2 = 0\\;, \n$$ {#eq-dtsquared}\n\n$$\n(\\d  t)(\\d  B) =0\\;, \n$$ {#eq-dB}\n\n$$\n(\\d  B)^2 =\\d  t\\;. \n$$ {#eq-dBsquared}\n\n\n\n:::\n\n\nWe apply these rules to compute the quadratic variation of $X$ as follows:\n\n::: Rule\n## \nIf $\\d  X = \\mu\\,\\d  t + \\sigma\\,\\d  B$ for a Brownian motion $B$, then\n\\begin{align*}\n(\\d  X)^2 &= (\\mu\\,\\d  t+\\sigma\\,\\d  B)^2\\\\\n&= \\mu^2(\\d  t)^2 + 2\\mu\\sigma(\\d  t)(\\d  B) + \\sigma^2(\\d  B)^2\\\\\n&= 0 + 0 + \\sigma^2\\,\\d  t\\;.\n\\end{align*}\n:::\n\nWe integrate this from 0 to $T$ to obtain the quadratic variation @eq-itoquadraticvariation over that time period:^[In a more formal mathematical presentation, one normally writes $\\d \\langle X,X\\rangle$ for what we are writing here as $(\\d  X)^2$.  This is the differential of the quadratic variation process, and the quadratic variation through date $T$ is\n$$\n\\langle X,X\\rangle _t = \\int_0^T \\d \\langle X,X\\rangle_t = \\int_0^T \\sigma^2_t\\,\\d  t\\;.\n$$]\n$$\n\\int_0^T (\\d  X_t)^2 = \\int_0^T \\sigma^2_t\\,\\d  t\\;.\n$$ {#eq-itoquadraticvariation2}\n\n\n\n\n## Ito's Formula {#sec-s_itosformula}\n\nFirst we recall some facts of the ordinary calculus.  If $y=g(x)$ and $x = f_t$ with $f$ and $g$ being continuously differentiable functions, then \n$$\\frac{\\d  y}{\\d  t} = \\frac{\\d  y}{\\d  x}\\times \\frac{\\d  x}{\\d  t} = g'(x_t)f'_t\\; .$$\nOver a time period $[0,T]$, this implies that\n$$y_t = y_0 + \\int_0^T \\frac{\\d  y}{\\d  t}\\,\\d  t = y_0 + \\int_0^T g'(x_t)f'_t\\,\\d  t\\; .$$\nSubstituting $\\d  x_t = f'_t\\,\\d  t$, we can also write this as\n$$\ny_t = y_0 + \\int_0^T g'(x_t)\\,\\d  x_t\\;.\n$$ {#eq-ordinarycalculus}\n\n\nWe can contrast  @eq-ordinarycalculus  with a special case of Ito's formula for the calculus of Ito processes (the more general formula will be discussed in the next section).  If $B$ is a Brownian motion and $Y = g(B)$ for a twice-continuously differentiable function $g$, then \\index{Ito's formula}\n$$\nY_t = Y_0 + \\int_0^T g'(B_t)\\,\\d  B_t + \\frac{1}{2}\\int_0^T g''(B_t)\\,\\d  t\\;.\n$$ {#eq-itonew1}\n\nThus, relative to the ordinary calculus, Ito's formula has an extra term involving the second derivative $g''$.  We can write @eq-itonew1 in differential form as\n$$\\,\\d  Y_t = \\frac{1}{2}g''(B_t)\\,\\d  t + g'(B_t)\\,\\d  B_t.$$\nThus, $Y=g(B)$ is an Ito process with drift $g''(B_t)/2$ and diffusion coefficient $g'(B_t)$.\n\nTo gain some intuition for the extra term in Ito's formula, we return to the ordinary calculus.  Given dates $t<u$, the derivative defines a linear approximation of the change in $y$ over this time period; i.e., setting $\\Delta x = x(u)-x_t$ and $\\Delta y = y(u) - y_t$, we have the approximation\n$$\\Delta y \\approx g'(x_t) \\,\\Delta x\\; .$$\nA better approximation is given by the second-order Taylor series expansion\n$$\\Delta y \\approx g'(x_t)\\,\\Delta x + \\frac{1}{2} g''(x_t)\\,[\\Delta x]^2\\; .$$\nAn interpretation of  @eq-ordinarycalculus is that the linear approximation works perfectly for infinitesimal time periods $\\d  t$, because we can compute the change in $y$ over the time period $[0,T]$ by summing up the infinitesimal changes $g'(x_t)\\,\\d  x_t$.  In other words, the second-order term $\\frac{1}{2} g''(x_t)\\,[\\Delta x]^2$ vanishes when we consider very small time periods.\n\nThe second-order Taylor series expansion in the case of $Y=g(B)$ is \n$$\\Delta Y \\approx g'(B_t)\\,\\Delta B + \\frac{1}{2} g''(B_t)\\,[\\Delta B]^2\\; .$$\nFor example, given a partition $0=t_0 < t_1 < \\cdots < t_N=T$ of the time interval $[0,T]$, we have, with the same notation we have used earlier,\n\n$$\nY_t = Y_0 + \\sum_{i=1}^N \\Delta Y_{t_i}  \n$$\n$$\n\\approx Y_0 + \\sum_{i=1}^N g'(B_{t_{i-1}})\\,\\Delta B_{t_i} + \\frac{1}{2} \\sum_{i=1}^N g''(B_{t_{i-1}})\\,[\\Delta B_{t_i}]^2\\;.\n$$ {#eq-itonew2}\n\n\nIf we make the time intervals $t_i-t_{i-1}$ shorter, letting $N \\rightarrow \\infty$, then we cannot expect that the extra term here will disappear, leading to the result  of the ordinary calculus shown in@eq-ordinarycalculus, because we know that\n$$\\lim_{N \\rightarrow \\infty} \\sum_{i=1}^N [\\Delta B_{t_i}]^2 = T\\; ,$$\nwhereas for the continuously differentiable function $x_t = f_t$, the same limit is zero.  In fact it seems sensible to interpret the limit of $[\\Delta B]^2$ as $(\\d  B)^2 =\\d  t$.\nThis is perfectly consistent with Ito's formula: if we take the limit in @eq-itonew2, replacing the limit of $[\\Delta B_{t_i}]^2$ with $(\\d  B)^2 = \\d  t$, we obtain @eq-itonew1.\n\nThe code below defines a function $g(x)=e^{x}$ ($g'(x)=e^x$ and $g''(x) = e^x$) and simulates the value $e^{B_t}$ in two ways.  The first way is to simulate the Ito expansion\n$$e^{B_t}=1 + \\int_0^t e^{B_s} d B_s + \\frac{1}{2}\\int_0^t e^{B_s} ds$$\nusing the discretization\n$$\\Delta e^{B_t}= e^{B_t} \\Delta B_t + \\frac{1}{2} e^{B_t} \\Delta t $$\n\n::: {#cell-simulated_ito .cell execution_count=1}\n``` {.python .cell-code}\n\"\"\"\nimport numpy as np\n\nn = 1000\nm = 1\n\n# Define a function and its first and second derivative\nG = lambda x: np.exp(x)\nDG = lambda x: np.exp(x)\nDDG = lambda x: np.exp(x)\n# Build G'(x)\\,\\d  B\nGdB = np.zeros(shape = (n, m))\nGdB[0] = np.repeat(DG_0, m) * inc[0]\nGdB[1:] = DG(Bt[0:n - 1]) * inc[1:]\nSI = np.zeros(shape = (n, m))\n# Stochastic Integral is cumulative sum of G'(B)dB plus initial\nSI = GdB.cumsum(axis = 0) + 0.5 * (DDG(Bt[0:n])*Q).cumsum(axis =0) + G_0\n# Compare Ito's Lemma \nplt.figure(figsize=(9,6))\nplt.plot(t[0:n], SI[:,0])\n\"\"\"\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n<>:1: SyntaxWarning:\n\ninvalid escape sequence '\\,'\n\n<>:1: SyntaxWarning:\n\ninvalid escape sequence '\\,'\n\nC:\\Users\\kerry\\AppData\\Local\\Temp\\ipykernel_11684\\3168237844.py:1: SyntaxWarning:\n\ninvalid escape sequence '\\,'\n\n```\n:::\n\n::: {#simulated_ito .cell-output .cell-output-display execution_count=1}\n```\n\"\\nimport numpy as np\\n\\nn = 1000\\nm = 1\\n\\n# Define a function and its first and second derivative\\nG = lambda x: np.exp(x)\\nDG = lambda x: np.exp(x)\\nDDG = lambda x: np.exp(x)\\n# Build G'(x)\\\\,\\\\d  B\\nGdB = np.zeros(shape = (n, m))\\nGdB[0] = np.repeat(DG_0, m) * inc[0]\\nGdB[1:] = DG(Bt[0:n - 1]) * inc[1:]\\nSI = np.zeros(shape = (n, m))\\n# Stochastic Integral is cumulative sum of G'(B)dB plus initial\\nSI = GdB.cumsum(axis = 0) + 0.5 * (DDG(Bt[0:n])*Q).cumsum(axis =0) + G_0\\n# Compare Ito's Lemma \\nplt.figure(figsize=(9,6))\\nplt.plot(t[0:n], SI[:,0])\\n\"\n```\n\nSimulated Ito Formula\n:::\n:::\n\n\nBelow is the exact simulated solution $e^{B_t}$.  It is almost impossible to see a difference.\n\n::: {#cell-simulated_exact .cell execution_count=2}\n``` {.python .cell-code}\n#exact solution\n\"\"\"\nplt.figure(figsize=(9,6))\nplt.plot(t[0:n], G(Bt[1:n + 1, 0]))\n\"\"\"\n```\n\n::: {#simulated_exact .cell-output .cell-output-display execution_count=2}\n```\n'\\nplt.figure(figsize=(9,6))\\nplt.plot(t[0:n], G(Bt[1:n + 1, 0]))\\n'\n```\n\nSimulated Exact Solution\n:::\n:::\n\n\nBelow we plot the $\\int_0^t \\frac{1}{2} g''(B_s) ds$ term.  Without this term the two plots above will not match.\n\n::: {#cell-correction .cell execution_count=3}\n``` {.python .cell-code}\n\"\"\"\nQVV = np.zeros(shape = (n, m))\nQVV = 0.5*(DDG(Bt[0:n]) * Q).cumsum(axis = 0)\nplt.figure(figsize=(9,6))\nplt.plot(t[0:n], QVV[:,0])\n\"\"\"\n```\n\n::: {#correction .cell-output .cell-output-display execution_count=3}\n```\n'\\nQVV = np.zeros(shape = (n, m))\\nQVV = 0.5*(DDG(Bt[0:n]) * Q).cumsum(axis = 0)\\nplt.figure(figsize=(9,6))\\nplt.plot(t[0:n], QVV[:,0])\\n'\n```\n\nSecond Derivative Term in Ito's Formula\n:::\n:::\n\n\nTo see the accuracy of Ito's approximation over different amounts of subdivisions, as well as the impact of the second derivative term $\\int_0^t (1/2)g''(B_s)ds$, we encourage readers to interact with the plot below.\n\n::: {#fig-interactive_ito}\n<iframe width=\"780\" height=\"1000\" src=\"https://derivatives-book-26ac36570fb8.herokuapp.com/math_finance_book_plots/ito_approx_plot\"></iframe>\n\nAccuracy of Ito's approximation\n:::\n\n\n## Multiple Ito Processes\n\nNow consider two Ito processes\n\n\n$$\n\\d  X_t = \\mu_x_t\\,\\d  t + \\sigma_x_t\\,\\d  B_x_t\\;,\n$$ {#eq-itoprocess110}\n\n$$\n\\d  Y_t = \\mu_y_t\\,\\d  t + \\sigma_y_t\\,\\d  B_y_t\\;,\n$$ {#eq-itoprocess111}\n\n\n\nwhere $B_x$ and $B_y$ can be different Brownian motions.  The relation between the two Brownian motions is determined by their covariance or correlation.  Given dates $t<u$, we know that both changes $B_x(u)-B_x_t$ and $B_y(u)-B_y_t$ are normally distributed with mean 0 and variance equal to $u-t$.  There will exist a (possibly random) process $\\rho$ such that the covariance \\index{covariance} of these two normally distributed random variables, given the information at date $t$, is \n$$\\E_t \\left[\\int_t^u \\rho_s\\,\\d  s\\right]\\; .$$\nThe process $\\rho$ is called the correlation coefficient of the two Brownian motions, \\index{correlation coefficient} because when it is constant the correlation of the changes $B_x(u)-B_x_t$ and $B_y(u)-B_y_t$ is\n$$\\frac{\\text{covariance}}{\\text{product of standard deviations}}  = \\frac{\\int_t^u \\rho \\,\\d  s}{\\sqrt{u-t} \\sqrt{u-t}} = \\frac{(u-t)\\rho}{u-t} = \\rho\\; .$$\nMoreover, given increasingly fine partitions $0=t_0 < \\cdots < t_N=T$ of an interval $[0,T]$ as before, we will have\n$$\\sum_{i=1}^N \\Delta B_x_{t_i} \\times \\Delta B_y_{t_i} \\rightarrow \\int_0^T \\rho_t\\,\\d  t$$\nas $N \\rightarrow \\infty$, with probability one.  \n\nWe know that\n$$\\sum _{i=1}^N [\\Delta X_{t_i}]^2 \\rightarrow \\int_0^T \\sigma_x^2_t\\,\\d  t \\quad \\text{and}\\quad  \\sum _{i=1}^N [\\Delta Y_{t_i}]^2 \\rightarrow \\int_0^T\\sigma_y^2_t\\,\\d  t\\;.\n$$ {#eq-itoprocess112}\n\nFurthermore, it can be shown that the sum of products satisfies\n$$\n\\sum_{i=1}^N \\Delta X_{t_i} \\times \\Delta Y_{t_i} \\rightarrow \\int_0^T \\sigma_x_t\\sigma_y_t\\rho_t\\,\\d  t\\;.\n$$ {#eq-itoprocess113}\n\n\n::: Rule\n## \nBy adding the rule \n$$\n(\\d  B_x)(\\d  B_y) = \\rho\\,\\d  t \n$$ {#eq-\\,\\d  B\\,\\d  B}\n to the rules @eq-\\,\\d  tsquared--@eq-\\,\\d  Bsquared, we can compute the limit in @eq-itoprocess113 as\n\n$$\n\\lim_{N \\rightarrow\\infty} \\sum_{i=1}^N \\Delta X_{t_i} \\times \\Delta Y_{t_i}  = \\int_0^T (\\d  X)(\\d  Y)\n$$\n$$\n= \\int_0^T (\\mu_x\\,\\d  t +\\sigma_x\\,\\d  B_x)(\\mu_y\\,\\d  t+\\sigma_y\\,\\d  B_y)\n$$\n$$\n= \\int_0^T\\sigma_x_t\\sigma_y_t \\rho_t\\,\\d  t\\;.\n$$ {#eq-itojointvariation}\n\n\n:::\n\n\nThe most general case of Ito's formula that we will need is for a function $Z_t = g(t, X_t, Y_t)$ where $X$ and $Y$ are Ito processes as in @eq-itoprocess110 - @eq-itoprocess111.  In this case, Ito's formula is^[We need to assume $g(t,x,y)$ is continuously differentiable in $t$ and twice continuously differentiable in $(x,y)$ for @eq-itogeneralnew and @eq-itogeneralnew2 to be valid.  Note also that we are using a short-hand notation here.  The partial derivatives of $g$ will generally depend on $t$, $X_t$ and $Y_t$ just as $g$ does.]\n\n$$\nZ_t = Z_0 + \\int_0^T \\frac{\\partial g}{\\partial t}\\,\\d  t + \\int_0^T \\frac{\\partial g}{\\partial x}\\,\\d  X_t + \\int_0^T \\frac{\\partial g}{\\partial y}\\,\\d  Y_t \n$$\n$$\n+ \\frac{1}{2} \\int_0^T \\frac{\\partial^2 g}{\\partial x^2}\\,(\\d  X_t)^2 +  \\frac{1}{2} \\int_0^T \\frac{\\partial^2 g}{\\partial y^2}\\,(\\d  Y_t)^2 \n$$\n$$\n+  \\int_0^T \\frac{\\partial^2 g}{\\partial x\\partial y}\\,(\\d  X_t)( \\d  Y_t)\\;.\n$$ {#eq-itogeneralnew}\n\n\nIn this equation, we apply  @eq-dtsquared--@eq-dB to compute\n\\begin{align*}\n(\\d  X_t)^2&= \\sigma_x^2_t\\,\\d  t\\; ,\\\\\n(\\d  Y_t)^2 &= \\sigma_y^2_t\\,\\d  t\\; ,\\\\\n(\\d  X_t)( \\d  Y_t) &= \\sigma_x_t\\sigma_y_t\\rho_t\\,\\d  t\\;.\n\\end{align*}\nIto's formula (@eq-itogeneralnew) appears a bit simpler (and easier to remember) if we write it in differential form.  We have:\n\n\n::: Rule\n## \nIf $Z_t = g(t, X_t, Y_t)$ where $X$ and $Y$ are Ito processes as in @eq-itoprocess110 - @eq-itoprocess111, then\n\n$$\n\\d  Z =  \\frac{\\partial g}{\\partial t}\\,\\d  t + \\frac{\\partial g}{\\partial x}\\,\\d  X +  \\frac{\\partial g}{\\partial y}\\,\\d  Y + \\frac{1}{2} \\frac{\\partial^2 g}{\\partial x^2}\\,(\\d  X)^2 +  \\frac{1}{2}  \\frac{\\partial^2 g}{\\partial y^2}\\,(\\d  Y)^2 \n$$\n$$\n+ \\frac{\\partial^2 g}{\\partial x\\partial y}\\,(\\d  X)(\\d  Y)\\;.\n$$ {#eq-itogeneralnew2}\n\n\n\n:::\n\n\n## Examples of Ito's Formula {#sec-s_examples}\nThe following are the applications of Ito's formula that will be used most frequently in the book.  They follow from the boxed formula at the end of the previous section by taking $g(x,y)=xy$ or $g(x,y)=y/x$ or $g(x)=e^x$ or $g(x) = \\log x$.\n\n\n\n\n::: Rule\n\n**Products.**\nIf $Z=XY$, then $\\d  Z=X\\,\\d  Y+Y\\,\\d  X + (\\d  X)(\\d  Y)$.  We can write this as\n$$\n\\frac{\\d  Z}{Z}=\\frac{\\d  X}{X} + \\frac{\\d  Y}{Y} + \\left(\\frac{\\d  X}{X}\\right)\\left(\\frac{\\d  Y}{Y}\\right)\\;.\n$$ {#eq-rule2}\n\n\n:::\n\n\n\n\n::: Rule\n\n**Ratios.**\nIf $Z=Y/X$, then \n$$\\frac{\\d  Z}{Z} = \\frac{\\d  Y}{Y} -\\frac{\\d  X}{X} - \\left(\\frac{\\d  Y}{Y}\\right)\\left(\\frac{\\d  X}{X}\\right) + \\left(\\frac{\\d  X}{X}\\right)^2\\;.\n$$ {#eq-rule4}\n\n\n:::\n\n\n\n::: Rule\n\n**Exponentials.**\nIf $Z=\\mathrm{e}^X$, then \n$$\\frac{\\d  Z}{Z}=\\d  X + \\frac{(\\d  X)^2}{2}\\;.\n$$ {#eq-rule5}\n\n\n:::\n\n\n\n::: Rule\n\n**Logarithms.**\nIf $Z=\\log X$, then\n$$\n\\d  Z=\\frac{\\d  X}{X} - \\frac{1}{2}\\left(\\frac{\\d  X}{X}\\right)^2\\;.\n$$ {#eq-rule6}\n\n\n:::\n\n\n\n::: Rule\n\n**Compounding/Discounting.**\nLet  \n$$Y_t =\\exp\\left(\\int_0^t q_s\\,\\d  s\\right)$$\nfor some (possibly random) process $q$ and define $Z=XY$ for any Ito process $X$.\nThe usual calculus gives us \n$\\d  Y_t=q_tY_t\\,\\d  t$,\nand the product rule above implies\n$$\n\\frac{\\d  Z}{Z}=q\\,\\d  t + \\frac{\\d  X}{X}\\;.\n$$ {#eq-compdisc1}\n\nThis is the same as in the usual calculus.  \n\n:::\n\n\n\n\n## Reinvesting Dividends {#sec-s_reinvestingdividends}\n\nFrequently, we will assume that the asset underlying a derivative security pays a constant dividend yield, \\index{dividend yield} which we will denote by $q$.  This means, for an asset with price $S_t$, that the dividend in an instant $\\d  t$ is $q S_t\\,\\d  t$.  If the dividends are reinvested in new shares, the number of shares will grow exponentially at rate $q$.  To see this, consider the portfolio starting with a single share of the asset and reinvesting dividends until some date $T$.  Let $X_t$ denote the number of shares resulting from this strategy at any time $t\\leq T$.  Then the dividend received at date $t$ is $q S_tX_t\\,\\d  t$, which can be used to purchase $q X_t\\,\\d  t$ new shares.  This implies that $\\d  X_t=q X_t\\,\\d  t$, or $\\d  X_t/\\d  t = q X_t$, and it is easy to check (and very well known) that this equation is solved by $X_t=\\mathrm{e}^{q t}X_0$.  In our case, with $X_0=1$, we have $X_t=\\mathrm{e}^{q t}$.\n\nThe dollar value of the trading strategy just described will be $X_tS_t = \\mathrm{e}^{q t}S_t$.  Denote this by $V_t$.  This is the value of a non-dividend-paying portfolio, because all dividends are reinvested.  From the Compounding/Discounting example in @sec-s_examples, we know that\n$$ \n\\frac{\\d  V}{V} = q\\,\\d  t + \\frac{\\d  S}{S}\\;.\n$$ {#eq-reinvestingdividends}\n\nThis means that the rate of return on the portfolio is the dividend yield $q\\,\\d  t$ plus the return $\\d  S/S$ due to capital gains.\n\n\n## Geometric Brownian Motion {#sec-s_geometricbrownianmotion}\nA random variable is lognormally distributed if it can be written as $\\tilde{y}=  e^{\\tilde{x}}$ where $\\tilde{x}$ is distributed according to a normal distribution with mean $m$ and standard deviation $s$.  The expected value of $\\tilde{y}$ is given by $\\E[\\tilde{y}] = e^{m+\\frac{s^2}{2}}$.\n\n::: Rule\n\n**Lognormal Random Variable.**\\;\nIf $\\tilde{x}$ is normally distributed with mean $m$ and standard deviation $s$, then $e^{\\tilde{x}}$ is lognormally distributed and\n$$\\E[e^{\\tilde{x}}]=e^{m + \\frac{1}{2} s^2};.\n$$ {#eq-lognormal}\n\n\n:::\n\nAn important stochastic process is geometric Brownian motion given by\n$$\nS_t=S_0\\exp\\left(\\mu t- \\sigma^2 t/2 + \\sigma B_t\\right)\n$$ {#eq-exponential1}\n\nfor constants $\\mu$ and $\\sigma$, where $B$ is a Brownian motion.  Note that for each time $t$, the random variable $S_t$ in @eq-exponential is a lognormal random variable. Using the product rule and the rule for exponentials, we obtain\n$$\n\\frac{\\d  S}{S} = \\mu\\,\\d  t+\\sigma\\,\\d  B\\;.\n$$ {#eq-Y}\n\nWhen we see an equation of the form @eq-Y, we should recognize @eq-exponential1 as the solution. \n\nThe process $S$ is called a geometric Brownian motion.  \\index{geometric Brownian motion} In keeping with the discussion of @sec-s_itoprocesses, we interpret @eq-Y as stating that $\\mu\\,\\d  t$ is the expected rate of change of $S$ and $\\sigma^2\\,\\d  t$ is the variance of the rate of change in an instant $\\d  t$.  We call $\\mu$ the drift and $\\sigma$ the volatility.  \\index{volatility} The geometric Brownian motion will grow at the average rate of $\\mu$, in the sense that $\\E[S_t] = \\mathrm{e}^{\\mu t}S_0$;  one way to verify this uses the formula for the mean of a lognormal random variable.\n\nTaking the natural logarithm of @eq-exponential1 gives an equivalent form of the solution:\n$$\n\\log S_t= \\log S_0+\\left(\\mu -\\frac{1}{2}\\sigma^2\\right)t + \\sigma B_t\\;.\n$$ {#eq-exponential2}\n  This shows that $\\log S_t - \\log S_0$ is a $(\\mu-\\sigma^2/2,\\sigma)$--Brownian motion.  Given information at time $t$, the logarithm of $S(u)$ for $u>t$ is normally \\index{lognormal distribution}distributed with mean $(u-t)(\\mu-\\sigma^2/2)$ and variance $(u-t)\\sigma^2$.  Because $S$ is the exponential of its logarithm, $S$ can never be negative.  For this reason, a geometric Brownian motion is a better model for stock prices than is a Brownian motion.\n\nThe differential of @eq-exponential2 is\n$$\n\\d  \\log S_t = \\left(\\mu -\\frac{1}{2}\\sigma^2\\right)\\,\\d  t+ \\sigma\\,\\d  B_t\\;.\n$$ {#eq-exponential3}\n\nWe conclude:\n\n::: Rule\n\nThe  equation \n$$\\frac{\\d  S}{S} = \\mu\\,\\d  t+\\sigma\\,\\d  B$$\nis equivalent to the equation\n$$\\d  \\log S = \\left(\\mu -\\frac{1}{2}\\sigma^2\\right)\\,\\d  t+ \\sigma\\,\\d  B\\; .$$\nThe solution of both equations is @eq-exponential1 or the equivalent @eq-exponential2.\n\n:::\n\n\n\nOver a discrete time interval $\\Delta t$, @eq-exponential3 implies that the change in the logarithm of $S$ is \n$$\n\\Delta \\log S = \\left(\\mu -\\frac{1}{2}\\sigma^2\\right)\\Delta t+ \\sigma\\,\\Delta B\\;.\n$$ {#eq-exponential11}\n\nIf $S$ is the price of a non-dividend-paying asset, then over the time period $t_{i-1}$ to $t_i$, with $t_i-t_{i-1}=\\Delta t$, we have\n$$\n\\Delta \\log S = r_i\\,\\Delta t\\;,\n$$ {#eq-exponential10}\n\nwhere $r_i$ is the  continuously compounded annualized rate of return \\index{continuously compounded return} during the period $\\Delta t$.  This follows from the definition of the continuously compounded rate of return as the constant rate over the time period $\\Delta t$ that would cause $S$ to grow (or fall) from $S_{t_{i-1}}$ to $S_{t_i}$.  To be precise, $r_i$ is defined by\n$$\\frac{S_{t_i}}{S_{t_{i-1}}} = \\mathrm{e}^{r_i\\Delta t}\\; ,$$\nwhich is equivalent to @eq-exponential10.\nThus, the geometric Brownian motion model (@eq-Y)implies that the continuously compounded annualized rate of return over a period of length $\\Delta t$ is given by\n$$r_i = \\mu -\\frac{1}{2}\\sigma^2+ \\frac{\\sigma\\Delta B}{\\Delta t}\\; .$$\nThis means that $r_i$ is normally distributed with mean $\\mu-\\sigma^2/2$ and variance $\\sigma^2/\\Delta t$.  Given historical data on the rates of return, the parameters $\\mu$ and $\\sigma$ can be estimated by standard methods (see @sec-c_stochasticvolatility).\n\nWe can simulate a path of $S$ by simulating the changes $\\Delta \\log S$.  The random variable $\\sigma \\Delta B$  in  @eq-exponential11 has a normal distribution with zero mean and variance equal to $\\sigma^2\\Delta t$.  We simulate it as $\\sigma\\sqrt{\\Delta t}$ multiplied by a standard normal.  The code below simulates $n=10000$ paths with $m=1000$ time steps. There are some features of the simulation which will prove useful later.  The drift $\\mu$ is labelled the interest rate $r=0.1$.  Other parameters are $\\sigma = 0.2$, and $T=0.5$.  The drift of the log stock price is labelled $drift=r-\\frac{\\sigma^2}{2}$.  The plot output is one of the simulated sample paths.  In practice, if we are only interested in the terminal value of the stock price we would use many fewer subdivisions, $n=1$.  Given a simulated mean zero normal random variable, $z$, changing the sign to $-z$ is also a simulated normal random variable with zero mean and the same standard deviation.  As a result, we have two simulations for the stock price labelled $St$ and $St1$, but we only plot one sample path for $St$. \n\n::: {#fcfcd01b .cell execution_count=4}\n``` {.python .cell-code}\n\"\"\"\n# Simulate geometric Brownian motion\nimport numpy as np\nimport matplotlib.pyplot as plt\n# number of paths\nn = 10000\n#number of divisions\nm = 1000\n# Interest rate (We set the drift equal to the interest rate)\nr = 0.1\n# Volatility\nsig = 0.2\n# Initial Stock Price\nS0 = 42\n# Maturity\nT = 0.5\n# Delta t\ndt = T/m\n# Drift\ndrift = (r-0.5*sig**2)\n# Volatility\nvol = sig * np.sqrt(dt)\n\nt = np.array(range(0,m + 1,1)) * dt\n\n# seed for random generator\nseed= 2020\n# define a random generator\nnp.random.seed(seed)\ninc = np.zeros(shape = (m + 1, n))\ninc[1:] = np.transpose(np.random.normal(loc = 0, scale = vol,size = (n,m)))\nSt = np.zeros(shape = (m + 1, n))\nSt = S0 * np.exp(np.cumsum(inc,axis=0) + (drift * t[0:m + 1])[:,None])\nSt1 = S0 * np.exp(-np.cumsum(inc,axis=0) + (drift * t[0:m + 1])[:,None])\nplt.figure(figsize=(9,6))\nplt.plot(t,St[:,1])\n\"\"\"\n\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```\n'\\n# Simulate geometric Brownian motion\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n# number of paths\\nn = 10000\\n#number of divisions\\nm = 1000\\n# Interest rate (We set the drift equal to the interest rate)\\nr = 0.1\\n# Volatility\\nsig = 0.2\\n# Initial Stock Price\\nS0 = 42\\n# Maturity\\nT = 0.5\\n# Delta t\\ndt = T/m\\n# Drift\\ndrift = (r-0.5*sig**2)\\n# Volatility\\nvol = sig * np.sqrt(dt)\\n\\nt = np.array(range(0,m + 1,1)) * dt\\n\\n# seed for random generator\\nseed= 2020\\n# define a random generator\\nnp.random.seed(seed)\\ninc = np.zeros(shape = (m + 1, n))\\ninc[1:] = np.transpose(np.random.normal(loc = 0, scale = vol,size = (n,m)))\\nSt = np.zeros(shape = (m + 1, n))\\nSt = S0 * np.exp(np.cumsum(inc,axis=0) + (drift * t[0:m + 1])[:,None])\\nSt1 = S0 * np.exp(-np.cumsum(inc,axis=0) + (drift * t[0:m + 1])[:,None])\\nplt.figure(figsize=(9,6))\\nplt.plot(t,St[:,1])\\n'\n```\n:::\n:::\n\n\nThe plot below is the distribution of the simulated stock price at $T$.\n\n::: {#93a8b704 .cell execution_count=5}\n``` {.python .cell-code}\n\"\"\"\nplt.figure(figsize=(9,6))\na=plt.hist(St[m,:], bins=100)\n\"\"\"\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```\n'\\nplt.figure(figsize=(9,6))\\na=plt.hist(St[m,:], bins=100)\\n'\n```\n:::\n:::\n\n\nWhile geometric Brownian motion is an important stochastic process to model stock prices, the process with drift equal to zero given by\n$$X_t = \\exp\\left(-\\frac{\\kappa^2}{2} + \\kappa B_t\\right)$$\n\nsatisfies $\\E[X_t]=1$ and $\\E[X_t|X_s]=X_s$ and is an important example of a strictly positive martingale.  Again, these facts can be verified using the formula for the expected value of a lognormal random variable.  Notice that we can write\n$$\\,\\d  X_t= \\kappa X_t \\,\\d  B_t\\;,$$\nwhich agrees with the martingale characterization of $\\int_0^t \\sigma(X_t,t) \\,\\d  B_t$.\n\n\n\n## Volatilities {#sec-s_volatilities}\n\nAs mentioned in @sec-s_geometricbrownianmotion, when we encounter an equation of the form \n$$\\frac{\\d  S}{S} = \\mu\\,\\d  t + \\sigma\\,\\d  B$$\nwhere $B$ is a Brownian motion, we will say  $\\sigma$ is the volatility of $S$.   We will occasionally need to compute the volatilities of products or ratios of random processes.  These computations follow directly from Ito's formula.\n\nSuppose \n$$\\frac{\\d  X}{X} = \\mu_x\\,\\d  t + \\sigma_x\\,\\d  B_x \\qquad \\text{and} \\qquad \n\\frac{\\d  Y}{Y} = \\mu_y\\,\\d  t + \\sigma_y\\,\\d  B_y\\; ,$$\nwhere $B_x$ and $B_y$ are Brownian motions with correlation $\\rho$, and $\\mu_x$, $\\mu_y$, $\\sigma_x$, $\\sigma_y$, and $\\rho$ may be quite general random processes.  \n\n### Products\nIf $Z=XY$, then @eq-rule2 gives us\n$$\n\\frac{\\d  Z}{Z} = (\\mu_x+\\mu_y+\\rho\\sigma_x\\sigma_y)\\,\\d  t + \\sigma_x\\,\\d  B_x + \\sigma_y\\,\\d  B_y\\;.\n$$ {#eq-volproduct1}\n\nThe instantaneous variance of $\\d  Z/Z$ is calculated, using the rules for products of differentials, as\n\\begin{align*}\n\\left(\\frac{\\d  Z}{Z}\\right)^2 &= (\\sigma_x\\,\\d  B_x + \\sigma_y\\,\\d  B_y)^2\\\\\n&= (\\sigma_x^2 + \\sigma_y^2 + 2\\rho\\sigma_x\\sigma_y)\\,\\d  t\\;.\n\\end{align*}\nAs will be explained below, the volatility is the square root of the instantaneous variance (dropping the $\\d  t$).  This implies:\n\n::: Rule\n## \nThe volatility of $XY$ is\n$$\n\\sqrt{\\sigma_x^2 + \\sigma_y^2 + 2\\rho\\sigma_x\\sigma_y}\\;.\n$$ {#eq-volatilityproduct}\n\n:::\n\n\n\n### Ratios\nIf $Z=Y/X$, then @eq-rule4 gives us\n$$\n\\frac{\\d  Z}{Z} = (\\mu_y-\\mu_x-\\rho\\sigma_x\\sigma_y+\\sigma_x^2)\\,\\d  t + \\sigma_y\\,\\d  B_y - \\sigma_x\\,\\d  B_x\\;.\n$$ {#eq-ratioproduct1}\n\nThe instantaneous variance of $\\d  Z/Z$ is therefore\n\\begin{align*}\n\\left(\\frac{\\d  Z}{Z}\\right)^2 &= (\\sigma_y\\,\\d  B_y - \\sigma_x\\,\\d  B_x)^2\\\\\n&= (\\sigma_x^2 + \\sigma_y^2 - 2\\rho\\sigma_x\\sigma_y)\\,\\d  t\\;.\n\\end{align*}\nThis implies:\n\n::: Rule\n## \nThe volatility of $Y/X$ is  \n$$\n\\sqrt{\\sigma_x^2 + \\sigma_y^2 - 2\\rho\\sigma_x\\sigma_y}\\;.\n$$ {#eq-volatilityratio}\n\n:::\n\n\n\n::: Extra\nTo understand why taking the square root of $(\\d  Z/Z)^2$ (dropping the $\\d  t$) gives the volatility, consider for example the product case $Z=XY$.  Define a random process $B$ by $B_0=0$ and \n$$\n\\d  B = \\frac{\\sigma_x}{\\sigma}\\,\\d  B_x + \\frac{\\sigma_y}{\\sigma}\\,\\d  B_y\\;,\n$$ {#eq-foreign\\,\\d  B}\n\nwhere $\\sigma$ is the volatility defined in @eq-volatilityproduct.\nThen we can write  @eq-volproduct1 as\n$$\n\\frac{\\d  Z}{Z} = \\left(\\mu_x +\\mu_y+ \\rho\\sigma_x\\sigma_y\\right)\\,\\d  t + \\sigma\\,\\d  B\\;.$$ {#eq-volproduct2}\n\nFrom the discussion in @sec-s_itoprocesses, we know that $B$ is a continuous martingale.  We can compute its quadratic variation from\n\\begin{align*}\n(\\d  B)^2 &= \\left(\\frac{\\sigma_x\\,\\d  B_x + \\sigma_s\\,\\d  B_s}{\\sigma}\\right)^2\\\\\n&= \\frac{(\\sigma_x^2 + \\sigma_s^2 + 2\\rho\\sigma_x\\sigma_s)\\,\\d  t}{\\sigma^2}\\; ,\\\\\n&= \\d  t\\;.\n\\end{align*}\nBy Levy's theorem (see @sec-s_quadraticvariation), any continuous martingale with this quadratic variation is necessarily a Brownian motion.  Therefore,  @eq-volproduct2 shows that $\\sigma$ is the volatility of $Z$ as defined at the beginning of the section.\n:::\n\n## {.unnumbered}\n\n\n::: Exercise\n Consider a discrete partition $0=t_0 < t_1 < \\cdots t_N=T$ of the time interval $[0,T]$ with $t_i - t_{i-1} = \\Delta t = T/N$ for each $i$.  Consider the function \n$$X_t=\\mathrm{e}^t\\; .$$\nWrite a code, which computes and plots $\\sum_{i=1}^N [\\Delta X_{t_i}]^2$, where \n$$\\Delta X_{t_i} = X_{t_i}-X_{t_{i-1}} = \\mathrm{e}^{t_i} - \\mathrm{e}^{t_{i-1}}\\; .$$\n:::\n::: Exercise\n Repeat the previous problem for the function $X_t = t^3$.  In both this and the previous problem, what happens to $\\sum_{i=1}^N [\\Delta X_{t_i}]^2$ as $N \\rightarrow \\infty$?\n:::\n::: Exercise\n Either use the code provided or write a code to compute $\\sum_{i=1}^N [\\Delta B_{t_i}]^2$, where $B$ is a simulated Brownian motion.  For a given $T$, what happens to the sum as $N \\rightarrow \\infty$?  \n:::\n::: Exercise\n Repeat the previous problem to compute $\\sum_{i=1}^N [\\Delta B_{t_i}]^3$, where $B$ is a simulated Brownian motion.  For a given $T$, what happens to the sum as $N \\rightarrow \\infty$?  \n:::\n::: Exercise\n Repeat the previous problem, computing instead $\\sum_{i=1}^N |\\Delta B_{t_i}|$ where $| \\cdot |$ denotes the absolute value.  What happens to this sum as $N \\rightarrow \\infty$?\n:::\n::: Exercise\nUse Ito's Lemma to derive the stochastic differential equation for $S_t^2$.  Argue that $S_t^2$ is geometric Brownian motion and find $\\E[S_t^2]$.\n::: \n::: Exercise\nIto's Lemma can be used in different ways to get the same answer.  For example, let $X_t = a t + b B_t$ and use Ito's lemma on the function $e^{X_t}$.  Alternatively, let $f(t, B_t) = e^{a t + bB_t}$.  Use Ito's lemma on $f(,)$.\n::: \n::: Exercise \nUse the facts $e^{x+y}=e^x \\times e^y$ and $\\frac{e^x}{e^y} = e^{x-y}$ to deduce the drift and volatility of the product and ratio of two geometric Brownian motions.\n::: \n::: Exercise\n Consider a discrete partition $0=t_0 < t_1 < \\cdots t_N=T$ of the time interval $[0,T]$ with $t_i - t_{i-1} = \\Delta t = T/N$ for each $i$.  Consider a geometric Brownian motion\n$$\\frac{\\d  Z}{Z} = \\mu\\,\\d  t + \\sigma\\,\\d  B\\; .$$\nAn approximate path $\\tilde{Z}_t$ of the geometric Brownian motion can be simulated as\n$$\n\\Delta \\tilde{Z}_{t_i} = \\tilde{Z}_{t_{i-1}} \\big[ \\mu\\,\\Delta t + \\sigma\\,\\Delta B\\big]\\;.\n$$ {#eq-exponential111}\nModify the code to generate both a path $Z_t$ and an approximate path $\\tilde{Z}_t$ according to @eq-exponential111, using the same $\\Delta B$  for both paths and taking $\\tilde{Z}_0 = Z_0$.  Plot both paths in the same figure.  How well does the approximation work for large $N$?   Warning:  \nFor $N$ larger than about $100 T$, the approximation will look perfect---you won't be able to tell that there are two plots in the figure.  One reason this is true is an exact formula is \n$$\n Z_{t_i} = Z_{t_{i-1}} \\exp\\left[ \\left(\\mu -\\frac{\\sigma^2}{2}\\right)\\,\\Delta t + \\sigma\\,\\Delta B\\right]\\;.\n$$ {#eq-exponential112}\nand using Taylor's Theorem for small $\\Delta t$, $e^{\\left(\\mu-\\frac{\\sigma^2}{2}\\right) \\Delta t} \\approx 1+ \\left(\\mu-\\frac{\\sigma^2}{2}\\right) \\Delta t$ and $e^{\\sigma \\Delta B_t} \\approx 1+ \\sigma \\Delta B_t +\\frac{1}{2}\\sigma^2 (\\Delta B_t)^2$ and $(\\,\\d  B_t)^2=\\Delta t$.\n:::\n::: Exercise\nUse simulation to find  $\\E^*[e^{-r T}{\\mathbf{1}}_{\\{S_t \\ge K\\}}]$ in the risk-neutral probability where\n\\begin{equation*}\n\\,\\d  S_t= r S_t \\,\\d  t + \\sigma S_t \\,\\d  B_t^*\n\\end{equation*}\nVerify that $S_t/e^{r t}$ is a martingale in the $*$ measure where $B^*$ is a Brownian motion.\nThen use simulation to find $S_0\\E^S[\\frac{1}{S_t} {\\mathbf{1}}_{\\{S_t \\ge K\\}}]$ in the pricing measure which uses the share as numeraire where \n\\begin{equation*}\n\\,\\d  S_t = (r + \\sigma^2) S_t \\,\\d  t + \\sigma S_t \\,\\d  B_t^S\n\\end{equation*}\nso the log satisfies\n\\begin{equation*}\n\\log(S_t) = \\log(S_0) + (r + \\frac{\\sigma^2}{2})t + \\sigma B_t^S\n\\end{equation*}\nYou should verify $e^{rt}/S_t$ is a martingale in the $S$ measure where $B^S$ is a Brownian motion.\nBoth estimates should be the same up to simulation error and give the time zero value of the random payoff ${\\mathbf{1}}_{\\{S_t \\ge K\\}}$ which is a random variable equal to $1$ if $S_t\\ge K$ and $0$ otherwise.  You should choose the values for $r$, $\\sigma$, $T$, and $K$.\n::: \n\n",
    "supporting": [
      "Chapter_Ito_files\\figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}