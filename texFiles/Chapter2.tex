\chapter{Continuous-Time Models}\label{c_continuoustime}

This chapter has three objectives.  The first is to introduce the concept of a Brownian motion.  A Brownian motion is a random process (a variable that changes randomly over time) that evolves continuously in time and has the property that its change over any time period is normally distributed with mean zero and variance equal to the length of the time period.  The ``mean zero'' feature means that a Brownian motion is a martingale.  We will also give a different characterization (Levy's theorem) emphasizing the ``quadratic variation'' process, which is a property of the paths (how the variable evolves over time, in a given state of the world) of the process.  

The second objective is to explain It\^o's formula, which is the chain rule for stochastic calculus.  In the Black-Scholes model, the stock price is assumed to satisfy
$$\frac{\D S}{S}=\mu\,\D t+\sigma\,\D B\; ,$$
where $B$ is a Brownian motion.  In the case that the stock pays no dividend, the rate of return is its price change $\D S$ divided by the initial price $S$, so the model states that the expected rate of return in each instant $\D t$  is $\mu\,\D t$ (of course, $t$ denotes time, so $\D t$ is the change in time).  The variance of the rate of return depends on $\sigma$.  This model can be equivalently written in terms of the natural logarithm of $S$, which we will write as $\log S$.  The above equation for the rate of return is equivalent to
$$\D\,\log S = \left(\mu - \frac{1}{2}\sigma^2\right)\,\D t + \sigma\,\D B\; .$$
We will explain this equivalence and other similar calculations that are useful for pricing derivatives.

The third objective is to explain how, when we change numeraires, as described in the previous chapter, we can calculate the expectation in the fundamental pricing formula \eqref{formula}.  The question is what effect does changing the numeraire (and hence the probability measure) have on the distribution of an asset price.  

Everything in the remainder of the book is based on the mathematics presented in this chapter.  For easy reference, the essential formulas have been highlighted in boxes.  


\section{Simulating a Brownian Motion}\label{s_simulatingbrownian}
We begin with the fact that changes in the value of a Brownian motion \index{Brownian motion} are normally distributed with mean zero and variance equal to the length of the time period.  Let $B(t)$ denote the value of a Brownian motion at time $t$.  Then for any date $u>t$, given the information at time $t$, the random variable $B(u) - B(t)$ is normally distributed with mean zero and variance equal to $u-t$.  Unless stated otherwise, our convention will be that a Brownian motion starts at $B(0)=0$.

We can generate an approximate Brownian motion in Excel.  To do so, we take a small time period $\varDelta t$ and define the value at the end of the period to be the value of the Brownian motion at the beginning plus a normally distributed variable with mean 0 and variance $\varDelta t$.  In the following procedure, the user is prompted to input the length $T$ of the entire time period over which the Brownian motion is to be simulated and to input the number $N$ of time periods of length $\varDelta t$ within the full interval $[0,T]$.  The length $\varDelta t$ of each individual time period is then calculated as $T/N$.  The quality of the approximation of this simulation to a true Brownian motion will be always be improved by increasing the number $N$.  Plotting the output of the procedure creates a picture of what we call a ``path'' of the Brownian motion, which means that it shows the value taken at each time in one state of the world.  Running the procedure again (for the same $T$ and $N$) will create a different plot, which can be interpreted as the values of the Brownian motion in another state of the world.  In other words, the path of the Brownian motion is itself random, depending in this approximation on the numbers produced by Excel's random number generating function.\footnote{The generation of normally distributed random numbers in Excel is discussed in Appendix~A.  The function RandN() here is user-created (to simplify typing) to equal the function Application.NormSInv(Rnd()) supplied in VBA.  The construction $\text{sqrtdt}*z$ scales the standard normal $z$ so that its standard deviation is $\sqrt{\varDelta t}$ and hence its variance is $\varDelta t$, as desired.  The subroutine creates two columns of data below the active cell in the Excel worksheet with headings ``Time'' and ``Brownian Motion.''  To plot the path of the Brownian motion, select the two columns and insert an ``XY (Scatter)'' chart, with data points connected by lines.}

\addcontentsline{lof}{figure}{Simulating Brownian Motion}
\small\begin{verbatim}
Sub Simulating_Brownian_Motion()
Dim T, dt, Sqrdt, BrownianMotion, i, N
T = InputBox("Enter the length of the time period (T)")
N = InputBox("Enter the number of periods (N)")
dt = T / N
Sqrdt = Sqr(dt)
ActiveCell.Value = "Time"
ActiveCell.Offset(0, 1) = "Brownian Motion"
ActiveCell.Offset(1, 0) = 0   ' beginning time
ActiveCell.Offset(1, 1) = 0   ' beginning value of Brownian motion
BrownianMotion = 0
For i = 1 To N
  ActiveCell.Offset(i + 1, 0) = i * dt          ' next time
  BrownianMotion = BrownianMotion + Sqrdt * RandN()
  ActiveCell.Offset(i + 1, 1) = BrownianMotion  ' next value
Next i
End Sub
\end{verbatim}\normalsize




\section{Quadratic Variation}\label{s_quadraticvariation}
If we take a large number $N$ of time steps in the simulation of the preceding section, we will see the distinctive characteristic of a Brownian motion: it jiggles rapidly, moving up and down in a very erratic way.  The name ``Brownian motion'' derives from the botanist Robert Brown's observations of the erratic behavior of particles suspended in a fluid.  This has long been thought to be a reasonable model for the behavior of a stock price.   
The plot of other functions with which we may be familiar will be much smoother.  This is captured in the concept of quadratic variation.  

Consider a discrete partition 
$$0=t_0 < t_1 < t_2 < \cdots < t_N=T$$
of the time interval $[0,T]$.  Let $B$ be a Brownian motion and calculate the sum of squared changes
$$\sum_{i=1}^N [\varDelta B(t_i)]^2\; ,$$
where $\varDelta B(t_i)$ denotes the change $B(t_i)-B(t_{i-1}).$  If we consider finer partitions with the length of each time interval $t_i-t_{i-1}$ going to zero, the limit of the sum is called the ``quadratic variation'' of the process.  \index{quadratic variation} For a Brownian motion, the quadratic variation over an interval $[0,T]$ is equal to $T$ with probability one.  

The functions with which we are normally familiar are continuously differentiable.  If $X$ is a continuously differentiable function of time (in each state of the world), then the quadratic variation of $X$ will be zero.  A simple example is a linear function: $X(t) = at$ for some constant $a$.  Then, taking $t_i-t_{i-1} = \varDelta t = T/N$ for each $i$, the sum of squared changes is
$$\sum_{i=1}^N [\varDelta X(t_i)]^2 = \sum_{i=1}^N  [a\,\varDelta t]^2 = Na^2 (\varDelta t)^2 = Na^2 \left(\frac{T}{N}\right)^2 = \frac{a^2T^2}{N} \rightarrow 0$$
as $N \rightarrow \infty$.  Essentially the same argument shows that the quadratic variation of any continuously differentiable function is zero, because such a function is approximately linear at each point.

Thus, the jiggling of a Brownian motion, which leads to the nonzero quadratic variation, is quite unusual.  To explain exactly how unusual it is, it is helpful to introduce the concept of ``total variation,'' \index{total variation} which is defined in the same way as quadratic variation but with the squared changes $[\varDelta B(t_i)]^2$ replaced by the absolute value of the changes $|\varDelta B(t_i)|.$  If the quadratic variation of a continuous function is nonzero, then its total variation is necessarily infinite, so each path of a Brownian motion has infinite total variation (with probability one).  It was mentioned above that, with a large number of time steps in the simulation of the preceding section, one could see the distinctive jiggling property of a Brownian motion.  This is not quite right.  Any plot drawn by a pencil (or a laser printer, for that matter) must have finite total variation, because the total variation is the total distance traveled by the pencil.  Hence, no matter how many time steps one uses, one will never create a continuous plot with the nonzero quadratic variation (and infinite total variation) that a Brownian path has.  Another way to understand this is to consider focusing on a small segment of a plot and viewing it with a magnifying glass.  If the segment is small enough, and excluding the finite number of kinks that a pencil can draw in the plot of a function, it will look approximately like a straight line under the magnifying glass (with slope equal to the derivative of the function).  However, if one could view a segment of a path of a true Brownian motion under a magnifying glass, it would look much the same as the entire picture does to the naked eye---no matter how small the segment, one would still see the characteristic jiggling.

One may well question why we should be interested in this curious mathematical object.  The reason is that asset pricing inherently involves martingales (variables that evolve randomly over time in such a way that their expected changes are always zero), as our fundamental pricing equation \eqref{formula} establishes.  Furthermore, continuous processes (variables whose paths are continuous functions of time) are much more tractable mathematically than are processes that can jump at some instants.  More importantly, it is possible in a mathematical model with continuous processes to define perfect hedges much more readily than it is in a model involving jump processes.  So, we are led to a study of continuous martingales.  An important fact is that any non-constant continuous martingale must have infinite total variation!  So, the normal functions with which we are familiar are left behind once we enter the study of continuous martingales.  

There remains perhaps the question of why we focus on Brownian motion within the world of continuous martingales.  The answer here is that any continuous martingale is really just a transformation of a Brownian motion.  This is a consequence of the following important fact, which is known as Levy's theorem: \index{Levy's theorem}
\mybox{A continuous martingale is a Brownian motion if and only if its quadratic variation over each interval $[0,T]$ equals $T$.}
Thus, among continuous martingales, a Brownian motion is defined by the condition that the quadratic variation over each interval $[0,T]$ is equal to $T$.  This is really just a normalization.  A different continuous martingale may have a different quadratic variation, but it can be converted to a Brownian motion just by deforming the time scale.  Furthermore, many continuous martingales can be constructed as ``stochastic integrals'' with respect to a Brownian motion.  We take up this topic in the next section.

\section{It\^o Processes}\label{s_itoprocesses}
An It\^o process is a variable $X$ that changes over time as \index{It\^o process}
\begin{equation}\label{itoprocess}
\D X(t) = \mu(t)\,\D t+\sigma(t)\,\D B(t)\;,
\end{equation}
where $B$ is a Brownian motion, and $\mu$ and $\sigma$ can also be random processes.  Some regularity conditions are needed on $\mu$ and $\sigma$ which we will omit, except for noting that $\mu(t)$ and $\sigma(t)$ should be known at time $t$.  In particular, constant $\mu$ and $\sigma$ are certainly acceptable.  When we add the changes over time, we get
$$X(T)=X(0) + \int_0^T\mu(t)\,\D t + \int_0^T\sigma(t)\,\D B(t)$$
for any $T>0$.  There are other types of random processes, in particular, processes that can jump, but we will not consider them in this book.

We will not formally define the integral $\int_0^T \sigma(t)\,\D B(t)$, but it should be understood as being approximately equal to a discrete sum of the form 
$$\sum_{i=1}^N \sigma(t_{i-1})\,\varDelta B(t_i)\; ,$$
where $0=t_0 < \cdots t_N=T$ and the time periods $t_i-t_{i-1}$ are small.  Given that we can simulate the changes $\varDelta B(t_i)$ as random normals, we can approximately simulate the random variable $\int_0^T \sigma(t)\,\D B(t)$ and hence we can approximately simulate $X(T)$.

An It\^o process evolves continuously over time.  We interpret $\mu(t)\,\D t$ as the expected change in $X$ in an instant $\D t$.  The quantity $\mu(t)$  is also called the ``drift'' of the process $X$ at time $t$.   \index{drift} The coefficient $\sigma(t)$ is called the ``diffusion'' coefficient of $X$ at time $t$.  \index{diffusion coefficient}

If $\mu$ and $\sigma$ are constant, it is standard to refer to an It\^o process $X$ as a $(\mu,\sigma)$--Brownian motion.  Of course, it is not a martingale when $\mu\neq 0$.  For example, when $\mu>0$, $X$ tends to increase over time.  However, it has the jiggling property of a Brownian motion, scaled by the diffusion coefficient $\sigma$. 

A very important fact is that an It\^o process such as \eqref{itoprocess} can be a martingale only if $\mu=0$.  This should seem sensible, because $\mu\,\D t$ is the expected change in $X$, and a process is a martingale only if its expected change is zero.\footnote{If the sources of uncertainty in the market can be modeled as Brownian motions, then in fact every martingale is an It\^o process with $\mu=0$.  This is some justification for the assumption we will make in this book, when studying continuous-time models, that all martingales are It\^o processes.}   This observation plays a fundamental role in deriving asset pricing formulas, as we will begin to see in Sect.~\ref{s_girsanov}.
Conversely, if $\mu=0$ and 
\begin{equation}\label{regularity1}
E \left[\int_0^T \sigma^2(t)\,\D t\right] < \infty
\end{equation}
for each $T$,  
then the It\^o process is a continuous martingale and the variance of its date--$T$ value, calculated with the information available at date 0, is:
$$\var[X(T)] = E \left[\int_0^T \sigma^2(t)\,\D t\right]\; .$$  

Whether $\mu$ is zero or not, and independently of the assumption \eqref{regularity1}, the quadratic variation of the It\^o process $X$ is 
\begin{equation}\label{itoquadraticvariation}
\lim_{N \rightarrow \infty} \sum_{i=1}^N[\varDelta X(t_i)]^2 = \int_0^T \sigma^2(t)\,\D t
\end{equation}
with probability one.  Thus we obtain (when $\mu=0$ and \eqref{regularity1} holds) a continuous martingale with a different quadratic variation than a Brownian motion via the diffusion function $\sigma$.

To ``compute'' the quadratic variation of an It\^o process, we use the following simple and important rules (for the sake of brevity, we drop the ``$(t)$'' notation from $B(t)$ here and sometimes later):
\mybox{\begin{subequations}\label{multiplydifferentials}
\begin{align}
(\D t)^2 &= 0\;, \label{dtsquared}\\
(\D t)(\D B) &=0\;, \label{dtdB}\\
(\D B)^2 &=\D t\;. \label{dBsquared}
\end{align}
\end{subequations}}

We apply these rules to ``compute'' the quadratic variation of $X$ as follows:
\mybox{If $\D X = \mu\,\D t + \sigma\,\D B$ for a Brownian motion $B$, then
\begin{align*}
(\D X)^2 &= (\mu\,\D t+\sigma\,\D B)^2\\
&= \mu^2(\D t)^2 + 2\mu\sigma(\D t)(\D B) + \sigma^2(\D B)^2\\
&= 0 + 0 + \sigma^2\,\D t\;.
\end{align*}}
We integrate this from 0 to $T$ to obtain the quadratic variation \eqref{itoquadraticvariation} over that time period:\footnote{In a more formal mathematical presentation, one normally writes $\D\langle X,X\rangle$ for what we are writing here as $(\D X)^2$.  This is the differential of the quadratic variation process, and the quadratic variation through date $T$ is
$$\langle X,X\rangle (T) = \int_0^T \D\langle X,X\rangle(t) = \int_0^T \sigma^2(t)\,\D t\;.$$}
\begin{equation}\label{itoquadraticvariation2}
\int_0^T (\D X(t))^2 = \int_0^T \sigma^2(t)\,\D t\;.
\end{equation}



\section{It\^o's Formula}\label{s_itosformula}

First we recall some facts of the ordinary calculus.  If $y=g(x)$ and $x = f(t)$ with $f$ and $g$ being continuously differentiable functions, then 
$$\frac{\D y}{\D t} = \frac{\D y}{\D x}\times \frac{\D x}{\D t} = g'(x(t))f'(t)\; .$$
Over a time period $[0,T]$, this implies that
$$y(T) = y(0) + \int_0^T \frac{\D y}{\D t}\,\D t = y(0) + \int_0^T g'(x(t))f'(t)\,\D t\; .$$
Substituting $\D x(t) = f'(t)\,\D t$, we can also write this as
\begin{equation}\label{ordinarycalculus}
y(T) = y(0) + \int_0^T g'(x(t))\,\D x(t)\;.
\end{equation}

We can contrast  \eqref{ordinarycalculus}  with a special case of It\^o's formula for the calculus of It\^o processes (the more general formula will be discussed in the next section).  If $B$ is a Brownian motion and $Y = g(B)$ for a twice-continuously differentiable function $g$, then \index{It\^o's formula}
\begin{equation}\label{itonew1}
Y(T) = Y(0) + \int_0^T g'(B(t))\,\D B(t) + \frac{1}{2}\int_0^T g''(B(t))\,\D t\;.
\end{equation}
Thus, relative to the ordinary calculus, It\^o's formula has an ``extra term'' involving the second derivative $g''$.  We can write \eqref{itonew1} in differential form as
$$dY(t) = \frac{1}{2}g''(B(t))\,\D t + g'(B(t))\,\D B(t).$$
Thus, $Y=g(B)$ is an It\^o process with drift $g''(B(t))/2$ and diffusion coefficient $g'(B(t))$.

To gain some intuition for the ``extra term'' in It\^o's formula, we return to the ordinary calculus.  Given dates $t<u$, the derivative defines a linear approximation of the change in $y$ over this time period; i.e., setting $\varDelta x = x(u)-x(t)$ and $\varDelta y = y(u) - y(t)$, we have the approximation
$$\varDelta y \approx g'(x(t)) \,\varDelta x\; .$$
A better approximation is given by the second-order Taylor series expansion
$$\varDelta y \approx g'(x(t))\,\varDelta x + \frac{1}{2} g''(x(t))\,[\varDelta x]^2\; .$$
An interpretation of  \eqref{ordinarycalculus} is that the linear approximation works perfectly for infinitesimal time periods $\D t$, because we can compute the change in $y$ over the time period $[0,T]$ by ``summing up'' the infinitesimal changes $g'(x(t))\,\D x(t)$.  In other words, the second-order term $\frac{1}{2} g''(x(t))\,[\varDelta x]^2$ ``vanishes'' when we consider very small time periods.

The second-order Taylor series expansion in the case of $Y=g(B)$ is 
$$\varDelta Y \approx g'(B(t))\,\varDelta B + \frac{1}{2} g''(B(t))\,[\varDelta B]^2\; .$$
For example, given a partition $0=t_0 < t_1 < \cdots < t_N=T$ of the time interval $[0,T]$, we have, with the same notation we have used earlier,
\begin{align}
Y(T) &= Y(0) + \sum_{i=1}^N \varDelta Y(t_i) \notag \\
&\approx Y(0) + \sum_{i=1}^N g'(B(t_{i-1}))\,\varDelta B(t_i) + \frac{1}{2} \sum_{i=1}^N g''(B(t_{i-1}))\,[\varDelta B(t_i)]^2\;.\label{itonew2}
\end{align}
If we make the time intervals $t_i-t_{i-1}$ shorter, letting $N \rightarrow \infty$, we cannot expect that the ``extra'' term here will disappear, leading to the result \eqref{ordinarycalculus} of the ordinary calculus, because we know that
$$\lim_{N \rightarrow \infty} \sum_{i=1}^N [\varDelta B(t_i)]^2 = T\; ,$$
whereas for the continuously differentiable function $x(t) = f(t)$, the same limit is zero.  In fact it seems sensible to interpret the limit of $[\varDelta B]^2$ as $(\D B)^2 =\D t$.
This is perfectly consistent with It\^o's formula: if we take the limit in \eqref{itonew2}, replacing the limit of $[\varDelta B(t_i)]^2$ with $(\D B)^2 = \D t$, we obtain \eqref{itonew1}.

\section{Multiple It\^o Processes}

Now consider two It\^o processes
\begin{subequations}
\begin{align}
\D X(t) &= \mu_x(t)\,\D t + \sigma_x(t)\,\D B_x(t)\;,\label{itoprocess110}\\
\D Y(t) &= \mu_y(t)\,\D t + \sigma_y(t)\,\D B_y(t)\;,\label{itoprocess111}
\end{align}
\end{subequations}
where $B_x$ and $B_y$ can be different Brownian motions.  The relation between the two Brownian motions is determined by their covariance or correlation.  Given dates $t<u$, we know that both changes $B_x(u)-B_x(t)$ and $B_y(u)-B_y(t)$ are normally distributed with mean 0 and variance equal to $u-t$.  There will exist a (possibly random) process $\rho$ such that the covariance \index{covariance} of these two normally distributed random variables, given the information at date $t$, is 
$$E_t \left[\int_t^u \rho(s)\,\D s\right]\; .$$
The process $\rho$ is called the correlation coefficient of the two Brownian motions, \index{correlation coefficient} because when it is constant the correlation of the changes $B_x(u)-B_x(t)$ and $B_y(u)-B_y(t)$ is
$$\frac{\text{covariance}}{\text{product of standard deviations}}  = \frac{\int_t^u \rho \,\D s}{\sqrt{u-t} \sqrt{u-t}} = \frac{(u-t)\rho}{u-t} = \rho\; .$$
Moreover, given increasingly fine partitions $0=t_0 < \cdots < t_N=T$ of an interval $[0,T]$ as before, we will have
$$\sum_{i=1}^N \varDelta B_x(t_i) \times \varDelta B_y(t_i) \rightarrow \int_0^T \rho(t)\,\D t$$
as $N \rightarrow \infty$, with probability one.  

We know that
\begin{equation}\label{itoprocess112}\sum _{i=1}^N [\varDelta X(t_i)]^2 \rightarrow \int_0^T \sigma_x^2(t)\,\D t \quad \text{and}\quad  \sum _{i=1}^N [\varDelta Y(t_i)]^2 \rightarrow \int_0^T\sigma_y^2(t)\,\D t\;.
\end{equation}
Furthermore, it can be shown that the sum of products satisfies
\begin{equation}\label{itoprocess113}
\sum_{i=1}^N \varDelta X(t_i) \times \varDelta Y(t_i) \rightarrow \int_0^T \sigma_x(t)\sigma_y(t)\rho(t)\,\D t\;.
\end{equation}
\mybox{By adding the rule 
\begin{equation}\label{dBdB}
(\D B_x)(\D B_y) = \rho\,\D t \tag{\ref{multiplydifferentials}d}
\end{equation} to the rules \eqref{dtsquared}--\eqref{dBsquared}, we can ``compute'' the limit in \eqref{itoprocess113} as
\begin{align}
\lim_{N \rightarrow\infty} \sum_{i=1}^N \varDelta X(t_i) \times \varDelta Y(t_i)  &= \int_0^T (\D X)(\D Y)\notag\\
&= \int_0^T (\mu_x\,\D t +\sigma_x\,\D B_x)(\mu_y\,\D t+\sigma_y\,\D B_y)\notag\\
&= \int_0^T\sigma_x(t)\sigma_y(t) \rho(t)\,\D t\;.\label{itojointvariation}
\end{align}}

The most general case of It\^o's formula that we will need is for a function $Z(t) = g(t, X(t), Y(t))$ where $X$ and $Y$ are It\^o processes as in \eqref{itoprocess110111}.  In this case, It\^o's formula is\footnote{We need to assume $g(t,x,y)$ is continuously differentiable in $t$ and twice continuously differentiable in $(x,y)$ for \eqref{itogeneralnew} and \eqref{itogeneralnew2} to be valid.  Note also that we are using a short-hand notation here.  The partial derivatives of $g$ will generally depend on $t$, $X(t)$ and $Y(t)$ just as $g$ does.}
\begin{align}
Z(T) = Z(0) &+ \int_0^T \frac{\partial g}{\partial t}\,\D t + \int_0^T \frac{\partial g}{\partial x}\,\D X(t) + \int_0^T \frac{\partial g}{\partial y}\,\D Y(t) \notag\\
&+ \frac{1}{2} \int_0^T \frac{\partial^2 g}{\partial x^2}\,(\D X(t))^2 +  \frac{1}{2} \int_0^T \frac{\partial^2 g}{\partial y^2}\,(\D Y(t))^2\notag \\
&+  \int_0^T \frac{\partial^2 g}{\partial x\partial y}\,(\D X(t))( \D Y(t))\;.\label{itogeneralnew}
\end{align}
In this equation, we apply the rules \eqref{dtsquared}--\eqref{dBdB} to compute
\begin{align*}
(\D X(t))^2&= \sigma_x^2(t)\,\D t\; ,\\
(\D Y(t))^2 &= \sigma_y^2(t)\,\D t\; ,\\
(\D X(t))( \D Y(t)) &= \sigma_x(t)\sigma_y(t)\rho(t)\,\D t\;.
\end{align*}
It\^o's formula \eqref{itogeneralnew} appears a bit simpler (and easier to remember) if we write it in ``differential form."  We have:

\mybox{If $Z(t) = g(t, X(t), Y(t))$ where $X$ and $Y$ are It\^o processes as in \eqref{itoprocess110111}, then
\begin{align}
\D Z = & \frac{\partial g}{\partial t}\,\D t + \frac{\partial g}{\partial x}\,\D X +  \frac{\partial g}{\partial y}\,\D Y + \frac{1}{2} \frac{\partial^2 g}{\partial x^2}\,(\D X)^2 +  \frac{1}{2}  \frac{\partial^2 g}{\partial y^2}\,(\D Y)^2 \notag\\
&+ \frac{\partial^2 g}{\partial x\partial y}\,(\D X)(\D Y)\;.\label{itogeneralnew2}
\end{align}
}

\section{Examples of It\^o's Formula}\label{s_examples}
The following are the applications of It\^o's formula that will be used most frequently in the book.  They follow from the boxed formula at the end of the previous section by taking $g(x,y)=xy$ or $g(x,y)=y/x$ or $g(x)=e^x$ or $g(x) = \log x$.



\mybox{
\textbf{Products.}\;
If $Z=XY$, then $\D Z=X\,\D Y+Y\,\D X + (\D X)(\D Y)$.  We can write this as
\begin{equation}\label{rule2}
\frac{\D Z}{Z}=\frac{\D X}{X} + \frac{\D Y}{Y} + \left(\frac{\D X}{X}\right)\left(\frac{\D Y}{Y}\right)\;.
\end{equation}
}


\mybox{
\textbf{Ratios.}\;
If $Z=Y/X$, then 
\begin{equation}\label{rule4}\frac{\D Z}{Z} = \frac{\D Y}{Y} -\frac{\D X}{X} - \left(\frac{\D Y}{Y}\right)\left(\frac{\D X}{X}\right) + \left(\frac{\D X}{X}\right)^2\;.
\end{equation}
}

\mybox{
\textbf{Exponentials.}\;
If $Z=\E^X$, then 
\begin{equation}\label{rule5}\frac{\D Z}{Z}=\D X + \frac{(\D X)^2}{2}\;.
\end{equation}
}

\mybox{
\textbf{Logarithms.}\;
If $Z=\log X$, then
\begin{equation}\label{rule6}
\D Z=\frac{\D X}{X} - \frac{1}{2}\left(\frac{\D X}{X}\right)^2\;.
\end{equation}
}

\mybox{
\textbf{Compounding/Discounting.}
Let  
$$Y(t) =\exp\left(\int_0^t q(s)\,\D s\right)$$
for some (possibly random) process $q$ and define $Z=XY$ for any It\^o process~$X$.
The usual calculus gives us 
$\D Y(t)=q(t)Y(t)\,\D t$,
and the product rule above implies
\begin{equation}\label{compdisc1}
\frac{\D Z}{Z}=q\,\D t + \frac{\D X}{X}\;.
\end{equation}
This is the same as in the usual calculus.  
}



\section{Reinvesting Dividends}\label{s_reinvestingdividends}

Frequently, we will assume that the asset underlying a derivative security pays a ``constant dividend yield,'' \index{dividend yield} which we will denote by $q$.  This means, for an asset with price $S(t)$, that the dividend ``in an instant $\D t$'' is $q S(t)\,\D t$.  If the dividends are reinvested in new shares, the number of shares will grow exponentially at rate $q$.  To see this, consider the portfolio starting with a single share of the asset and reinvesting dividends until some date $T$.  Let $X(t)$ denote the number of shares resulting from this strategy at any time $t\leq T$.  Then the dividend received at date $t$ is $q S(t)X(t)\,\D t$, which can be used to purchase $q X(t)\,\D t$ new shares.  This implies that $\D X(t)=q X(t)\,\D t$, or $\D X(t)/\D t = q X(t)$, and it is easy to check (and very well known) that this equation is solved by $X(t)=\E^{q t}X(0)$.  In our case, with $X(0)=1$, we have $X(t)=\E^{q t}$.

The dollar value of the trading strategy just described will be $X(t)S(t) = \E^{q t}S(t)$.  Denote this by $V(t)$.  This is the value of a non-dividend-paying portfolio, because all dividends are reinvested.  From the Compounding/Discounting example in Sect.~\ref{s_examples}, we know that
\begin{equation}\label{reinvestingdividends} 
\frac{\D V}{V} = q\,\D t + \frac{\D S}{S}\;.
\end{equation}
This means that the rate of return on the portfolio is the dividend yield $q\,\D t$ plus the return $\D S/S$ due to capital gains.

\newpage
\section{Geometric Brownian Motion}\label{s_geometricbrownianmotion}
Let
\begin{equation}\label{exponential1}
S(t)=S(0)\exp\left(\mu t- \sigma^2 t/2 + \sigma B(t)\right)
\end{equation}
for constants $\mu$ and $\sigma$, where $B$ is a Brownian motion.
Using the product rule and the rule for exponentials, we obtain
\begin{equation}\label{Y}
\frac{\D S}{S} = \mu\,\D t+\sigma\,\D B\;.
\end{equation}
When we see an equation of the form \eqref{Y}, we should recognize \eqref{exponential1} as the solution.  

The process $S$ is called a ``geometric Brownian motion.''  \index{geometric Brownian motion} In keeping with the discussion of Sect.~\ref{s_itoprocesses}, we interpret \eqref{Y} as stating that $\mu\,\D t$ is the expected rate of change of $S$ and $\sigma^2\,\D t$ is the variance of the rate of change in an instant $\D t$.  We call $\mu$ the ``drift'' and $\sigma$ the ``volatility.''  \index{volatility} The geometric Brownian motion will grow at the average rate of $\mu$, in the sense that $E[S(t)] = \E^{\mu t}S(0)$.

Taking the natural logarithm of \eqref{exponential1} gives an equivalent form of the solution:
\begin{equation}\label{exponential2}
\log S(t)= \log S(0)+\left(\mu -\frac{1}{2}\sigma^2\right)t + \sigma B(t)\;.
\end{equation}  This shows that $\log S(t) - \log S(0)$ is a $(\mu-\sigma^2/2,\sigma)$--Brownian motion.  Given information at time $t$, the logarithm of $S(u)$ for $u>t$ is normally \index{lognormal distribution}distributed with mean $(u-t)(\mu-\sigma^2/2)$ and variance $(u-t)\sigma^2$.  Because $S$ is the exponential of its logarithm, $S$ can never be negative.  For this reason, a geometric Brownian motion is a better model for stock prices than is a Brownian motion.

The differential of \eqref{exponential2} is
\begin{equation}\label{exponential3}
\D \log S(t) = \left(\mu -\frac{1}{2}\sigma^2\right)\,\D t+ \sigma\,\D B(t)\;.
\end{equation}
We conclude:
\mybox{
The  equation 
$$\frac{\D S}{S} = \mu\,\D t+\sigma\,\D B$$
is equivalent to the equation
$$\D \log S(t) = \left(\mu -\frac{1}{2}\sigma^2\right)\,\D t+ \sigma\,\D B(t)\; .$$
The solution of both equations is \eqref{exponential1} or the equivalent formula \eqref{exponential2}.
}

\newpage
Over a discrete time interval $\varDelta t$, equation \eqref{exponential3} implies that the change in the logarithm of $S$ is 
\begin{equation}\label{exponential11}
\varDelta \log S = \left(\mu -\frac{1}{2}\sigma^2\right)\varDelta t+ \sigma\,\varDelta B\;.
\end{equation}
If $S$ is the price of a non-dividend-paying asset, then over the time period $t_{i-1}$ to $t_i$, with $t_i-t_{i-1}=\varDelta t$, we have
\begin{equation}\label{exponential10}
\varDelta \log S = r_i\,\varDelta t\;,
\end{equation}
where $r_i$ is the  continuously compounded annualized rate of return \index{continuously compounded return} during the period $\varDelta t$.  This follows from the definition of the continuously compounded rate of return as the constant rate over the time period $\varDelta t$ that would cause~$S$ to grow (or fall) from $S(t_{i-1})$ to $S(t_i)$.  To be precise, $r_i$ is defined by
$$\frac{S(t_i)}{S(t_{i-1})} = \E^{r_i\varDelta t}\; ,$$
which is equivalent to \eqref{exponential10}.
Thus, the geometric Brownian motion model \eqref{Y} implies that the continuously compounded annualized rate of return over a period of length $\varDelta t$ is given by
$$r_i = \mu -\frac{1}{2}\sigma^2+ \frac{\sigma\varDelta B}{\varDelta t}\; .$$
This means that $r_i$ is normally distributed with mean $\mu-\sigma^2/2$ and variance $\sigma^2/\varDelta t$.  Given historical data on the rates of return, the parameters $\mu$ and $\sigma$ can be estimated by standard methods (see Chap.~\ref{c_stochasticvolatility}).

We can simulate a path of $S$ by simulating the changes $\varDelta \log S$.  The random variable $\sigma \varDelta B$  in  \eqref{exponential11} has a normal distribution with zero mean and variance equal to $\sigma^2\varDelta t$.  We simulate it as $\sigma\sqrt{\varDelta t}$ multiplied by a standard normal.

\addcontentsline{lof}{figure}{Simulating Geometric Brownian Motion}
\small\begin{verbatim}
Sub Simulating_Geometric_Brownian_Motion()
Dim T, S, mu, sigma, dt, SigSqrdt, LogS, drift, i, N
T = InputBox("Enter the length of the time period (T)")
N = InputBox("Enter the number of periods (N)")
S = InputBox("Enter the initial stock price (S)")
mu = InputBox("Enter the expected rate of return (mu)")
sigma = InputBox("Enter the volatility (sigma)")
dt = T / N
SigSqrdt = sigma * Sqr(dt)
drift = (mu - 0.5 * sigma * sigma) * dt
LogS = Log(S)
ActiveCell.Value = "Time"
ActiveCell.Offset(0, 1) = "Stock Price"
ActiveCell.Offset(1, 0) = 0   ' beginning time
ActiveCell.Offset(1, 1) = S   ' beginning stock price
For i = 1 To N
  ActiveCell.Offset(i + 1, 0) = i * dt      ' next time
  LogS = LogS + SigSqrdt * RandN()
  ActiveCell.Offset(i + 1, 1) = Exp(LogS)   ' next stock price
Next i
End Sub
\end{verbatim}\normalsize



\section{Numeraires and Probabilities}\label{s_girsanov}
When we change probability measures, we cannot expect a process $B$ that was a Brownian motion to remain a Brownian motion.    The expected change in a Brownian motion must always be zero, but when we change probabilities, the expected change of $B$ is likely to become nonzero.  (Likewise, a martingale is unlikely to remain a martingale when we change probabilities.)  However, the Brownian motion $B$ will still be an It\^o process under the new probability measure.  In fact, every It\^o process under one probability measure will still be an It\^o process under the new probability measure, and the diffusion coefficient of the It\^o process will be unaffected by the change in probabilities.\footnote{To be a little more precise, this is true provided sets of states of the world having zero probability continue to have zero probability when the probabilities are changed.  Because of the way we change probability measures when we change numeraires (cf.  \eqref{probSnumeraire}) this will always be true for us.}  Changing probabilities only changes the drift of an It\^o process.  

In a sense, this should not be surprising.  It was noted in Sect.~\ref{s_quadraticvariation} that a Brownian motion $B$ can be defined as a continuous martingale with paths that jiggle in such a way that the quadratic variation over any interval $[0,T]$ is equal to $T$.  Changing the probabilities will change the probabilities of the various paths (so it may affect the expected change in $B$) but it will not affect how each path jiggles. So, under the new probability measure, $B$ should still be like a Brownian motion but it may have a nonzero drift.  If we consider a general It\^o process, the reasoning is the same.  The diffusion coefficient $\sigma$ determines how much each path jiggles, and this is unaffected by changing the probability measure.  Furthermore, instantaneous covariances---the $(\D X)(\D Y)$ terms---between It\^o processes are unaffected by changing the probability measure.  Only the drifts are affected.

As explained in Sect.~\ref{s_introoptions}, we need to know the distribution of the underlying under probability measures corresponding to different numeraires.  Let~$S$ be the price of an asset that has a constant dividend yield $q$, and, as in Sect.~\ref{s_reinvestingdividends}, let $V(t)=\E^{qt}S(t)$.  This is the price of the portfolio in which all dividends are reinvested, and we have 
$$\frac{\D V}{V} = q\,\D t + \frac{\D S}{S}\; .$$
Let $Y$ be the price of another another asset that does not pay dividends.  Let~$r(t)$ denote the instantaneous risk-free rate at date $t$ and let $R(t) = \exp\left(\int_0^t r(s)\,\D s\right)$.  Assume
\begin{align*}
 \frac{\D S}{S} &= \mu_s\,\D t+\sigma_s\,\D B_s\; ,\\
 \frac{\D Y}{Y} &= \mu_y\,\D t+\sigma_y\,\D B_y\;,
\end{align*}
where $B_s$ and $B_y$ are Brownian motions under the actual probability measure with correlation $\rho$, and where $\mu_s, \mu_y, \sigma_s, \sigma_y$ and $\rho$ can be quite general random pro\-cesses.  
We consider the dynamics of the asset price $S$ under three different probability measures.  In each case, we follow the same steps: (i) we note that the ratio of an asset price to the numeraire asset price must be a martingale, (ii) we use It\^o's formula to calculate the drift of this ratio, and (iii) we use the fact that the drift of a martingale must be zero to compute the drift of $\D S/S$.


\subsection*{Risk-Neutral Probabilities}
Under the risk-neutral measure, $Z(t)$ defined as 
$$Z(t) = \frac{V(t)}{R(t)} = \exp\left(-\int_0^t r(s)\,\D s\right)V(t)$$
is a martingale.  Using the compounding/discounting rule, we have
$$\frac{\D Z}{Z} =-r\,\D t + \frac{\D V}{V} = (q-r)\,\D t + \frac{\D S}{S}\; .$$
For $Z$ to be a martingale, the drift ($\D t$ part) of $\D Z/Z$ must be zero.  Therefore, the drift of $\D S/S$ must be $(r-q)\,\D t$ under the risk-neutral measure.  Because the change of measure does not affect the volatility, this implies:
\mybox{\begin{equation}\label{riskneutral11}
\frac{\D S}{S} =( r-q)\,\D t+\sigma_s\,\D B^*_s\;,
\end{equation}
where $B^*_s$ is a Brownian motion under the risk-neutral measure. } 


\subsection*{Underlying as the Numeraire}
When $V$ is the numeraire, the process
$Z(t)$ defined as 
$$Z(t) = \frac{R(t)}{V(t)} = \frac{\exp\left(\int_0^t r(s)\,\D s\right)}{V(t)}$$
is a martingale.  Using the rule for ratios, we have
$$\frac{\D Z}{Z} =r\,\D t - \frac{\D V}{V} + \left(\frac{\D V}{V}\right)^2 = (r -q+ \sigma^2_s)\,\D t - \frac{\D S}{S}\; .$$
Because the drift of $\D Z/Z$ must be zero, this implies that the drift of $\D S/
S$ is $(r -q + \sigma^2_s)\,\D t$.  We conclude that:
\mybox{\begin{equation}\label{own11}
\frac{\D S}{S} = (r-q+ \sigma^2_s)\,\D t+\sigma_s\,\D B^*_s\;,
\end{equation}
where now $B^*_s$ denotes a Brownian motion when $V(t)=\E^{qt}S(t)$ is the numeraire.}


\subsection*{Another Risky Asset as the Numeraire}
When $Y$ is the numeraire, $Z(t)$ defined as 
$$Z(t) = \frac{V(t)}{Y(t)}$$ must be a martingale.  Using again the rule for ratios, we have
\begin{align*}
\frac{\D Z}{Z} &= \frac{\D V}{V} -\frac{\D Y}{Y}- \left(\frac{\D V}{V}\right)\left(\frac{\D Y}{Y}\right) + \left(\frac{\D Y}{Y}\right)^2\\
& = \frac{\D V}{V} -\frac{\D Y}{Y} -\rho\sigma_s\sigma_y\,\D t+\sigma_y^2\,\D t\\
&= \frac{\D S}{S} -\frac{\D Y}{Y} + (q-\rho\sigma_s\sigma_y\,\D t+\sigma_y^2)\,\D t\; .
\end{align*}
We can apply our previous example to compute the dynamics of $Y$ when $Y$ is the numeraire.  This shows that the drift of $\D Y/Y$ is $(r+ \sigma^2_y)\,\D t$.  Because the drift of $\D Z/Z$ must be zero, it follows that the drift of $\D S/S$ is
$(r-q+ \rho\sigma_s\sigma_y)\,\D t$.  We conclude that:
\mybox{\begin{equation}\label{other11}
\frac{\D S}{S} = (r-q+ \rho\sigma_s\sigma_y)\,\D t+\sigma_s\,\D B^*_s\;,
\end{equation}
where  $B^*_s$ denotes a Brownian motion under the probability measure corresponding to the non-dividend-paying risky asset $Y$ being the numeraire, and where $\rho$ is the correlation of $S$ and~$Y$.}

Notice that the formula \eqref{other11}, while more complicated, is also more general than the others.  In fact, it includes the formulas \eqref{riskneutral11} and \eqref{own11} as special cases: (i) if $Y$ is the price of the instantaneously risk-free asset, then $\sigma_y=0$ and \eqref{other11} simplifies to \eqref{riskneutral11}, and (ii) if $Y=
V$, then $\sigma_y=\sigma_s$ and $\rho=1$, so \eqref{other11} simplifies to \eqref{own11}.

\subsection*{Further Discussion}

It would be natural for one to ask at this point: ``what is the Brownian motion $B^*_s$ and where did it come from?''  We have argued that once we know the drift, and the fact that the volatility does not change, we can immediately write down, for example, 
$$\frac{\D S}{S} = (r-q)\,\D t + \sigma_s\,\D B^*_s$$
for a Brownian motion $B^*_s$ under the risk-neutral measure.  To answer this question, we will give here the definition of $B^*_s$ under the risk-neutral measure.  The definition shows that we are justified in writing down  \eqref{riskneutral11}--\eqref{other11}, but we will not repeat the definition each time we make a statement of this sort.     

We showed that $Z$ is a martingale under the risk-neutral measure, where~$Z$ satisfies
\begin{equation}\label{numeraire101}
\frac{\D Z}{Z} = (q-r)\,\D t + \frac{\D S}{S} = (q-r+\mu_s)\,\D t + \sigma_s\,\D B_s\;.
\end{equation}
Define $B^*_s(0) = 0$ and
\begin{equation}\label{numeraire102}
\D B^*_s = \left(\frac{q-r+\mu_s}{\sigma_s}\right)\,\D t + \D B_s\;.
\end{equation}
Then 
$$\D B^*_s = \frac{1}{\sigma_s}\left(\frac{\D Z}{Z}\right)$$
and hence is a continuous martingale under the risk-neutral measure.  We can compute its quadratic variation as
$$(\D B^*_s)^2 = \left(\frac{q-r+\mu_s}{\sigma_s}\right)^2(\D t)^2 + 2\left(\frac{q-r+\mu_s}{\sigma_s}\right)(\D t)(\D B_s) + (\D B_s)^2 = \D t\; .$$
Therefore, by Levy's theorem (Sect.~\ref{s_quadraticvariation}), $B^*_s$ is a Brownian motion under the risk-neutral measure.   From  \eqref{numeraire101} and \eqref{numeraire102} we have
$$(q-r)\,\D t + \frac{\D S}{S} = \sigma_s\,\D B^*_s \quad \Longleftrightarrow \quad \frac{\D S}{S} = (r-q)\,\D t + \sigma_s\,\D B^*_s\;,$$
as in  \eqref{riskneutral11}.

\section{Tail Probabilities of Geometric Brownian Motions}\label{s_tailprobs}

For each of the numeraires discussed in the previous section, we have
\begin{equation}\label{tailprob1}
\D \log S = \alpha\,\D t + \sigma\,\D B\;,
\end{equation}
for some $\alpha$ and $\sigma$, where $B$ is a Brownian motion under the probability measure associated with the numeraire.  Specifically, $\sigma=\sigma_s$, $B=B^*_s$, and

\begin{enumerate}
\renewcommand{\labelenumi}{(\arabic{enumi})}
\item for the risk-neutral measure, $\alpha = r-q-\sigma_s^2/2$,
\item when $\E^{qt}S(t)$ is the numeraire, $\alpha = r-q +\sigma_s^2/2$,
\item when another risky asset price $Y$ is the numeraire, $\alpha = r-q+\rho\sigma_s\sigma_y-\sigma_s^2/2$.
\end{enumerate}

We will assume in this section that $\alpha$ and $\sigma$ are constants.
The essential calculation in pricing options, as we will see in the next chapter and in Chap.~\ref{c_exotics}, is to compute $\text{prob}(S(T)>K)$ and $\text{prob}(S(T)<K)$ for a constant $K$ (the strike price of an option), where $\text{prob}$ denotes the probabilities at date 0 (the date we are pricing an option) associated with a particular numeraire.  

Equation \eqref{tailprob1} gives us
$$\log S(T) = \log S(0) + \alpha T + \sigma B(T)\; .$$
Given this, we deduce
\begin{align} 
S(T) > K & \quad\Longleftrightarrow\quad \log S(T) > \log K\notag\\
& \quad\Longleftrightarrow\quad \sigma B(T) > \log K - \log S(0)-\alpha T\notag\\
& \quad\Longleftrightarrow\quad \frac{B(T)}{\sqrt{T}} > \frac{\log K - \log S(0)-\alpha T}{\sigma\sqrt{T}}\notag\\
& \quad\Longleftrightarrow\quad -\frac{B(T)}{\sqrt{T}} < \frac{\log S(0)-\log K + \alpha T}{\sigma\sqrt{T}}\notag\\
& \quad\Longleftrightarrow\quad -\frac{B(T)}{\sqrt{T}} < \frac{\log \left(\frac{S(0)}{K}\right) + \alpha T}{\sigma\sqrt{T}}\;.\label{tailprob2}
\end{align}
The random variable on the left-hand side of \eqref{tailprob2} has the standard normal distribution---it is normally distributed with mean equal to zero and variance equal to one.  As is customary, we will denote the probability that a standard normal is less than some number $d$ as $\N(d)$.  We conclude:
\mybox{Assume $\D \log S = \alpha\,\D t + \sigma\,\D B$, where $B$ is a Brownian motion.  Then, for any number~$K$,
\begin{equation}\label{tailprob01}
\text{prob}(S(T)>K) = \N(d)\;,
\end{equation}
where
\begin{equation}\label{tailprob3}
d = \frac{\log \left(\frac{S(0)}{K}\right) + \alpha T}{\sigma\sqrt{T}}\;.
\end{equation}}

The  probability $\text{prob}(S(T)<K)$ can be calculated similarly, but the simplest way to derive it is to note that the events $S(T)>K$ and $S(T)<K$ are ``complementary''---their probabilities sum to one (the event $S(T)=K$ having zero probability).  Therefore $\text{prob}(S(T)<K) = 1-\N(d)$.  This is the probability that a standard normal is greater than $d$, and by virtue of the symmetry of the standard normal distribution, it equals the probability that a standard normal is less than $-d$.  Therefore, we have:
\mybox{Assume $\D \log S = \alpha\,\D t + \sigma\,\D B$, where $B$ is a Brownian motion.  Then, for any number~$K$,
\begin{equation}\label{tailprob02}
\text{prob}(S(T)<K) = \N(-d)\;,
\end{equation}
where $d$ is defined in \eqref{tailprob3}.}


\section{Volatilities}\label{s_volatilities}

As mentioned in Sect.~\ref{s_geometricbrownianmotion}, when we encounter an equation of the form 
$$\frac{\D S}{S} = \mu\,\D t + \sigma\,\D B$$
where $B$ is a Brownian motion, we will say  ``$\sigma$ is the volatility of $S$.''  For example, in the Black-Scholes model, the most important assumption is that the volatility of the underlying asset price is constant.  We will occasionally need to compute the volatilities of products or ratios of random processes.  These computations follow directly from It\^o's formula.

Suppose 
$$\frac{\D X}{X} = \mu_x\,\D t + \sigma_x\,\D B_x \qquad \text{and} \qquad 
\frac{\D Y}{Y} = \mu_y\,\D t + \sigma_y\,\D B_y\; ,$$
where $B_x$ and $B_y$ are Brownian motions with correlation $\rho$, and $\mu_x$, $\mu_y$, $\sigma_x$, $\sigma_y$, and $\rho$ may be quite general random processes.  

\subsection*{Products}
If $Z=XY$, then \eqref{rule2} gives us
\begin{equation}\label{volproduct1}
\frac{\D Z}{Z} = (\mu_x+\mu_y+\rho\sigma_x\sigma_y)\,\D t + \sigma_x\,\D B_x + \sigma_y\,\D B_y\;.
\end{equation}
The instantaneous variance of $\D Z/Z$ is calculated, using the rules for products of differentials, as
\begin{align*}
\left(\frac{\D Z}{Z}\right)^2 &= (\sigma_x\,\D B_x + \sigma_y\,\D B_y)^2\\
&= (\sigma_x^2 + \sigma_y^2 + 2\rho\sigma_x\sigma_y)\,\D t\;.
\end{align*}
As will be explained below, the volatility is the square root of the instantaneous variance (dropping the $\D t$).  This implies:
\mybox{The volatility of $XY$ is
\begin{equation}\label{volatilityproduct}
\sqrt{\sigma_x^2 + \sigma_y^2 + 2\rho\sigma_x\sigma_y}\;.
\end{equation}}


\subsection*{Ratios}
If $Z=Y/X$, then \eqref{rule4} gives us
\begin{equation}\label{ratioproduct1}
\frac{\D Z}{Z} = (\mu_y-\mu_x-\rho\sigma_x\sigma_y+\sigma_x^2)\,\D t + \sigma_y\,\D B_y - \sigma_x\,\D B_x\;.
\end{equation}
The instantaneous variance of $\D Z/Z$ is therefore
\begin{align*}
\left(\frac{\D Z}{Z}\right)^2 &= (\sigma_y\,\D B_y - \sigma_x\,\D B_x)^2\\
&= (\sigma_x^2 + \sigma_y^2 - 2\rho\sigma_x\sigma_y)\,\D t\;.
\end{align*}
This implies:
\mybox{The volatility of $Y/X$ is  
\begin{equation}\label{volatilityratio}
\sqrt{\sigma_x^2 + \sigma_y^2 - 2\rho\sigma_x\sigma_y}\;.
\end{equation}}


\subsection*{Further Discussion}
To understand why taking the square root of $(\D Z/Z)^2$ (dropping the $\D t$) gives the volatility, consider for example the product case $Z=XY$.  Define a random process $B$ by $B(0)=0$ and 
\begin{equation}\label{foreigndB}
\D B = \frac{\sigma_x}{\sigma}\,\D B_x + \frac{\sigma_y}{\sigma}\,\D B_y\;,
\end{equation}
where $\sigma$ is the volatility defined in \eqref{volatilityproduct}.
Then we can write  \eqref{volproduct1} as
\begin{equation}\label{volproduct2}
\frac{\D Z}{Z} = \left(\mu_x +\mu_y+ \rho\sigma_x\sigma_y\right)\,\D t + \sigma\,\D B\;.\end{equation}
From the discussion in Sect.~\ref{s_itoprocesses}, we know that $B$ is a continuous martingale.  We can compute its quadratic variation from
\begin{align*}
(\D B)^2 &= \left(\frac{\sigma_x\,\D B_x + \sigma_s\,\D B_s}{\sigma}\right)^2\\
&= \frac{(\sigma_x^2 + \sigma_s^2 + 2\rho\sigma_x\sigma_s)\,\D t}{\sigma^2}\; ,\\
&= \D t\;.
\end{align*}
By Levy's theorem (see Sect.~\ref{s_quadraticvariation}), any continuous martingale with this quadratic variation is necessarily a Brownian motion.  Therefore,  \eqref{volproduct2} shows that $\sigma$ is the volatility of $Z$ as defined at the beginning of the section.

\section*{Problems}
\addcontentsline{toc}{section}{Problems}
\begin{prob} Consider a discrete partition $0=t_0 < t_1 < \cdots t_N=T$ of the time interval $[0,T]$ with $t_i - t_{i-1} = \varDelta t = T/N$ for each $i$.  Consider the function 
$$X(t)=\E^t\; .$$
Create a VBA subroutine, prompting the user to input $T$ and $N$, which computes and prints $\sum_{i=1}^N [\varDelta X(t_i)]^2$, where 
$$\varDelta X(t_i) = X(t_i)-X(t_{i-1}) = \E^{t_i} - \E^{t_{i-1}}\; .$$
Hint: The sum can be computed as follows.
\small\begin{verbatim}
sum = 0
For i = 1 To N
    DeltaX = Exp(i/N)-Exp((i-1)/N)
    sum = sum + DeltaX * DeltaX
Next i
\end{verbatim}\normalsize
\end{prob}\begin{prob} Repeat the previous problem for the function $X(t) = t^3$.  In both this and the previous problem, what happens to $\sum_{i=1}^N [\varDelta X(t_i)]^2$ as $N \rightarrow \infty$?
\end{prob}\begin{prob} Repeat the previous problem to compute $\sum_{i=1}^N [\varDelta B(t_i)]^2$, where $B$ is a simulated Brownian motion.  For a given $T$, what happens to the sum as $N \rightarrow \infty$?  
\end{prob}\begin{prob} Repeat the previous problem, computing instead $\sum_{i=1}^N |\varDelta B(t_i)|$ where $| \cdot |$ denotes the absolute value.  What happens to this sum as $N \rightarrow \infty$?
\end{prob}\begin{prob} Consider a discrete partition $0=t_0 < t_1 < \cdots t_N=T$ of the time interval $[0,T]$ with $t_i - t_{i-1} = \varDelta t = T/N$ for each $i$.  Consider a geometric Brownian motion
$$\frac{\D Z}{Z} = \mu\,\D t + \sigma\,\D B\; .$$
An approximate path $\tilde{Z}(t)$ of the geometric Brownian motion can be simulated as
\begin{equation}\label{exponential111}
\varDelta \tilde{Z}(t_i) = \tilde{Z}(t_{i-1}) \big[ \mu\,\varDelta t + \sigma\,\varDelta B\big]\;.
\end{equation}
The subroutine \verb!Simulating_Geometric_Brownian_Motion! simulates a path~\verb!Z! of a geometric Brownian motion. Modify the subroutine to prompt the user to input $T$, $N$, $\sigma$, $\mu$, and $Z(0)$ and to generate both a path $Z(t)$ and an approximate path $\tilde{Z}(t)$ according to \eqref{exponential111}, using the same $\varDelta B$  for both paths and taking $\tilde{Z}(0) = Z(0)$.  Plot both paths in the same figure.  How well does the approximation work for large $N$?   Warning:  
For $N$ larger than about $100 T$, the approximation will look perfect---you won't be able to tell that there are two plots in the figure.
\end{prob}

