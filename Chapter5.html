<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Pricing and Hedging Derivative Securities - 5&nbsp; Estimating and Modelling Volatility</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./Chapter6.html" rel="next">
<link href="./Chapter4.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://hypothes.is/embed.js"></script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./Chapter5.html"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Estimating and Modelling Volatility</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Pricing and Hedging Derivative Securities</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Calls and Puts</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Binomial Model and Changes of Measure</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Continuous-Time Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Black-Scholes</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter5.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Estimating and Modelling Volatility</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter6.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Introduction to Monte Carlo and Binomial Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter7.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Foreign Exchange</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter8.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Forward, Futures, and Exchange Options</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter9.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Exotic Options</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">More on Monte Carlo and Binomial Valuation</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter11.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Finite Difference Methods</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter12.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Fixed Income Concepts</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter13.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Introduction to Fixed Income Derivatives</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter14.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Valuing Derivatives in the Extended Vasicek Model</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter15.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">A Brief Survey of Term Structure Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./AppendixB.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Miscellaneous Facts about Continuous-Time Models</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Chapter contents</h2>
   
  <ul class="collapse">
  <li><a href="#sec-s_statistics" id="toc-sec-s_statistics" class="nav-link active" data-scroll-target="#sec-s_statistics"><span class="header-section-number">5.1</span> Statistics Review</a></li>
  <li><a href="#sec-s_estimatingvolatility" id="toc-sec-s_estimatingvolatility" class="nav-link" data-scroll-target="#sec-s_estimatingvolatility"><span class="header-section-number">5.2</span> Estimating a Constant Volatility and Mean</a></li>
  <li><a href="#estimating-a-changing-volatility" id="toc-estimating-a-changing-volatility" class="nav-link" data-scroll-target="#estimating-a-changing-volatility"><span class="header-section-number">5.3</span> Estimating a Changing Volatility</a></li>
  <li><a href="#sec-s_garch" id="toc-sec-s_garch" class="nav-link" data-scroll-target="#sec-s_garch"><span class="header-section-number">5.4</span> GARCH Models</a></li>
  <li><a href="#sec-s_stochasticvolatility" id="toc-sec-s_stochasticvolatility" class="nav-link" data-scroll-target="#sec-s_stochasticvolatility"><span class="header-section-number">5.5</span> Stochastic Volatility Models</a></li>
  <li><a href="#sec-s_smilesagain" id="toc-sec-s_smilesagain" class="nav-link" data-scroll-target="#sec-s_smilesagain"><span class="header-section-number">5.6</span> Smiles and Smirks Again</a></li>
  <li><a href="#hedging-and-market-completeness" id="toc-hedging-and-market-completeness" class="nav-link" data-scroll-target="#hedging-and-market-completeness"><span class="header-section-number">5.7</span> Hedging and Market Completeness</a></li>
  <li><a href="#exercises" id="toc-exercises" class="nav-link" data-scroll-target="#exercises"><span class="header-section-number">5.8</span> Exercises</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec-c_stochasticvolatility" class="quarto-section-identifier"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Estimating and Modelling Volatility</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>Thus far, we have assumed that the volatility of the underlying asset is constant or varying in a non-random way during the lifetime of the derivative. In this chapter we will look at models that relax this assumption and allow the volatility to change randomly. This is very important, because there is plenty of evidence that volatilities do change over time in a random way.</p>
<p>In the first three sections, we will consider the problem of estimating the volatility. The discussion of estimation methods leads naturally into the discussion of modelling a changing volatility.</p>
<section id="sec-s_statistics" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="sec-s_statistics"><span class="header-section-number">5.1</span> Statistics Review</h2>
<p>We begin with a brief review of basic statistics. Given a random sample <span class="math inline">\(\{x_1,\ldots,x_N\}\)</span> of size <span class="math inline">\(N\)</span> from a population with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>, the best estimate of <span class="math inline">\(\mu\)</span> is of course the sample mean <span class="math display">\[\bar{x} = \frac{1}{N}\sum_{i=1}^{N}x_i\; .\]</span> The variance is the expected value of <span class="math inline">\((x-\mu)^2\)</span>, so an obvious estimate of the variance is the sample average of <span class="math inline">\((x_i-\mu)^2\)</span>, replacing <span class="math inline">\(\mu\)</span> with its estimate <span class="math inline">\(\bar{x}\)</span>. This would be <span class="math display">\[\frac{1}{N}\sum_{i=1}^{N} (x_i-\bar{x})^2\]</span> However, because <span class="math inline">\(\bar{x}\)</span> is computed from the <span class="math inline">\(x_i\)</span>, the <span class="math inline">\(x_i\)</span> will deviate less on average from <span class="math inline">\(\bar{x}\)</span> than they do from the true mean <span class="math inline">\(\mu\)</span>. Hence the estimate proposed above will on average be less than <span class="math inline">\(\sigma^2\)</span>. To eliminate this bias, it suffices just to scale the estimate up by a factor of <span class="math inline">\(N/(N-1)\)</span>. This leads to the estimate <span class="math display">\[s^2=\frac{1}{N-1}\sum_{i=1}^{N} (x_i-\bar{x})^2\; ,\]</span> and the best estimate of <span class="math inline">\(\sigma\)</span> is the square root <span class="math display">\[s=\sqrt{\frac{1}{N-1}\sum_{i=1}^{N} (x_i-\bar{x})^2}\; .\]</span> To calculate <span class="math inline">\(s^2\)</span>, notice that <span class="math display">\[\begin{align*}
\sum_{i=1}^{N} (x_i-\bar{x})^2 &amp;= \sum_{i=1}^{N} (x_i^2-2x_i\bar{x}+\bar{x}^2)\\
&amp;=\sum_{i=1}^{N} x_i^2 -2\bar{x}\sum_{i=1}^{N} x_i + \sum_{i=1}^N \bar{x}^2\\
&amp;=\sum_{i=1}^{N} x_i^2 -2\bar{x}(N\bar{x})+N\bar{x}^2\\
&amp;=\sum_{i=1}^{N} x_i^2 -N\bar{x}^2\;.
\end{align*}\]</span> Therefore <span class="math display">\[s=\sqrt{\frac{1}{N-1}\left(\sum_{i=1}^{N} x_i^2-N\bar{x}^2\right)}\; .\]</span></p>
<p>It is important to know how much variation there would be in <span class="math inline">\(\bar{x}\)</span> if one had access to multiple random samples. More variation means that an <span class="math inline">\(\bar{x}\)</span> computed from a single sample will be a less reliable estimate of <span class="math inline">\(\mu\)</span>. The variance of <span class="math inline">\(\bar{x}\)</span> in repeated samples is <span class="math inline">\(\sigma^2/N\)</span>,^[The variance of <span class="math inline">\(\bar{x] = (1/N)(x_1 + \cdots + x_N)\)</span> is, by independence of the <span class="math inline">\(x_i\)</span>, equal to <span class="math inline">\((1/N)^2(\mathrm{var}{x_1} + \cdots + \mathrm{var}{x_N})\)</span>, and, because the <span class="math inline">\(x_i\)</span> all have the same variance <span class="math inline">\(\sigma^2\)</span>, this is equal to <span class="math inline">\((1/N)^2 \times N\sigma^2 = \sigma^2/N\)</span>.} and our best estimate of this variance is <span class="math inline">\(s^2/N\)</span>. The standard deviation of <span class="math inline">\(\bar{x}\)</span> in repeated samples, which is called the standard error of <span class="math inline">\(\bar{x}\)</span>, is <span class="math inline">\(\sigma/\sqrt{N}\)</span>, and we estimate this by <span class="math inline">\(s/\sqrt{N}\)</span>, which equals <span class="math display">\[\sqrt{\frac{1}{N(N-1)}\left(\sum_{i=1}^{N} x_i^2-N\bar{x}^2\right)}\; .\]</span> If the population from which <span class="math inline">\(x\)</span> is sampled has a normal distribution, then a 95% confidence interval for <span class="math inline">\(\mu\)</span> will be <span class="math inline">\(\bar{x}\)</span> plus or minus 1.96 standard errors. Even if <span class="math inline">\(x\)</span> does not have a normal distribution, by the Central Limit Theorem, <span class="math inline">\(\bar{x}/\sqrt{N}\)</span> will be approximately normally distributed if the sample size <span class="math inline">\(N\)</span> is large enough, and plus or minus 1.96 standard errors will still be approximately a 95% confidence interval for <span class="math inline">\(\mu\)</span>. </p>
</section>
<section id="sec-s_estimatingvolatility" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="sec-s_estimatingvolatility"><span class="header-section-number">5.2</span> Estimating a Constant Volatility and Mean</h2>
<p>Consider an asset price that is a geometric Brownian motion under the actual probability measure: <span class="math display">\[\frac{\mathrm{d} S}{S} = \mu\,\mathrm{d} t + \sigma\,\mathrm{d} B\; ,\]</span> where <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> are unknown constants and <span class="math inline">\(B\)</span> is a Brownian motion. We can as usual write this in log form as <span class="math display">\[\mathrm{d}\log S = \left(\mu-\frac{1}{2}\sigma^2\right)\,\mathrm{d} t + \sigma\,\mathrm{d} B\; .\]</span> Over a discrete time period of length <span class="math inline">\(\Delta t\)</span>, this implies <span id="eq-dlogs"><span class="math display">\[
\Delta \log S = \left(\mu-\frac{1}{2}\sigma^2\right)\Delta t + \sigma \Delta B\;.
\tag{5.1}\]</span></span></p>
<p>Suppose we have observed the asset price <span class="math inline">\(S\)</span> at dates <span class="math inline">\(0=t_0&lt;t_1&lt;\cdots&lt; t_N=T\)</span>, where <span class="math inline">\(t_i-t_{i-1}=\Delta t\)</span>. If the asset pays dividends, we will take <span class="math inline">\(S\)</span> to be the value of the portfolio in which the dividends are reinvested in new shares. Thus, in general, <span class="math inline">\(S(t_i)/S(t_{i-1})\)</span> denotes the gross return (one plus the rate of return) between dates <span class="math inline">\(t_{i-1}\)</span> and <span class="math inline">\(t_i\)</span>. This return is measured on a non-compounded and non-annualized basis. The annualized continuously-compounded rate of return is the rate <span class="math inline">\(r_i\)</span> defined by <span class="math display">\[\frac{S(t_i)}{S(t_{i-1})} = \mathrm{e}^{r_i\Delta t}\; .\]</span> This implies that <span id="eq-contcompreturn"><span class="math display">\[
r_i = \frac{\log S(t_i)-\log S(t_{i-1})}{\Delta t} = \mu-\frac{1}{2}\sigma^2 + \sigma \frac{B(t_i)-B(t_{i-1})}{\Delta t}\;.
\tag{5.2}\]</span></span></p>
<p>Because <span class="math inline">\(B(t_i)-B(t_{i-1})\)</span> is normally distributed with mean zero and variance <span class="math inline">\(\Delta t\)</span>, the sample <span class="math inline">\(\{r_1,\ldots,r_N\}\)</span> is a sample of independent random variables each of which is normally distributed with mean <span class="math inline">\(\mu-\sigma^2/2\)</span> and variance <span class="math inline">\(\sigma^2/\Delta t\)</span>. We are focused on estimating <span class="math inline">\(\sigma^2\)</span>, so it will simplify things to define <span id="eq-volyi"><span class="math display">\[
y_i = r_i\sqrt{\Delta t} = \frac{\log S(t_i)-\log S(t_{i-1})}{\sqrt{\Delta t}}\;.
\tag{5.3}\]</span></span></p>
<p>The sample <span class="math inline">\(\{y_1,\ldots,y_N\}\)</span> is a sample of independent random variables each of which is normally distributed with mean <span class="math inline">\((\mu-\sigma^2/2)\sqrt{\Delta t}\)</span> and variance <span class="math inline">\(\sigma^2\)</span>. As was discussed in the previous section, the best estimate of the mean of <span class="math inline">\(y\)</span> is the sample mean <span class="math display">\[\bar{y} = \frac{1}{N}\sum_{i=1}^{N}y_i\; ,\]</span> and the best estimate of <span class="math inline">\(\sigma^2\)</span> is <span class="math display">\[\hat{\sigma}^2 = \frac{1}{N-1}\sum_{i=1}^{N} (y_i-\bar{y})^2\; .\]</span> This means that we estimate <span class="math inline">\(\mu\)</span> as <span class="math display">\[\hat{\mu} = \frac{\bar{y}}{\sqrt{\Delta t}} + \frac{1}{2}\hat{\sigma}^2 = \bar{r}+ \frac{1}{2}\hat{\sigma}^2\; .\]</span></p>
<p>Let us digress for a moment to discuss the reliability of <span class="math inline">\(\hat{\mu}\)</span> as an estimate of <span class="math inline">\(\mu\)</span>. Notice that</p>
<p><span class="math display">\[
\bar{r}
= \frac{\sum_{i=1}^N \log S(t_i)-\log S(t_{i-1})}{N\Delta t}
\]</span> <span class="math display">\[
=   \frac{\log S(T)-\log S(0)}{N\Delta t}
\]</span> <span id="eq-volrbar"><span class="math display">\[
= \frac{\log S(T)-\log S(0)}{T}\;.
\tag{5.4}\]</span></span></p>
<p>Therefore the first component <span class="math inline">\(\bar{r}\)</span> of the estimate of <span class="math inline">\(\mu\)</span> depends only on the total change in <span class="math inline">\(S\)</span> over the time period. Hence, the reliability of this component cannot depend on how frequently we observe <span class="math inline">\(S\)</span> within the time period <span class="math inline">\([0,T]\)</span>. The standard deviation of <span class="math inline">\(\bar{r}\)</span> in repeated samples is the standard deviation of <span class="math inline">\([\log S(T)-\log S(0)]/T\)</span>, which is <span class="math inline">\(\sigma/\sqrt{T}\)</span>. This is likely to be quite large. For example, with <span class="math inline">\(\sigma =0.3\)</span> and ten years of data (<span class="math inline">\(T=10\)</span>), the standard deviation of <span class="math inline">\(\bar{r}\)</span> is 9.5%, which means that a 95% confidence interval will be a band of roughly 38%. Given that <span class="math inline">\(\mu\)</span> itself should be of the order of magnitude of 10%, such a wide confidence interval is useless for all practical purposes.</p>
<p>Fortunately, it is easier to estimate <span class="math inline">\(\sigma\)</span>. We observed in the previous section that the <span class="math inline">\(\hat{\sigma}^2\)</span> defined above can be calculated as <span id="eq-estimator_sig2"><span class="math display">\[
\frac{1}{N-1}\sum_{i=1}^N y_i^2 - \frac{N\bar{y}^2}{N-1}\;.
\tag{5.5}\]</span></span></p>
<p>From <a href="#eq-volyi">Equation&nbsp;<span class="quarto-unresolved-ref">eq-volyi</span></a> of <span class="math inline">\(y_i\)</span> and <a href="#eq-volrbar">Equation&nbsp;<span class="quarto-unresolved-ref">eq-volrbar</span></a>, we have <span class="math display">\[\bar{y} =  \frac{\sqrt{\Delta t}}{T}[\log S(T)-\log S(0)]\; .\]</span> Hence, the second term in <a href="#eq-estimator_sig2">Equation&nbsp;<span class="quarto-unresolved-ref">eq-estimator_sig2</span></a> is <span class="math display">\[ \frac{N}{N-1}\left(\frac{\Delta t}{T^2}\right)[\log S(T)-\log S(0)]^2\; .\]</span> If we observe the stock price sufficiently frequently, so that <span class="math inline">\(\Delta t\)</span> is very small, this term will be negligible. In this circumstance, <span class="math inline">\(\hat{\sigma}^2\)</span> is approximately</p>
<p><span class="math display">\[
\frac{1}{N-1}\sum_{i=1}^N y_i^2 = \frac{1}{N-1}\sum_{i=1}^N \frac{[\log S(t_i)-\log S(t_{i-1})]^2}{\Delta t}
\]</span> <span id="eq-estimator_sig2_3"><span class="math display">\[
= \frac{N}{N-1}\times \frac{1}{T}\times \sum_{i=1}^N [\log S(t_i)-\log S(t_{i-1})]^2 \;.
\tag{5.6}\]</span></span></p>
<p>If we observe <span class="math inline">\(S\)</span> more and more frequently, letting <span class="math inline">\(\Delta t \rightarrow 0\)</span> and <span class="math inline">\(N \rightarrow \infty\)</span>, the sum <span class="math display">\[\sum_{i=1}^N [\log S(t_i)-\log S(t_{i-1})]^2\]</span> will converge with probability one to <span class="math inline">\(\sigma^2T\)</span>, as explained in <a href="#sec-s_quadraticvariation"><span class="quarto-unresolved-ref">sec-s_quadraticvariation</span></a>. This implies that <span class="math inline">\(\hat{\sigma}^2\)</span> will converge to <span class="math inline">\(\sigma^2\)</span>. Thus, in theory, we can estimate <span class="math inline">\(\sigma^2\)</span> with any desired degree of precision by simply observing <span class="math inline">\(S\)</span> sufficiently frequently. This is true no matter how short the overall time period <span class="math inline">\([0,T]\)</span> may be.</p>
<p>In practice, this doesn’t work out quite so well. If we observe minute-by-minute data, or we observe each transaction, much of the variation in the price <span class="math inline">\(S\)</span> will be due to bouncing back and forth between the bid price and the ask price. This is not really what we want to estimate, and this source of variation will be much less important if we look at weekly or even daily data. So, there are practical limits to how frequently we should observe <span class="math inline">\(S\)</span>. Nevertheless, it is still true that, if <span class="math inline">\(\sigma^2\)</span> were truly constant, we could estimate it with a very high degree of precision. In fact, we can estimate the volatility of a stock with enough precision to determine that it really isn’t constant! The real problem that we face is to estimate and model a changing volatility.</p>
</section>
<section id="estimating-a-changing-volatility" class="level2" data-number="5.3">
<h2 data-number="5.3" class="anchored" data-anchor-id="estimating-a-changing-volatility"><span class="header-section-number">5.3</span> Estimating a Changing Volatility</h2>
<p>Without attempting yet to model how the volatility may change, we can say a few things about how we might estimate a changing volatility. In this and following sections, we will take the observation interval <span class="math inline">\(\Delta t\)</span> to be fixed. We assume it is small (say, a day or a week) and focus on the estimate <a href="#eq-estimator_sig2_3">Equation&nbsp;<span class="quarto-unresolved-ref">eq-estimator_sig2_3</span></a>. Recall from <a href="#sec-s_statistics"><span class="quarto-unresolved-ref">sec-s_statistics</span></a> that the reason we are dividing by <span class="math inline">\(N-1\)</span> rather than <span class="math inline">\(N\)</span> is that the sample standard deviation usually underestimates the actual standard deviation, because it uses the sample mean, which will be closer to the points <span class="math inline">\(x_i\)</span> than will be the true mean. However, <a href="#eq-estimator_sig2_3">Equation&nbsp;<span class="quarto-unresolved-ref">eq-estimator_sig2_3</span></a> does not employ the sample mean (it replaces it with zero), so there is no reason to make this correction. So, we take as our point of departure the estimate <span class="math display">\[\frac{1}{T} \sum_{i=1}^N [\log S(t_i)-\log S(t_{i-1})]^2 = \frac{1}{N}\sum_{i=1}^N y_i^2 \; .\]</span> An obvious response to the volatility changing over time is simply to avoid using data from the distant past. Such data is not likely to be informative about the current value of the volatility. What distant should mean in this context is not entirely clear, but, for example, we might want to use only the last 60 observations. If we are using daily data, this would mean that at the end of each day we would add that day’s observation and drop the observation from 61 days past. This leads to a somewhat abruptly varying estimate. For example, a very large movement in the price on a particular day increases the volatility estimate for the next 60 days. On the 61st day, this observation would drop from the sample, leading to an abrupt drop in the estimate (presuming that there is not an equally large change in <span class="math inline">\(S\)</span> on the 61st day). This seems unreasonable. An estimate in which the impact of each observation decays smoothly over time is more attractive.</p>
<p>We can construct such an estimate as <span id="eq-sig_estimator4"><span class="math display">\[
\hat{\sigma}^2_{i+1} = (1-\lambda) y_{i}^2 + \lambda\hat{\sigma}^2_{i}
\tag{5.7}\]</span></span></p>
<p>for any constant <span class="math inline">\(0&lt;\lambda&lt;1\)</span>. Here, <span class="math inline">\(\hat{\sigma}^2_{i+1}\)</span> denotes the estimate of the volatility from date <span class="math inline">\(t_{i}\)</span> to date <span class="math inline">\(t_{i+1}\)</span>. The estimate <a href="#eq-sig_estimator4">Equation&nbsp;<span class="quarto-unresolved-ref">eq-sig_estimator4</span></a> is a weighted average of the estimate <span class="math inline">\(\hat{\sigma}^2_{i}\)</span> for the previous time period and the most recently observed squared change <span class="math inline">\(y_{i}^2\)</span>. Following the same procedure, the next estimate will be <span class="math display">\[\begin{align*}
\hat{\sigma}^2_{i+2}&amp; = (1-\lambda) y_{i+1}^2 + \lambda\hat{\sigma}^2_{i+1}\\
&amp;= (1-\lambda) y_{i+1}^2 + \lambda(1-\lambda)  y_{i}^2 + \lambda^2\hat{\sigma}^2_{i}\;.
\end{align*}\]</span> Likewise, the estimate at the following date will be <span class="math display">\[\hat{\sigma}^2_{i+3} = (1-\lambda) y_{i+2}^2 +\lambda(1-\lambda) y_{i+1}^2 + \lambda^2(1-\lambda)^2  y_{i}^2 +\lambda^{3}\hat{\sigma}^2_{i}\; .\]</span> This demonstrates the declining importance of the squared deviation <span class="math inline">\(y_{i}^2\)</span> for future estimates. At each date, <span class="math inline">\(y_{i}^2\)</span> enters with a weight that is lower by a factor of <span class="math inline">\(\lambda\)</span>, compared to the previous date. If <span class="math inline">\(\lambda\)</span> is small, the decay in the importance of each squared deviation will be fast. In fact, <a href="#eq-sig_estimator4">Equation&nbsp;<span class="quarto-unresolved-ref">eq-sig_estimator4</span></a> shows that, if <span class="math inline">\(\lambda\)</span> is close to zero, the estimate <span class="math inline">\(\hat{\sigma}_{i+1}^2\)</span> is approximately equal to the squared deviation <span class="math inline">\(y_i^2\)</span>—previous squared deviations are relatively unimportant. On the other hand, if <span class="math inline">\(\lambda\)</span> is close to one, the decay will be slow; i.e., the importance of <span class="math inline">\(y_i^2\)</span> for the estimate <span class="math inline">\(\hat{\sigma}^2_{i+2}\)</span> will be nearly the same as for <span class="math inline">\(\hat{\sigma}^2_{i+1}\)</span>, and nearly the same for <span class="math inline">\(\hat{\sigma}^2_{i+3}\)</span> as for <span class="math inline">\(\hat{\sigma}^2_{i+2}\)</span>, etc. This will lead to a smooth (slowly varying) volatility estimate. The slowly varying nature of the estimate in this case is also clear from <a href="#eq-sig_estimator4">Equation&nbsp;<span class="quarto-unresolved-ref">eq-sig_estimator4</span></a>, because it shows that if <span class="math inline">\(\lambda\)</span> is close to one, then <span class="math inline">\(\hat{\sigma}^2_{i+1}\)</span> will be approximately the same as <span class="math inline">\(\hat{\sigma}^2_{i}\)</span>.</p>
<p>This method can also be used to estimate covariances, simply by replacing the squared deviations <span class="math inline">\(y_i^2\)</span> by the product of deviations for two different assets. And, of course, given covariance and variance estimates, we can construct estimates of correlations. To ensure that an estimated correlation is between <span class="math inline">\(-1\)</span> and <span class="math inline">\(+1\)</span>, we will need to use the same <span class="math inline">\(\lambda\)</span> to estimate each of the variances and the covariance. This is the method used by RiskMetrics.^[See Mina and Xiao <span class="citation" data-cites="MX">(<a href="#ref-MX" role="doc-biblioref">Mina and Xiao 2001</a>)</span>, available online at </p>
</section>
<section id="sec-s_garch" class="level2" data-number="5.4">
<h2 data-number="5.4" class="anchored" data-anchor-id="sec-s_garch"><span class="header-section-number">5.4</span> GARCH Models</h2>
<p>We are going to adopt a subtle but important change of perspective now. Instead of considering <a href="#eq-sig_estimator4">Equation&nbsp;<span class="quarto-unresolved-ref">eq-sig_estimator4</span></a> as simply an estimation procedure, we are going to assume that the actual volatility evolves according to <a href="#eq-sig_estimator4">Equation&nbsp;<span class="quarto-unresolved-ref">eq-sig_estimator4</span></a>, or a generalization thereof. We are also going to reintroduce the expected change in <span class="math inline">\(\log S\)</span>, which we dropped in going from <a href="#eq-estimator_sig2">Equation&nbsp;<span class="quarto-unresolved-ref">eq-estimator_sig2</span></a> to <a href="#eq-estimator_sig2_3">Equation&nbsp;<span class="quarto-unresolved-ref">eq-estimator_sig2_3</span></a>. Specifically, we return to <a href="#eq-dlogs">Equation&nbsp;<span class="quarto-unresolved-ref">eq-dlogs</span></a>, but we operate under the risk-neutral measure, so <span class="math inline">\(\mu=r-q\)</span>, and we have <span id="eq-dlogs2"><span class="math display">\[
\log S(t_{i+1}) - \log S(t_i) = \left(r-q-\frac{1}{2}\sigma_{i+1}^2\right)\Delta t + \sigma_{i+1} \Delta B\;.
\tag{5.8}\]</span></span></p>
<p>We assume the volatility <span class="math inline">\(\sigma_{i+1}\)</span> between dates <span class="math inline">\(t_i\)</span> and <span class="math inline">\(t_{i+1}\)</span> is given by <span id="eq-garch"><span class="math display">\[
\sigma_{i+1}^2 = a + b y_{i}^2 + c \sigma_i^2\;,
\tag{5.9}\]</span></span></p>
<p>for some constants <span class="math inline">\(a &gt; 0\)</span>, <span class="math inline">\(b\geq 0\)</span> and <span class="math inline">\(c\geq 0\)</span>, with <span class="math inline">\(y_i\)</span> now defined by <span class="math display">\[y_i = \frac{\log S(t_i)-\log S(t_{i-1})-\left(r-q-\frac{1}{2}\sigma_i^2\right)\Delta t}{\sqrt{\Delta t}}\; .\]</span> From <a href="#eq-dlogs2">Equation&nbsp;<span class="quarto-unresolved-ref">eq-dlogs2</span></a>, applied to the period from <span class="math inline">\(t_{i-1}\)</span> to <span class="math inline">\(t_i\)</span>, this implies that <span class="math inline">\(y_i\)</span> is normally distributed with mean zero and variance <span class="math inline">\(\sigma_i^2\)</span>, and of course <span class="math inline">\(y_{i+1}\)</span> has variance <span class="math inline">\(\sigma_{i+1}^2\)</span>, etc.<br>
Under these assumptions, the random process <span class="math inline">\(\log S\)</span> is called a GARCH(1,1) process.^[GARCH is the acronym for Generalized Autoregressive Conditional Heteroskedastic. GARCH(1,1) means that there is only one past <span class="math inline">\(y\)</span> (no <span class="math inline">\(y_{i-1]\)</span>, <span class="math inline">\(y_{i-2}\)</span>, etc.) and one past <span class="math inline">\(\sigma\)</span> (no <span class="math inline">\(\sigma_{i-1}\)</span>, <span class="math inline">\(\sigma_{i-2}\)</span>, etc.) in <a href="#eq-garch">Equation&nbsp;<span class="quarto-unresolved-ref">eq-garch</span></a>. See Bollerslev <span class="citation" data-cites="Bollerslev">(<a href="#ref-Bollerslev" role="doc-biblioref">Bollerslev 1986</a>)</span>.} There are many varieties of GARCH processes that have been proposed in the literature, but we will only consider GARCH(1,1), which is the simplest.</p>
<p>We assume <span class="math inline">\(b+c&lt;1\)</span>, in which case we can write the variance equation as a generalization of <a href="#eq-sig_estimator4">Equation&nbsp;<span class="quarto-unresolved-ref">eq-sig_estimator4</span></a>. Namely, %<span class="math display">\[\sigma_{i+1}^2 = (1-\phi)d + \phi\left[(1-\lambda) y_{i}^2 + \lambda \sigma^2_{i}\right]\; ,\]</span> <span id="eq-garch10"><span class="math display">\[
\sigma_{i+1}^2 = \kappa\theta + (1-\kappa)\left[  (1-\lambda) y_{i}^2 + \lambda\sigma^2_{i}\right]\;,
\tag{5.10}\]</span></span></p>
<p>where <span class="math inline">\(\lambda=c/(b+c)\)</span>, %<span class="math inline">\(\phi=b+c\)</span>, and <span class="math inline">\(d=a/(1-b-c)\)</span>.<br>
<span class="math inline">\(\kappa = 1-b-c\)</span>, and <span class="math inline">\(\theta=a/(1-b-c)\)</span>. Hence, <span class="math inline">\(\sigma_{i+1}^2\)</span> is a weighted average with weights <span class="math inline">\(\kappa\)</span> and <span class="math inline">\(1-\kappa\)</span>, of two parts, one being the constant <span class="math inline">\(\theta\)</span> and the other being itself a weighted average of <span class="math inline">\(y_{i}^2\)</span> and <span class="math inline">\(\sigma^2_{i}\)</span>. Whatever the variance might be at time <span class="math inline">\(t_i\)</span>, the variance of <span class="math inline">\(y_j\)</span> at any date <span class="math inline">\(t_j\)</span> far into the future, computed without knowing the intervening <span class="math inline">\(y_{i+1}, y_{i+2},\ldots\)</span>, will be approximately the constant <span class="math inline">\(\theta\)</span>. The constant <span class="math inline">\(\theta\)</span> is called the unconditional variance, whereas <span class="math inline">\(\sigma_{i}^2\)</span> is the conditional variance of <span class="math inline">\(y_i\)</span>. </p>
<p>To understand the unconditional variance, it is useful to consider the variance forecasting equation. Specifically, we can calculate <span class="math inline">\(E_{t_i} \left[\sigma_{i+n}^2\right]\)</span>, which is the estimate made at date <span class="math inline">\(t_i\)</span> of the variance of <span class="math inline">\(y_{i+n}\)</span>; i.e, we estimate the variance without having observed <span class="math inline">\(y_{i+1},\ldots,y_{i+n-1}\)</span>. Note that by definition <span class="math inline">\(E_{t_{i}}[y_{i+1}^2]=\sigma_{i+1}^2\)</span>, so <a href="#eq-garch10">Equation&nbsp;<span class="quarto-unresolved-ref">eq-garch10</span></a> implies <span class="math display">\[\begin{align*}
E_{t_{i}}\left[\sigma_{i+2}^2\right] &amp;= \kappa\theta + (1-\kappa)\left[  (1-\lambda) E_{t_{i}}[y_{i+1}^2] + \lambda\sigma^2_{i+1}\right] \\
&amp;= \kappa\theta + (1-\kappa)\sigma^2_{i+1}\; .
\end{align*}\]</span> Likewise, <span class="math display">\[E_{t_{i+1}}\left[\sigma_{i+3}^2\right] = \kappa\theta + (1-\kappa)\sigma^2_{i+2}\; ,\]</span> and taking the expectation at date <span class="math inline">\(t_i\)</span> of both sides of this yields <span class="math display">\[\begin{align*}
E_{t_{i}}\left[\sigma_{i+3}^2\right] = E_{t_{i}}\left[E_{t_{i+1}}\left[\sigma_{i+3}^2\right]\right] &amp;=\kappa\theta + (1-\kappa)E_{t_{i}}\left[\sigma_{i+2}^2\right]\\
&amp;=\kappa\theta + (1-\kappa)\left[\kappa\theta + (1-\kappa)\sigma^2_{i+1}\right]\\
&amp;=\kappa\theta[1+(1-\kappa)] + (1-\kappa)^2\sigma^2_{i+1}\;.
\end{align*}\]</span> This generalizes to <span class="math display">\[E_{t_{i}}\left[\sigma_{i+n}^2\right] = \kappa\theta\left[1+(1-\kappa)+ \cdots (1-\kappa)^{n-2}\right] + (1-\kappa)^{n-1}\sigma^2_{i+1}\; .\]</span> Thus, there is decay at rate <span class="math inline">\(\kappa\)</span> in the importance of the current volatility <span class="math inline">\(\sigma^2_{i+1}\)</span> for forecasting the future volatility. Furthermore, as <span class="math inline">\(n\rightarrow \infty\)</span>, the geometric series <span class="math display">\[1+(1-\kappa)+ \cdots (1-\kappa)^{n-2}\]</span> converges to <span class="math inline">\(1/\kappa\)</span>, so, as <span class="math inline">\(n \rightarrow \infty\)</span> we obtain <span class="math display">\[E_{t_{i}}\left[\sigma_{i+n}^2\right] \rightarrow \theta\; .\]</span> This means that our best estimate of the conditional variance, at some date far in the future, is approximately the unconditional variance <span class="math inline">\(\theta\)</span>.</p>
<p>The most interesting feature of the volatility equation is that large returns (in absolute value) lead to an increase in the variance and hence are likely to be followed by more large returns (whether positive or negative). This is the phenomenon of volatility clustering, which is quite observable in actual markets. This feature also implies that the distribution of returns will be fat tailed (more technically, leptokurtic). This means that the probability of extreme returns is higher than under a normal distribution with the same standard deviation.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> It is well documented that daily and weekly returns in most markets have this fat-tailed property.</p>
<p>We can simulate a path of an asset price that follows a GARCH process and the path of its volatility as follows. The following macro produces three columns of data (with headings), the first column being time, the second the asset price, and the third the volatility.</p>
<p>To price European options, we need to compute the usual probabilities <span class="math inline">\(\text{prob}^S(S(T)&gt;K)\)</span> and <span class="math inline">\(\text{prob}^R(S(T) &gt;K)\)</span>. Heston and Nandi <span class="citation" data-cites="HN">(<a href="#ref-HN" role="doc-biblioref">Heston and Nandi 2000</a>)</span> provide a fast method for computing these probabilities in a GARCH (1,1) model.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> Rather than developing this approach, we will show in <a href="#sec-c_introcomputation"><span class="quarto-unresolved-ref">sec-c_introcomputation</span></a> how to apply Monte-Carlo methods.</p>
</section>
<section id="sec-s_stochasticvolatility" class="level2" data-number="5.5">
<h2 data-number="5.5" class="anchored" data-anchor-id="sec-s_stochasticvolatility"><span class="header-section-number">5.5</span> Stochastic Volatility Models</h2>
<p>The volatility is stochastic (random) in a GARCH model, but it is determined by the changes in the stock price. In this section, in contrast, we will consider models in which the volatility depends on a second Brownian motion. The most popular model of this type is the model of Heston <span class="citation" data-cites="Heston">(<a href="#ref-Heston" role="doc-biblioref">Heston 1993</a>)</span>. In this model, we have, as usual,</p>
<p><span id="eq-heston1"><span class="math display">\[
\mathrm{d}\log S = \left(r-q-\frac{1}{2}\sigma^2\right)\,\mathrm{d} t + \sigma\,\mathrm{d} B_s\;,
\tag{5.11}\]</span></span></p>
<p>where <span class="math inline">\(B_s\)</span> is a Brownian motion under the risk-neutral measure but now <span class="math inline">\(\sigma\)</span> is not a constant but instead evolves as <span class="math inline">\(\sigma(t) = \sqrt{v(t)}\)</span> where</p>
<p><span id="eq-heston2"><span class="math display">\[
dv(t) = \kappa \big[\theta-v(t)\big]\,\mathrm{d} t + \gamma \sqrt{v(t)}\,\mathrm{d} B_v\;,
\tag{5.12}\]</span></span></p>
<p>where <span class="math inline">\(B_v\)</span> is a Brownian motion under the risk-neutral measure having a constant correlation <span class="math inline">\(\rho\)</span> with the Brownian motion <span class="math inline">\(B_s\)</span>. In this equation, <span class="math inline">\(\kappa\)</span>, <span class="math inline">\(\theta\)</span> and <span class="math inline">\(\gamma\)</span> are positive constants. Given the empirical fact that negative return shocks have a bigger impact on future volatility than do positive shocks, one would expect the correlation <span class="math inline">\(\rho\)</span> to be negative.</p>
<p>The term <span class="math inline">\(\kappa (\theta-v)\)</span> will be positive when <span class="math inline">\(v&lt;\theta\)</span> and negative when <span class="math inline">\(v&gt;\theta\)</span> and hence <span class="math inline">\(\sigma^2=v\)</span> will tend to drift towards <span class="math inline">\(\theta\)</span>, which, as in the GARCH model, is the long-run or unconditional mean of <span class="math inline">\(\sigma^2\)</span>. Thus, the volatility is said to mean revert. The rate at which it drifts towards <span class="math inline">\(\theta\)</span> is obviously determined by the magnitude of <span class="math inline">\(\kappa\)</span>, also as in the GARCH model.</p>
<p>The specification <a href="#eq-heston2">Equation&nbsp;<span class="quarto-unresolved-ref">eq-heston2</span></a> implies that the volatility of <span class="math inline">\(v\)</span> approaches zero whenever <span class="math inline">\(v\)</span> approaches zero. In this circumstance, one might expect the drift towards <span class="math inline">\(\theta\)</span> to dominate the volatility and keep <span class="math inline">\(v\)</span> nonnegative, and this is indeed the case; thus, the definition <span class="math inline">\(\sigma(t) = \sqrt{v(t)}\)</span> is possible. Moreover, the parameter <span class="math inline">\(\gamma\)</span> plays a role here that is similar to the role of <span class="math inline">\(1-\lambda\)</span> in the GARCH model—the variance of the variance in the GARCH model <a href="#eq-garch10">Equation&nbsp;<span class="quarto-unresolved-ref">eq-garch10</span></a> depends on the weight <span class="math inline">\(1-\lambda\)</span> placed on the scaled return <span class="math inline">\(y_i\)</span>, just as the variance of the variance in the stochastic volatility model <a href="#eq-heston2">Equation&nbsp;<span class="quarto-unresolved-ref">eq-heston2</span></a> depends on the weight <span class="math inline">\(\gamma\)</span> placed on <span class="math inline">\(\mathrm{d} B_v\)</span>.</p>
<p>We could discretize <a href="#eq-heston1">Equation&nbsp;<span class="quarto-unresolved-ref">eq-heston1</span></a> - <a href="#eq-heston2">Equation&nbsp;<span class="quarto-unresolved-ref">eq-heston2</span></a> as:</p>
<p><span id="eq-heston3"><span class="math display">\[
\log S(t_{i+1}) = \log S(t_i) + \left(r-q-\frac{1}{2}\sigma(t_i)^2\right)\,\Delta t + \sqrt{v(t_i)}\,\Delta B_s,
\tag{5.13}\]</span></span></p>
<p><span id="eq-heston4"><span class="math display">\[
v(t_{i+1}) = v(t_i) + \kappa \big[\theta-v(t_i)\big]\,\Delta t + \gamma \sqrt{v(t_i)}\,\Delta B_v\;.
\tag{5.14}\]</span></span></p>
<p>However, even though in the continuous-time model <a href="#eq-heston1">Equation&nbsp;<span class="quarto-unresolved-ref">eq-heston1</span></a> - <a href="#eq-heston2">Equation&nbsp;<span class="quarto-unresolved-ref">eq-heston2</span></a> we always have <span class="math inline">\(v(t) \geq 0\)</span> and hence can define <span class="math inline">\(\sigma(t)=\sqrt{v(t)}\)</span>, there is no guarantee that <span class="math inline">\(v(t_{i+1})\)</span> defined by <a href="#eq-heston4">Equation&nbsp;<span class="quarto-unresolved-ref">eq-heston4</span></a> will be nonnegative. A simple remedy is to define <span class="math inline">\(v(t_{i+1})\)</span> as the larger of zero and the right-hand side of <a href="#eq-heston4">Equation&nbsp;<span class="quarto-unresolved-ref">eq-heston4</span></a>; thus, we will simulate the Heston model as <a href="#eq-heston3">Equation&nbsp;<span class="quarto-unresolved-ref">eq-heston3</span></a> and<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> <span id="eq-heston41"><span class="math display">\[
v(t_{i+1}) = \max\left\{0,v(t_i) + \kappa \big[\theta-v(t_i)\big]\,\Delta t + \gamma \sqrt{v(t_i)}\,\Delta B_v\right\}\;.
\tag{5.15}\]</span></span></p>
<p>A simple way to simulate the changes <span class="math inline">\(\Delta B_s\)</span> and <span class="math inline">\(\Delta B_v\)</span> in the two correlated Brownian motions is to generate two independent standard normals <span class="math inline">\(z_1\)</span> and <span class="math inline">\(z_2\)</span> and take <span class="math display">\[\Delta B_s = \sqrt{\Delta t}\,z \qquad \text{and} \qquad \Delta B_v = \sqrt{\Delta t}\,z^*\; ,\]</span> where we define <span class="math display">\[z = z_1 \qquad \text{and} \qquad z^* = \rho z_1 + \sqrt{1-\rho^2}\,z_2\; .\]</span> The random variable <span class="math inline">\(z^*\)</span> is also a standard normal, and the correlation between <span class="math inline">\(z\)</span> and <span class="math inline">\(z^*\)</span> is <span class="math inline">\(\rho\)</span>.</p>
<p>To price European options, we again need to compute <span class="math display">\[\text{prob}^S(S(T)&gt;K) \qquad \text{and} \qquad \text{prob}^R(S(T)&gt;K)\; .\]</span> The virtue of modelling volatility as in <a href="#eq-heston2">Equation&nbsp;<span class="quarto-unresolved-ref">eq-heston2</span></a> is that these probabilities can be computed quite efficiently, as shown by Heston <span class="citation" data-cites="Heston">(<a href="#ref-Heston" role="doc-biblioref">Heston 1993</a>)</span>.<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> There are many other ways in which one could model volatility, but the computations may be more difficult. For example, one could replace <a href="#eq-heston2">Equation&nbsp;<span class="quarto-unresolved-ref">eq-heston2</span></a> by <span id="eq-heston5"><span class="math display">\[
\sigma(t) = \mathrm{e}^{v(t)} \quad \text{and} \quad dv(t) = \kappa (\theta-v(t))\,\mathrm{d} t + \lambda \,\mathrm{d} B^*\;.
\tag{5.16}\]</span></span></p>
<p>This implies a lognormal volatility and is simpler to simulate than <a href="#eq-heston2">Equation&nbsp;<span class="quarto-unresolved-ref">eq-heston2</span></a>—because <span class="math inline">\(\mathrm{e}^{v}\)</span> is well defined even when <span class="math inline">\(v\)</span> is negative—but it is easier to calculate the probabilities <span class="math inline">\(\text{prob}^S(S(T)&gt;K)\)</span> and <span class="math inline">\(\text{prob}^R(S(T)&gt;K)\)</span> if we assume <a href="#eq-heston2">Equation&nbsp;<span class="quarto-unresolved-ref">eq-heston2</span></a>.</p>
<p>One way to implement the GARCH or stochastic volatility model is to imply both the initial volatility <span class="math inline">\(\sigma(0)\)</span> and the constants <span class="math inline">\(\kappa\)</span>, <span class="math inline">\(\theta\)</span> and <span class="math inline">\(\lambda\)</span> or <span class="math inline">\(\kappa\)</span>, <span class="math inline">\(\theta\)</span>, <span class="math inline">\(\gamma\)</span> and <span class="math inline">\(\rho\)</span> from observed option prices. These four (or five) constants can be computed by forcing the model prices of four (or five) options to equal the observed market prices. Or, a larger set of prices can be used and the constants can be chosen to minimize the average squared error or some other measure of goodness-of-fit between the model and market prices.</p>
</section>
<section id="sec-s_smilesagain" class="level2" data-number="5.6">
<h2 data-number="5.6" class="anchored" data-anchor-id="sec-s_smilesagain"><span class="header-section-number">5.6</span> Smiles and Smirks Again</h2>
<p>As mentioned before, the GARCH and stochastic volatility models can generate fat-tailed distributions for the asset price <span class="math inline">\(S(T)\)</span>. Thus, they can be more nearly consistent with the option smiles discussed in <a href="#sec-s_smiles"><span class="quarto-unresolved-ref">sec-s_smiles</span></a> than is the Black-Scholes model (though it appears that one must include jumps in asset prices as well as stochastic volatility in order to duplicate market prices with an option pricing formula). To understand the relation, let <span class="math inline">\(\sigma_\text{am}\)</span> denote the implied volatility from an at-the-money call option, i.e., a call option with strike <span class="math inline">\(K=S(0)\)</span>. The characteristic of a smile is that implied volatilities from options of the same maturity with strike prices significantly above and below <span class="math inline">\(S(0)\)</span> are higher than <span class="math inline">\(\sigma_\text{am}\)</span>.</p>
<p>A strike price higher than <span class="math inline">\(S(0)\)</span> corresponds to an out-of-the money call option. The high implied volatility means that the market is pricing the right to buy at <span class="math inline">\(K&gt;S(0)\)</span> above the Black-Scholes price computed from the volatility <span class="math inline">\(\sigma_\text{am}\)</span>; thus, the market must attach a higher probability to stock prices <span class="math inline">\(S(T)&gt;S(0)\)</span> than the volatility <span class="math inline">\(\sigma_\text{am}\)</span> would suggest.</p>
<p>A strike price lower than <span class="math inline">\(S(0)\)</span> corresponds to an in-the-money call option. The put option with the same strike is out of the money. The high implied volatility means that the market is pricing call options above the Black-Scholes price computed from the volatility <span class="math inline">\(\sigma_\text{am}\)</span>. By put-call parity, the market must also be pricing put options above the Black-Scholes price computed from the volatility <span class="math inline">\(\sigma_\text{am}\)</span>. The high prices for the rights to buy and sell at <span class="math inline">\(K&lt;S(0)\)</span> means that the market must attach a higher probability to stock prices <span class="math inline">\(S(T)&lt;S(0)\)</span> than the volatility <span class="math inline">\(\sigma_\text{am}\)</span> would suggest. In particular, the high price for the right to sell at <span class="math inline">\(K&lt;S(0)\)</span> means a high insurance premium for owners of the asset who seek to insure their positions, which is consistent with a market view that there is a significant probability of a large loss. This can be interpreted as a crash premium. Indeed, the implied volatilities at strikes less than <span class="math inline">\(S(0)\)</span> are typically higher than the implied volatilities at strikes above <span class="math inline">\(S(0)\)</span> (giving the smile the appearance of a smirk, as discussed in <a href="#sec-s_smiles"><span class="quarto-unresolved-ref">sec-s_smiles</span></a>), which is consistent with a larger probability of crashes than of booms (a fatter tail for low returns than for high).</p>
</section>
<section id="hedging-and-market-completeness" class="level2" data-number="5.7">
<h2 data-number="5.7" class="anchored" data-anchor-id="hedging-and-market-completeness"><span class="header-section-number">5.7</span> Hedging and Market Completeness</h2>
<p>The GARCH model is inherently a discrete-time model. If returns have a GARCH structure at one frequency (e.g., monthly), they will not have a GARCH structure at a different frequency (e.g., weekly). Hence, the return period (monthly, weekly, ) is part of the specification of the model. One interpretation of the model is that the dates <span class="math inline">\(t_i\)</span> at which the variance changes are the only dates at which investors can trade. Under this interpretation, it is impossible to perfectly hedge an option: the gross return <span class="math inline">\(S(t_i)/S(t_{i-1})\)</span> over the interval <span class="math inline">\((t_{i-1},t_i)\)</span> is lognormally distributed, so no portfolio of the stock and riskless asset formed at <span class="math inline">\(t_{i-1}\)</span> and held over the interval <span class="math inline">\((t_{i-1},t_i)\)</span> can perfectly replicate the return of an option over the interval. As discussed in <a href="#sec-s_incomplete"><span class="quarto-unresolved-ref">sec-s_incomplete</span></a>, we call a market in which some derivatives cannot be perfectly hedged an incomplete market. Thus, the GARCH model is an example of an incomplete market, if investors can only trade at the frequency at which returns have a GARCH structure. However, it is unreasonable to assume that investors can only trade weekly or monthly or even daily.</p>
<p>Another interpretation of the GARCH model is that investors can trade continuously and the asset has a constant volatility within each period <span class="math inline">\((t_{i-1},t_i)\)</span>. Under this interpretation, the market is complete and options can be delta-hedged. The completeness is a result of the fact that the change <span class="math inline">\(\sigma_{i+1}-\sigma_i\)</span> in the volatility at date <span class="math inline">\(t_i\)</span> (recall that <span class="math inline">\(\sigma_i\)</span> is the volatility over the period <span class="math inline">\((t_{i-1},t_i)\)</span> and <span class="math inline">\(\sigma_{i+1}\)</span> is the volatility over the period <span class="math inline">\((t_{i},t_{i+1})\)</span>) depends only on <span class="math inline">\(\log S(t_i)\)</span>. Thus, the only random factor in the model that needs to be hedged is, as usual, the underlying asset price. However, this interpretation of the model is also a bit strange. Suppose for example that monthly returns are assumed to have a GARCH structure. Then the model states that the volatility in February will be higher if there is an unusually large return (in absolute value) in January. Suppose there is an unusually large return in the first half of January. Then, intuitively, one would expect the change in the volatility to occur in the second half of January rather than being delayed until February. However, the model specifies that the volatility is constant during each month, hence constant during January in this example.</p>
<p>The stochastic volatility model is more straightforward. The market is definitely incomplete. The value of a call option at date <span class="math inline">\(t&lt;T\)</span>, where <span class="math inline">\(T\)</span> is the maturity of the option, will depend on the underlying asset price <span class="math inline">\(S(t)\)</span> and the volatility <span class="math inline">\(\sigma(t)\)</span>. Denoting the value by <span class="math inline">\(C(t,S(t),\sigma(t))\)</span>, we have from Ito’s formula that <span class="math display">\[
\mathrm{d} C(t) = \text{something}\;\mathrm{d} t + \frac{\partial C}{\partial S}\,\mathrm{d} S(t) + \frac{\partial C}{\partial \sigma}\,\mathrm{d} \sigma(t)\; .\]</span> A replicating portfolio must have the same dollar change at each date <span class="math inline">\(t\)</span>. If we hold <span class="math inline">\(\partial C/\partial S\)</span> shares of the underlying asset, then the change in the value of the shares will be <span class="math inline">\((\partial C/\partial S)\,\mathrm{d} S\)</span>. However, there is no way to match the<br>
<span class="math inline">\((\partial C/\partial \sigma)\,\mathrm{d} \sigma\)</span> term using the underlying asset and the riskless asset.</p>
<p>The significance of the market being incomplete is that the value of a derivative asset that cannot be replicated using traded assets (e.g., the underlying and riskless assets) is not uniquely determined by arbitrage considerations. As discussed in <a href="#sec-s_incomplete"><span class="quarto-unresolved-ref">sec-s_incomplete</span></a>, one must use equilibrium pricing in this circumstance. That is what we have implicitly done in this chapter. By assuming particular dynamics for the volatility under the risk-neutral measure, we have implicitly selected a particular risk-neutral measure from the set of risk-neutral measures that are consistent with the absence of arbitrage.</p>
</section>
<section id="exercises" class="level2" data-number="5.8">
<h2 data-number="5.8" class="anchored" data-anchor-id="exercises"><span class="header-section-number">5.8</span> Exercises</h2>
<div id="exr-e_mixture" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 5.1 </strong></span>The purpose of this exercise is to generate a fat-tailed distribution from a model that is simpler than the GARCH and stochastic volatility models but has somewhat the same flavor. The distribution will be a mixture of normals. Create an Excel worksheet in which the user can input <span class="math inline">\(S\)</span>, <span class="math inline">\(r\)</span>, <span class="math inline">\(q\)</span>, <span class="math inline">\(T\)</span>, <span class="math inline">\(\sigma_1\)</span> and <span class="math inline">\(\sigma_2\)</span>. Use these inputs to produce a column of 500 simulated <span class="math inline">\(\log S(T)\)</span>. In each simulation, define <span class="math inline">\(\log S(T)\)</span> as <span class="math display">\[\log S(T) = \log S(0) + \left(r-q-\frac{1}{2}\sigma^2\right)T + \sigma \sqrt{T}z\;,\]</span> where <span class="math inline">\(z\)</span> is a standard normal, <span class="math inline">\(\sigma = x\sigma_1 + (1-x)\sigma_2\)</span>, and <span class="math inline">\(x\)</span> is a random variable that equals zero or one with equal probabilities. You can define <span class="math inline">\(z\)</span> in each simulation as and <span class="math inline">\(x\)</span> as . Calculate the mean and standard deviation of the <span class="math inline">\(\log S(T)\)</span> and calculate the fraction that lie more than two standard deviations below the mean. If the <span class="math inline">\(\log S(T)\)</span> all came from a normal distribution with the same variance, then this fraction should equal $(-2) = $ 2.275%. If the fraction is higher, then the distribution is fat tailed. (Of course, the actual fraction would differ from 2.275% in any particular case due to the randomness of the simulation, even if all of the <span class="math inline">\(\log S(T)\)</span> came from a normal distribution with the same variance).</p>
</div>
<div id="exr-e_GARCH1" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 5.2 </strong></span>Create an Excel macro prompting the user to input the same inputs as in the subroutine except for the initial volatility and <span class="math inline">\(\theta\)</span>. Simulate 500 paths of a GARCH process and output <span class="math inline">\(\log S(T)\)</span> for each simulation (you don’t need to output the entire paths as in the macro). Take the initial volatility to be 0.3 and <span class="math inline">\(\theta = 0.09\)</span>. Determine whether the distribution is fat-tailed by computing the fraction of the <span class="math inline">\(\log S(T)\)</span> that lie two or more standard deviations below the mean, as in the previous exercise. For what values of <span class="math inline">\(\kappa\)</span> and <span class="math inline">\(\lambda\)</span> does the distribution appear to be especially fat-tailed?</p>
</div>
<div id="exr-nolabel" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 5.3 </strong></span>Repeat <a href="#exr-e_GARCH1">Exercise&nbsp;<span class="quarto-unresolved-ref">exr-e_GARCH1</span></a> for the Heston stochastic volatility model, describing the values of <span class="math inline">\(\kappa\)</span>, <span class="math inline">\(\gamma\)</span> and <span class="math inline">\(\rho\)</span> that appear to generate especially fat-tailed distributions. ext ext Excel provides some tools that are useful for exercises of this sort. If you load the Data Analysis add-in (click Tools/Add Ins), you can produce a histogram of the simulated data, which is useful for visually analyzing departures from normality. The Data Analysis add-in will also produce summary statistics, including the kurtosis and skewness of the data (without using the add-in, the kurtosis can be computed with the Excel function and the skewness with the Excel function ). The kurtosis of a random variable <span class="math inline">\(x\)</span> is defined as <span class="math inline">\(E[(x-\mu)^4]/\sigma^4\)</span>, where <span class="math inline">\(\mu\)</span> is the mean and <span class="math inline">\(\sigma\)</span> is the standard deviation of <span class="math inline">\(x\)</span>. The kurtosis of a normal distribution is 3. A kurtosis larger than 3 is excess kurtosis, meaning the distribution is leptokurtic (fat tailed). Excel’s function actually computes excess kurtosis, so a positive value indicates a fat-tailed distribution. The skewness of <span class="math inline">\(x\)</span> is defined as <span class="math inline">\(E[(x-\mu)^3]/\sigma^3\)</span>. The skewness of a normal distribution is zero. Negative skewness indicates the distribution is skewed to the left, meaning the lower tail is fatter than the upper tail (crashes are more likely than booms). Positive skewness indicates the distribution is skewed to the right.</p>
</div>


<div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-Bollerslev" class="csl-entry" role="listitem">
Bollerslev, T. 1986. <span>“Generalized Autoregressive Conditional Heteroskedasticity.”</span> <em>Journal of Econometrics</em> 31: 307–27.
</div>
<div id="ref-broadiekaya" class="csl-entry" role="listitem">
Broadie, M., and O. Kaya. 2006. <span>“Exact Simulation of Stochastic Volatility and Other Affine Jump Diffusion Processes.”</span> <em>Operations Research</em> 52: 217–31.
</div>
<div id="ref-Epps" class="csl-entry" role="listitem">
Epps, T. W. 2000. <em>Pricing Derivative Securities</em>. World Scientific Publishing, Singapore.
</div>
<div id="ref-Glasserman" class="csl-entry" role="listitem">
Glasserman, P. 2004. <em>Monte Carlo Methods in Financial Engineering</em>. Springer, New York Berlin Heidelberg.
</div>
<div id="ref-Heston" class="csl-entry" role="listitem">
Heston, S. 1993. <span>“A Closed-Form Solution for Options with Stochastic Volatility with Applications to Bond and Currency Options.”</span> <em>Review of Financial Studies</em> 6: 327–44.
</div>
<div id="ref-HN" class="csl-entry" role="listitem">
Heston, S., and S. Nandi. 2000. <span>“A Closed-Form GARCH Option Valuation Model.”</span> <em>Review of Financial Studies</em> 13: 585–625.
</div>
<div id="ref-MX" class="csl-entry" role="listitem">
Mina, J., and J. Xiao. 2001. <em>Return to RiskMetrics</em>. The Evolution of a Standard.
</div>
</div>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>Conversely, the probability of returns very near the mean must also be higher than under a normal distribution with the same standard deviation—a fat-tailed distribution must also have a relatively narrow peak.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Actually, a slightly more general model is considered in <span class="citation" data-cites="HN">(<a href="#ref-HN" role="doc-biblioref">Heston and Nandi 2000</a>)</span>, in which large negative returns lead to a greater increase in volatility than do large positive returns. This accommodates the empirically observed negative correlation between stock returns and volatility.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>There are better (but more complicated) ways to simulate the Heston model. An excellent discussion of ways to simulate the volatility process can be found in Glasserman <span class="citation" data-cites="Glasserman">(<a href="#ref-Glasserman" role="doc-biblioref">Glasserman 2004</a>)</span>. Broadie and Kaya <span class="citation" data-cites="broadiekaya">(<a href="#ref-broadiekaya" role="doc-biblioref">Broadie and Kaya 2006</a>)</span> present a method for simulating from the exact distribution of the asset price in the Heston model and related models.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>Further discussion can be found in Epps <span class="citation" data-cites="Epps">(<a href="#ref-Epps" role="doc-biblioref">Epps 2000</a>)</span>.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./Chapter4.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Black-Scholes</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./Chapter6.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Introduction to Monte Carlo and Binomial Models</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>